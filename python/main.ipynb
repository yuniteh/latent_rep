{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import os\n",
    "import copy as cp\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from DL_utils import MLP, MLPbeta, CNN, eval_nn\n",
    "\n",
    "import process_data as prd\n",
    "from lda import train_lda, predict, eval_lda, eval_lda_ch\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'AB'\n",
    "with open('train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: traindata_manual/AB2_traindata_2.p\n"
     ]
    }
   ],
   "source": [
    "## Training \n",
    "sub = 2\n",
    "train_grp = 2\n",
    "n_train = 'fullallmix4'\n",
    "train_scale = 5\n",
    "cv_type = 'manual'\n",
    "scaler_load = False\n",
    "feat_type = 'mav'\n",
    "\n",
    "ind = (params[:,0] == sub) & (params[:,3] == train_grp)\n",
    "\n",
    "x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,sub_type,dt=cv_type,load=True,train_grp=train_grp)\n",
    "\n",
    "emg_scale = np.ones((np.size(x_train,1),1))\n",
    "for i in range(np.size(x_train,1)):\n",
    "    emg_scale[i] = 5/np.max(np.abs(x_train[:,i,:]))\n",
    "x_train = x_train*emg_scale\n",
    "x_valid = x_valid*emg_scale\n",
    "\n",
    "x_train_noise, x_train_clean, y_train_clean = prd.add_noise(x_train, p_train, sub, n_train, train_scale)\n",
    "x_valid_noise, x_valid_clean, y_valid_clean = prd.add_noise(x_train, p_train, sub, n_train, train_scale)\n",
    "\n",
    "# shuffle data to make even batches\n",
    "x_train_noise, x_train_clean, y_train_clean = shuffle(x_train_noise, x_train_clean, y_train_clean, random_state = 0)\n",
    "\n",
    "# Extract features\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_train_noise_cnn, scaler = prd.extract_scale(x_train_noise,scaler,scaler_load,ft=feat_type,emg_scale=emg_scale) \n",
    "x_train_clean_cnn, _ = prd.extract_scale(x_train_clean,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_valid_noise_cnn, _ = prd.extract_scale(x_valid_noise,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_valid_clean_cnn, _ = prd.extract_scale(x_valid_clean,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_train_noise_cnn = x_train_noise_cnn.astype('float32')\n",
    "x_valid_noise_cnn = x_valid_noise_cnn.astype('float32')\n",
    "\n",
    "# reshape data for nonconvolutional network\n",
    "x_train_noise_mlp = x_train_noise_cnn.reshape(x_train_noise_cnn.shape[0],-1)\n",
    "x_valid_noise_mlp = x_valid_noise_cnn.reshape(x_valid_noise_cnn.shape[0],-1)\n",
    "\n",
    "\n",
    "# create batches\n",
    "trainmlp_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_mlp, y_train_clean)).batch(128)\n",
    "testmlp_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_mlp, y_valid_clean)).batch(128)\n",
    "traincnn_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_cnn, y_train_clean)).batch(128)\n",
    "testcnn_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_cnn, y_valid_clean)).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "mlp_beta = MLPbeta()\n",
    "cnn = CNN()\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "## TRAIN TEST MLP\n",
    "@tf.function\n",
    "def train_mlp(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_out = mlp(x)\n",
    "        loss = loss_fn(y, y_out)\n",
    "    gradients = tape.gradient(loss, mlp.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, mlp.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_mlp(x, y):\n",
    "    y_out = mlp(x)\n",
    "    t_loss = loss_fn(y, y_out)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(y, y_out)\n",
    "\n",
    "## TRAIN TEST MLP BETA\n",
    "@tf.function\n",
    "def train_mlpbeta(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_out = mlp_beta(x)\n",
    "        loss = loss_fn(y, y_out)\n",
    "    gradients = tape.gradient(loss, mlp_beta.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, mlp_beta.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_mlpbeta(x, y):\n",
    "    y_out = mlp_beta(x)\n",
    "    t_loss = loss_fn(y, y_out)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(y, y_out)\n",
    "\n",
    "## TRAIN TEST CNN\n",
    "@tf.function\n",
    "def train_cnn(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_out = cnn(x)\n",
    "        loss = loss_fn(y, y_out)\n",
    "    gradients = tape.gradient(loss, cnn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, cnn.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_cnn(x, y):\n",
    "    y_out = cnn(x)\n",
    "    t_loss = loss_fn(y, y_out)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(y, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp\n",
      "Epoch 1, Loss: 1.943560242652893, Accuracy: 15.873016357421875, Test Loss: 1.937218189239502, Test Accuracy: 17.234127044677734\n",
      "Epoch 2, Loss: 1.9178284406661987, Accuracy: 21.35714340209961, Test Loss: 1.8859671354293823, Test Accuracy: 26.432540893554688\n",
      "Epoch 3, Loss: 1.8527731895446777, Accuracy: 30.071428298950195, Test Loss: 1.8307876586914062, Test Accuracy: 33.07936477661133\n",
      "Epoch 4, Loss: 1.8170874118804932, Accuracy: 34.0555534362793, Test Loss: 1.802474021911621, Test Accuracy: 36.31746292114258\n",
      "Epoch 5, Loss: 1.7910137176513672, Accuracy: 36.988094329833984, Test Loss: 1.7804394960403442, Test Accuracy: 38.31349182128906\n",
      "Epoch 6, Loss: 1.769500732421875, Accuracy: 39.333335876464844, Test Loss: 1.7619285583496094, Test Accuracy: 40.150794982910156\n",
      "Epoch 7, Loss: 1.7521098852157593, Accuracy: 40.904762268066406, Test Loss: 1.7457218170166016, Test Accuracy: 41.77381134033203\n",
      "Epoch 8, Loss: 1.7390204668045044, Accuracy: 42.2976188659668, Test Loss: 1.7339714765548706, Test Accuracy: 43.0555534362793\n",
      "Epoch 9, Loss: 1.7297792434692383, Accuracy: 43.369049072265625, Test Loss: 1.725471019744873, Test Accuracy: 43.841270446777344\n",
      "Epoch 10, Loss: 1.7210583686828613, Accuracy: 44.43253707885742, Test Loss: 1.714288592338562, Test Accuracy: 45.18650817871094\n",
      "Epoch 11, Loss: 1.7114678621292114, Accuracy: 45.44047546386719, Test Loss: 1.7068750858306885, Test Accuracy: 45.892860412597656\n",
      "Epoch 12, Loss: 1.7030450105667114, Accuracy: 46.376983642578125, Test Loss: 1.696487307548523, Test Accuracy: 47.06349182128906\n",
      "Epoch 13, Loss: 1.6937932968139648, Accuracy: 47.369049072265625, Test Loss: 1.6880080699920654, Test Accuracy: 47.74603271484375\n",
      "Epoch 14, Loss: 1.6874250173568726, Accuracy: 47.96428680419922, Test Loss: 1.6822240352630615, Test Accuracy: 48.36904525756836\n",
      "Epoch 15, Loss: 1.6825602054595947, Accuracy: 48.488094329833984, Test Loss: 1.6767350435256958, Test Accuracy: 49.011905670166016\n",
      "Epoch 16, Loss: 1.678236722946167, Accuracy: 48.833335876464844, Test Loss: 1.6730670928955078, Test Accuracy: 49.333335876464844\n",
      "Epoch 17, Loss: 1.6749132871627808, Accuracy: 49.162696838378906, Test Loss: 1.670701026916504, Test Accuracy: 49.53174591064453\n",
      "Epoch 18, Loss: 1.6721084117889404, Accuracy: 49.28174591064453, Test Loss: 1.6687275171279907, Test Accuracy: 49.67460250854492\n",
      "Epoch 19, Loss: 1.6695367097854614, Accuracy: 49.56349182128906, Test Loss: 1.6673954725265503, Test Accuracy: 49.85317611694336\n",
      "Epoch 20, Loss: 1.6676536798477173, Accuracy: 49.68254089355469, Test Loss: 1.665611982345581, Test Accuracy: 49.988094329833984\n",
      "Epoch 21, Loss: 1.6658155918121338, Accuracy: 49.908729553222656, Test Loss: 1.6637269258499146, Test Accuracy: 50.21825408935547\n",
      "Epoch 22, Loss: 1.6637519598007202, Accuracy: 50.17063522338867, Test Loss: 1.6602271795272827, Test Accuracy: 50.472225189208984\n",
      "Epoch 23, Loss: 1.6621636152267456, Accuracy: 50.277774810791016, Test Loss: 1.6576097011566162, Test Accuracy: 50.79365539550781\n",
      "Epoch 24, Loss: 1.6594709157943726, Accuracy: 50.58333206176758, Test Loss: 1.6550308465957642, Test Accuracy: 50.873016357421875\n",
      "Epoch 25, Loss: 1.6566777229309082, Accuracy: 50.80952453613281, Test Loss: 1.65189528465271, Test Accuracy: 51.15873336791992\n",
      "Epoch 26, Loss: 1.6536954641342163, Accuracy: 51.15079116821289, Test Loss: 1.6497478485107422, Test Accuracy: 51.43650817871094\n",
      "Epoch 27, Loss: 1.6509579420089722, Accuracy: 51.35714340209961, Test Loss: 1.6463704109191895, Test Accuracy: 51.829368591308594\n",
      "Epoch 28, Loss: 1.6486046314239502, Accuracy: 51.5, Test Loss: 1.6415990591049194, Test Accuracy: 52.31349563598633\n",
      "Epoch 29, Loss: 1.6447563171386719, Accuracy: 51.916664123535156, Test Loss: 1.6428247690200806, Test Accuracy: 52.08333206176758\n",
      "Epoch 30, Loss: 1.6435943841934204, Accuracy: 51.96428298950195, Test Loss: 1.640663743019104, Test Accuracy: 52.4444465637207\n",
      "Training mlpbeta\n",
      "Epoch 1, Loss: 1.8619098663330078, Accuracy: 28.33333396911621, Test Loss: 1.7843047380447388, Test Accuracy: 38.337303161621094\n",
      "Epoch 2, Loss: 1.7597564458847046, Accuracy: 40.476192474365234, Test Loss: 1.7421135902404785, Test Accuracy: 42.17856979370117\n",
      "Epoch 3, Loss: 1.7174373865127563, Accuracy: 44.68253707885742, Test Loss: 1.700273871421814, Test Accuracy: 46.53968048095703\n",
      "Epoch 4, Loss: 1.6907703876495361, Accuracy: 47.273807525634766, Test Loss: 1.6861649751663208, Test Accuracy: 47.837303161621094\n",
      "Epoch 5, Loss: 1.6802711486816406, Accuracy: 48.36904525756836, Test Loss: 1.6674939393997192, Test Accuracy: 49.7420654296875\n",
      "Epoch 6, Loss: 1.6626596450805664, Accuracy: 50.14682388305664, Test Loss: 1.6505744457244873, Test Accuracy: 51.27381134033203\n",
      "Epoch 7, Loss: 1.6494232416152954, Accuracy: 51.337303161621094, Test Loss: 1.6379001140594482, Test Accuracy: 52.54365158081055\n",
      "Epoch 8, Loss: 1.638858675956726, Accuracy: 52.52381134033203, Test Loss: 1.6288882493972778, Test Accuracy: 53.59920883178711\n",
      "Epoch 9, Loss: 1.6324717998504639, Accuracy: 53.158729553222656, Test Loss: 1.6238888502120972, Test Accuracy: 54.000003814697266\n",
      "Epoch 10, Loss: 1.6277309656143188, Accuracy: 53.658729553222656, Test Loss: 1.6220588684082031, Test Accuracy: 54.11111068725586\n",
      "Epoch 11, Loss: 1.6240952014923096, Accuracy: 53.99603271484375, Test Loss: 1.6200978755950928, Test Accuracy: 54.28968048095703\n",
      "Epoch 12, Loss: 1.6206880807876587, Accuracy: 54.31746292114258, Test Loss: 1.6169755458831787, Test Accuracy: 54.66666793823242\n",
      "Epoch 13, Loss: 1.6179375648498535, Accuracy: 54.63492202758789, Test Loss: 1.6141247749328613, Test Accuracy: 54.84920883178711\n",
      "Epoch 14, Loss: 1.6153870820999146, Accuracy: 54.7976188659668, Test Loss: 1.61165452003479, Test Accuracy: 55.10317611694336\n",
      "Epoch 15, Loss: 1.614029049873352, Accuracy: 54.992061614990234, Test Loss: 1.613791584968567, Test Accuracy: 54.9603157043457\n",
      "Epoch 16, Loss: 1.6114803552627563, Accuracy: 55.11111068725586, Test Loss: 1.6165682077407837, Test Accuracy: 54.7579345703125\n",
      "Epoch 17, Loss: 1.608453392982483, Accuracy: 55.5079345703125, Test Loss: 1.6157810688018799, Test Accuracy: 54.76984405517578\n",
      "Epoch 18, Loss: 1.6069419384002686, Accuracy: 55.73809814453125, Test Loss: 1.6065518856048584, Test Accuracy: 55.63492202758789\n",
      "Epoch 19, Loss: 1.601109504699707, Accuracy: 56.31745910644531, Test Loss: 1.6042386293411255, Test Accuracy: 55.880950927734375\n",
      "Epoch 20, Loss: 1.5942332744598389, Accuracy: 56.94444274902344, Test Loss: 1.6018345355987549, Test Accuracy: 56.05555725097656\n",
      "Epoch 21, Loss: 1.5853321552276611, Accuracy: 57.90079116821289, Test Loss: 1.5902172327041626, Test Accuracy: 57.384918212890625\n",
      "Epoch 22, Loss: 1.5774245262145996, Accuracy: 58.65079116821289, Test Loss: 1.5862663984298706, Test Accuracy: 57.496028900146484\n",
      "Epoch 23, Loss: 1.5722466707229614, Accuracy: 59.126983642578125, Test Loss: 1.5782891511917114, Test Accuracy: 58.57142639160156\n",
      "Epoch 24, Loss: 1.5676859617233276, Accuracy: 59.61111068725586, Test Loss: 1.570741891860962, Test Accuracy: 59.365081787109375\n",
      "Epoch 25, Loss: 1.5662469863891602, Accuracy: 59.78571319580078, Test Loss: 1.5684072971343994, Test Accuracy: 59.5317497253418\n",
      "Epoch 26, Loss: 1.5619220733642578, Accuracy: 60.33729934692383, Test Loss: 1.5665103197097778, Test Accuracy: 59.60714340209961\n",
      "Epoch 27, Loss: 1.5575366020202637, Accuracy: 60.718257904052734, Test Loss: 1.5622222423553467, Test Accuracy: 60.095237731933594\n",
      "Epoch 28, Loss: 1.557839274406433, Accuracy: 60.76984405517578, Test Loss: 1.5624881982803345, Test Accuracy: 59.992061614990234\n",
      "Epoch 29, Loss: 1.5541163682937622, Accuracy: 61.115081787109375, Test Loss: 1.5583947896957397, Test Accuracy: 60.55952453613281\n",
      "Epoch 30, Loss: 1.5506699085235596, Accuracy: 61.42856979370117, Test Loss: 1.5604174137115479, Test Accuracy: 60.34920883178711\n",
      "Training cnn\n",
      "Epoch 1, Loss: 1.8299298286437988, Accuracy: 31.785715103149414, Test Loss: 1.7189056873321533, Test Accuracy: 44.36111068725586\n",
      "Epoch 2, Loss: 1.6701587438583374, Accuracy: 50.14682388305664, Test Loss: 1.6264872550964355, Test Accuracy: 54.55158996582031\n",
      "Epoch 3, Loss: 1.6152794361114502, Accuracy: 55.484127044677734, Test Loss: 1.601760983467102, Test Accuracy: 56.71428298950195\n",
      "Epoch 4, Loss: 1.5941941738128662, Accuracy: 57.30158615112305, Test Loss: 1.5832798480987549, Test Accuracy: 58.42460250854492\n",
      "Epoch 5, Loss: 1.5633591413497925, Accuracy: 60.591270446777344, Test Loss: 1.558449625968933, Test Accuracy: 61.0555534362793\n",
      "Epoch 6, Loss: 1.5449010133743286, Accuracy: 62.599205017089844, Test Loss: 1.547511339187622, Test Accuracy: 62.119049072265625\n",
      "Epoch 7, Loss: 1.5349384546279907, Accuracy: 63.404762268066406, Test Loss: 1.543014407157898, Test Accuracy: 62.35317611694336\n",
      "Epoch 8, Loss: 1.5276520252227783, Accuracy: 64.02777862548828, Test Loss: 1.5304057598114014, Test Accuracy: 63.666664123535156\n",
      "Epoch 9, Loss: 1.523608684539795, Accuracy: 64.43254089355469, Test Loss: 1.5293331146240234, Test Accuracy: 63.75\n",
      "Epoch 10, Loss: 1.5201990604400635, Accuracy: 64.69841003417969, Test Loss: 1.5287853479385376, Test Accuracy: 63.734127044677734\n",
      "Epoch 11, Loss: 1.516350269317627, Accuracy: 65.03571319580078, Test Loss: 1.5222634077072144, Test Accuracy: 64.38491821289062\n",
      "Epoch 12, Loss: 1.5143940448760986, Accuracy: 65.1706314086914, Test Loss: 1.5126763582229614, Test Accuracy: 65.37698364257812\n",
      "Epoch 13, Loss: 1.51182222366333, Accuracy: 65.47222137451172, Test Loss: 1.511582374572754, Test Accuracy: 65.43254089355469\n",
      "Epoch 14, Loss: 1.5092066526412964, Accuracy: 65.65872955322266, Test Loss: 1.5134071111679077, Test Accuracy: 65.28174591064453\n",
      "Epoch 15, Loss: 1.5064176321029663, Accuracy: 66.01983642578125, Test Loss: 1.5128309726715088, Test Accuracy: 65.30158233642578\n",
      "Epoch 16, Loss: 1.5050400495529175, Accuracy: 66.1706314086914, Test Loss: 1.5080087184906006, Test Accuracy: 65.65872955322266\n",
      "Epoch 17, Loss: 1.502002239227295, Accuracy: 66.44047546386719, Test Loss: 1.511237621307373, Test Accuracy: 65.38491821289062\n",
      "Epoch 18, Loss: 1.500307321548462, Accuracy: 66.65079498291016, Test Loss: 1.505356788635254, Test Accuracy: 66.08333587646484\n",
      "Epoch 19, Loss: 1.4999176263809204, Accuracy: 66.65079498291016, Test Loss: 1.5007826089859009, Test Accuracy: 66.64285278320312\n",
      "Epoch 20, Loss: 1.4985404014587402, Accuracy: 66.72618865966797, Test Loss: 1.5010801553726196, Test Accuracy: 66.54364776611328\n",
      "Epoch 21, Loss: 1.49705171585083, Accuracy: 66.95634460449219, Test Loss: 1.5011032819747925, Test Accuracy: 66.54762268066406\n",
      "Epoch 22, Loss: 1.495590329170227, Accuracy: 67.10713958740234, Test Loss: 1.499746561050415, Test Accuracy: 66.6547622680664\n",
      "Epoch 23, Loss: 1.4945446252822876, Accuracy: 67.11111450195312, Test Loss: 1.4974193572998047, Test Accuracy: 66.84127044677734\n",
      "Epoch 24, Loss: 1.4924293756484985, Accuracy: 67.38095092773438, Test Loss: 1.4933947324752808, Test Accuracy: 67.26984405517578\n",
      "Epoch 25, Loss: 1.492274284362793, Accuracy: 67.25396728515625, Test Loss: 1.4931386709213257, Test Accuracy: 67.34127044677734\n",
      "Epoch 26, Loss: 1.489912509918213, Accuracy: 67.63095092773438, Test Loss: 1.4925453662872314, Test Accuracy: 67.29364776611328\n",
      "Epoch 27, Loss: 1.490275263786316, Accuracy: 67.52777862548828, Test Loss: 1.4896187782287598, Test Accuracy: 67.65079498291016\n",
      "Epoch 28, Loss: 1.4892535209655762, Accuracy: 67.72222900390625, Test Loss: 1.4897148609161377, Test Accuracy: 67.61904907226562\n",
      "Epoch 29, Loss: 1.4880670309066772, Accuracy: 67.80952453613281, Test Loss: 1.4864652156829834, Test Accuracy: 67.94444274902344\n",
      "Epoch 30, Loss: 1.4869866371154785, Accuracy: 67.93254089355469, Test Loss: 1.4899084568023682, Test Accuracy: 67.5873031616211\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "models = ['mlp','mlpbeta','cnn']\n",
    "\n",
    "for model in models:\n",
    "    print('Training ' + model)\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "\n",
    "        # Train MLP\n",
    "        if model == 'mlp':\n",
    "            for x, y in trainmlp_ds:\n",
    "                train_mlp(x, y)\n",
    "            for x_test, y_test in testmlp_ds:\n",
    "                test_mlp(x_test, y_test)\n",
    "        # Train MLP Beta\n",
    "        elif model == 'mlpbeta':\n",
    "            for x, y in trainmlp_ds:\n",
    "                train_mlpbeta(x, y)\n",
    "            for x_test, y_test in testmlp_ds:\n",
    "                test_mlpbeta(x_test, y_test)\n",
    "        # Train CNN\n",
    "        elif model == 'cnn':\n",
    "            for x, y in traincnn_ds:\n",
    "                train_cnn(x,y)\n",
    "            for x_test, y_test in testcnn_ds:\n",
    "                test_cnn(x_test, y_test)\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}, '\n",
    "            f'Loss: {train_loss.result()}, '\n",
    "            f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "            f'Test Loss: {test_loss.result()}, '\n",
    "            f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_enc = mlp.get_layer(name='enc')\n",
    "mlpbeta_enc = mlp_beta.get_layer(name='enc')\n",
    "cnn_enc = cnn.get_layer(name='enc')\n",
    "\n",
    "mlp_aligned = mlp_enc(x_train_noise_mlp).numpy()\n",
    "mlp_beta_aligned = mlpbeta_enc(x_train_noise_mlp).numpy()\n",
    "cnn_aligned = cnn_enc(x_train_noise_cnn).numpy()\n",
    "\n",
    "y_train_aligned = np.argmax(y_train_clean, axis=1)[...,np.newaxis]\n",
    "w_mlp, c_mlp,_, _, _ = train_lda(mlp_aligned,y_train_aligned)\n",
    "w_mlpbeta, c_mlpbeta,_, _, _ = train_lda(mlp_beta_aligned,y_train_aligned)\n",
    "w_cnn, c_cnn,_, _, _ = train_lda(cnn_aligned,y_train_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: traindata_manual/AB2_traindata_4.p\n",
      "MLP ---- Clean Accuracy: 75.46, Noisy Accuracy: 57.54, LDA Clean Accuracy: 56.77, LDA Noisy Accuracy: 49.57\n",
      "MLPB ---- Clean Accuracy: 80.20, Noisy Accuracy: 62.97, LDA Clean Accuracy: 79.26, LDA Noisy Accuracy: 61.89\n",
      "CNN ---- Clean Accuracy: 86.00, Noisy Accuracy: 68.17, LDA Clean Accuracy: 75.34, LDA Noisy Accuracy: 59.69\n"
     ]
    }
   ],
   "source": [
    "test_grp = 4\n",
    "cv_type = 'manual'\n",
    "n_test = 'partposrealmixeven24'\n",
    "\n",
    "with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "    real_noise_temp, _ = pickle.load(f)\n",
    "\n",
    "_, x_test, _, _, p_test, _ = prd.train_data_split(raw,params,sub,sub_type,dt=cv_type,train_grp=test_grp)\n",
    "clean_size = int(np.size(x_test,axis=0))\n",
    "x_test = x_test*emg_scale\n",
    "\n",
    "x_test_noise, x_test_clean, y_test_clean = prd.add_noise(x_test, p_test, sub, n_test, 1, real_noise=real_noise_temp, emg_scale = emg_scale)\n",
    "x_test_cnn, _ = prd.extract_scale(x_test_noise,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_test_cnn = x_test_cnn.astype('float32')\n",
    "x_test_mlp = x_test_cnn.reshape(x_test_cnn.shape[0],-1)\n",
    "\n",
    "mlp_test_aligned = mlp_enc(x_test_mlp).numpy()\n",
    "mlpbeta_test_aligned = mlpbeta_enc(x_test_mlp).numpy()\n",
    "cnn_test_aligned = cnn_enc(x_test_cnn).numpy()\n",
    "y_test_aligned = np.argmax(y_test_clean, axis=1)[...,np.newaxis]\n",
    "\n",
    "clean_acc, noisy_acc = eval_nn(x_test_mlp, y_test_clean,mlp,clean_size)\n",
    "clean_lda = eval_lda(w_mlp,c_mlp,mlp_test_aligned[:clean_size,...],y_test_aligned[:clean_size,...])\n",
    "noisy_lda = eval_lda(w_mlp,c_mlp,mlp_test_aligned[clean_size:,...],y_test_aligned[clean_size:,...])\n",
    "print(\n",
    "    f'MLP ---- '\n",
    "    f'Clean Accuracy: {clean_acc * 100:.2f}, '\n",
    "    f'Noisy Accuracy: {noisy_acc * 100:.2f}, '\n",
    "    f'LDA Clean Accuracy: {clean_lda * 100:.2f}, '\n",
    "    f'LDA Noisy Accuracy: {noisy_lda * 100:.2f}'\n",
    ")\n",
    "\n",
    "clean_acc, noisy_acc = eval_nn(x_test_mlp, y_test_clean,mlp_beta,clean_size)\n",
    "clean_lda = eval_lda(w_mlpbeta,c_mlpbeta,mlpbeta_test_aligned[:clean_size,...],y_test_aligned[:clean_size,...])\n",
    "noisy_lda = eval_lda(w_mlpbeta,c_mlpbeta,mlpbeta_test_aligned[clean_size:,...],y_test_aligned[clean_size:,...])\n",
    "print(\n",
    "    f'MLPB ---- '\n",
    "    f'Clean Accuracy: {clean_acc * 100:.2f}, '\n",
    "    f'Noisy Accuracy: {noisy_acc * 100:.2f}, '\n",
    "    f'LDA Clean Accuracy: {clean_lda * 100:.2f}, '\n",
    "    f'LDA Noisy Accuracy: {noisy_lda * 100:.2f}'\n",
    ")\n",
    "\n",
    "clean_acc, noisy_acc = eval_nn(x_test_cnn, y_test_clean,cnn,clean_size)\n",
    "clean_lda = eval_lda(w_cnn,c_cnn,cnn_test_aligned[:clean_size,...],y_test_aligned[:clean_size,...])\n",
    "noisy_lda = eval_lda(w_cnn,c_cnn,cnn_test_aligned[clean_size:,...],y_test_aligned[clean_size:,...])\n",
    "print(\n",
    "    f'CNN ---- '\n",
    "    f'Clean Accuracy: {clean_acc * 100:.2f}, '\n",
    "    f'Noisy Accuracy: {noisy_acc * 100:.2f}, '\n",
    "    f'LDA Clean Accuracy: {clean_lda * 100:.2f}, '\n",
    "    f'LDA Noisy Accuracy: {noisy_lda * 100:.2f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".8"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a3b9df806ffb9c99dfd499571232d2e3ccda8a03627b2b254cd16611a407c53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf-2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
