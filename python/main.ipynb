{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import os\n",
    "import copy as cp\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from DL_utils import MLP, MLPbeta, CNN\n",
    "\n",
    "import process_data as prd\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'TR'\n",
    "with open('train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: traindata_manual/TR1_traindata_2.p\n"
     ]
    }
   ],
   "source": [
    "## Training \n",
    "sub = 1\n",
    "train_grp = 2\n",
    "n_train = 'fullallmix4'\n",
    "train_scale = 5\n",
    "cv_type = 'manual'\n",
    "scaler_load = False\n",
    "feat_type = 'feat'\n",
    "\n",
    "ind = (params[:,0] == sub) & (params[:,3] == train_grp)\n",
    "\n",
    "x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,sub_type,dt=cv_type,load=True,train_grp=train_grp)\n",
    "\n",
    "emg_scale = np.ones((np.size(x_train,1),1))\n",
    "for i in range(np.size(x_train,1)):\n",
    "    emg_scale[i] = 5/np.max(np.abs(x_train[:,i,:]))\n",
    "x_train = x_train*emg_scale\n",
    "x_valid = x_valid*emg_scale\n",
    "\n",
    "x_train_noise, x_train_clean, y_train_clean = prd.add_noise(x_train, p_train, sub, n_train, train_scale)\n",
    "x_valid_noise, x_valid_clean, y_valid_clean = prd.add_noise(x_train, p_train, sub, n_train, train_scale)\n",
    "\n",
    "# shuffle data to make even batches\n",
    "x_train_noise, x_train_clean, y_train_clean = shuffle(x_train_noise, x_train_clean, y_train_clean, random_state = 0)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Extract features\n",
    "x_train_noise_cnn, scaler = prd.extract_scale(x_train_noise,scaler,scaler_load,ft=feat_type,emg_scale=emg_scale) \n",
    "x_train_clean_cnn, _ = prd.extract_scale(x_train_clean,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_valid_noise_cnn, _ = prd.extract_scale(x_valid_noise,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_valid_clean_cnn, _ = prd.extract_scale(x_valid_clean,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "\n",
    "# reshape data for nonconvolutional network\n",
    "x_train_noise_mlp = x_train_noise_cnn.reshape(x_train_noise_cnn.shape[0],-1).astype('float32')\n",
    "x_valid_noise_mlp = x_valid_noise_cnn.reshape(x_valid_noise_cnn.shape[0],-1).astype('float32')\n",
    "\n",
    "# create batches\n",
    "trainmlp_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_mlp, y_train_clean)).batch(128)\n",
    "testmlp_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_mlp, y_valid_clean)).batch(128)\n",
    "traincnn_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_cnn.astype('float32'), y_train_clean)).batch(128)\n",
    "testcnn_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_cnn.astype('float32'), y_valid_clean)).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "mlp_beta = MLPbeta()\n",
    "cnn = CNN()\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "## TRAIN TEST MLP\n",
    "@tf.function\n",
    "def train_mlp(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_out = mlp(x)\n",
    "    loss = loss_fn(y, y_out)\n",
    "  gradients = tape.gradient(loss, mlp.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, mlp.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_mlp(x, y):\n",
    "  y_out = mlp(x)\n",
    "  t_loss = loss_fn(y, y_out)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(y, y_out)\n",
    "\n",
    "## TRAIN TEST MLP BETA\n",
    "@tf.function\n",
    "def train_mlpbeta(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_out = mlp_beta(x)\n",
    "    loss = loss_fn(y, y_out)\n",
    "  gradients = tape.gradient(loss, mlp_beta.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, mlp_beta.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_mlpbeta(x, y):\n",
    "  y_out = mlp_beta(x)\n",
    "  t_loss = loss_fn(y, y_out)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(y, y_out)\n",
    "\n",
    "## TRAIN TEST CNN\n",
    "@tf.function\n",
    "def train_cnn(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_out = cnn(x)\n",
    "    loss = loss_fn(y, y_out)\n",
    "  gradients = tape.gradient(loss, cnn.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, cnn.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_cnn(x, y):\n",
    "  y_out = cnn(x)\n",
    "  t_loss = loss_fn(y, y_out)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(y, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp\n",
      "Epoch 1, Loss: 1.925422191619873, Accuracy: 23.47222328186035, Test Loss: 1.9350544214248657, Test Accuracy: 16.72222137451172\n",
      "Epoch 2, Loss: 1.859458327293396, Accuracy: 28.559524536132812, Test Loss: 1.8525731563568115, Test Accuracy: 27.55158805847168\n",
      "Epoch 3, Loss: 1.8175556659698486, Accuracy: 34.32142639160156, Test Loss: 1.825659990310669, Test Accuracy: 28.99603271484375\n",
      "Epoch 4, Loss: 1.7918576002120972, Accuracy: 36.61904525756836, Test Loss: 1.8070279359817505, Test Accuracy: 32.349205017089844\n",
      "Epoch 5, Loss: 1.7708046436309814, Accuracy: 38.242061614990234, Test Loss: 1.7880475521087646, Test Accuracy: 36.68254089355469\n",
      "Epoch 6, Loss: 1.757755160331726, Accuracy: 39.880950927734375, Test Loss: 1.7638436555862427, Test Accuracy: 39.06745910644531\n",
      "Epoch 7, Loss: 1.7480956315994263, Accuracy: 41.087303161621094, Test Loss: 1.7623605728149414, Test Accuracy: 40.099205017089844\n",
      "Epoch 8, Loss: 1.7398271560668945, Accuracy: 42.22222137451172, Test Loss: 1.7694971561431885, Test Accuracy: 38.54365158081055\n",
      "Epoch 9, Loss: 1.7324119806289673, Accuracy: 42.92856979370117, Test Loss: 1.7474722862243652, Test Accuracy: 40.42857360839844\n",
      "Epoch 10, Loss: 1.7244865894317627, Accuracy: 43.38888931274414, Test Loss: 1.7659127712249756, Test Accuracy: 38.58333206176758\n",
      "Training mlpbeta\n",
      "Epoch 1, Loss: 1.934627652168274, Accuracy: 22.559524536132812, Test Loss: 1.9083795547485352, Test Accuracy: 20.44841194152832\n",
      "Epoch 2, Loss: 1.8335280418395996, Accuracy: 30.166667938232422, Test Loss: 1.8365097045898438, Test Accuracy: 28.650793075561523\n",
      "Epoch 3, Loss: 1.7883352041244507, Accuracy: 36.25, Test Loss: 1.8321073055267334, Test Accuracy: 30.095237731933594\n",
      "Epoch 4, Loss: 1.7629406452178955, Accuracy: 38.94841384887695, Test Loss: 1.8200945854187012, Test Accuracy: 30.591270446777344\n",
      "Epoch 5, Loss: 1.7536998987197876, Accuracy: 39.92063522338867, Test Loss: 1.7838408946990967, Test Accuracy: 37.69047546386719\n",
      "Epoch 6, Loss: 1.7341111898422241, Accuracy: 42.39682388305664, Test Loss: 1.787554144859314, Test Accuracy: 36.21825408935547\n",
      "Epoch 7, Loss: 1.714301586151123, Accuracy: 45.154762268066406, Test Loss: 1.7310068607330322, Test Accuracy: 41.69444274902344\n",
      "Epoch 8, Loss: 1.7077306509017944, Accuracy: 45.630950927734375, Test Loss: 1.729856252670288, Test Accuracy: 42.68254089355469\n",
      "Epoch 9, Loss: 1.697520136833191, Accuracy: 46.738094329833984, Test Loss: 1.7176644802093506, Test Accuracy: 43.623016357421875\n",
      "Epoch 10, Loss: 1.6928980350494385, Accuracy: 47.003971099853516, Test Loss: 1.7063339948654175, Test Accuracy: 44.95635223388672\n",
      "Training cnn\n",
      "Epoch 1, Loss: 1.8665581941604614, Accuracy: 27.72222137451172, Test Loss: 1.9692000150680542, Test Accuracy: 17.380952835083008\n",
      "Epoch 2, Loss: 1.8315212726593018, Accuracy: 31.488096237182617, Test Loss: 1.814780592918396, Test Accuracy: 31.095239639282227\n",
      "Epoch 3, Loss: 1.7728792428970337, Accuracy: 38.146827697753906, Test Loss: 1.7969472408294678, Test Accuracy: 33.4523811340332\n",
      "Epoch 4, Loss: 1.7382118701934814, Accuracy: 42.738094329833984, Test Loss: 1.7407957315444946, Test Accuracy: 43.257938385009766\n",
      "Epoch 5, Loss: 1.7037197351455688, Accuracy: 46.623016357421875, Test Loss: 1.7183527946472168, Test Accuracy: 44.023807525634766\n",
      "Epoch 6, Loss: 1.6772583723068237, Accuracy: 49.345237731933594, Test Loss: 1.703692078590393, Test Accuracy: 44.88095474243164\n",
      "Epoch 7, Loss: 1.6558036804199219, Accuracy: 51.38888931274414, Test Loss: 1.6737486124038696, Test Accuracy: 48.54365158081055\n",
      "Epoch 8, Loss: 1.6331474781036377, Accuracy: 53.75396728515625, Test Loss: 1.6352380514144897, Test Accuracy: 53.011905670166016\n",
      "Epoch 9, Loss: 1.613310694694519, Accuracy: 55.7023811340332, Test Loss: 1.6029285192489624, Test Accuracy: 56.69047927856445\n",
      "Epoch 10, Loss: 1.5946143865585327, Accuracy: 57.46031951904297, Test Loss: 1.5929886102676392, Test Accuracy: 57.72222137451172\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "models = ['mlp','mlpbeta','cnn']\n",
    "\n",
    "for model in models:\n",
    "  print('Training ' + model)\n",
    "  # Train MLP\n",
    "  for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    if 'mlp' in model:\n",
    "      for x, y in trainmlp_ds:\n",
    "        # Train MLP\n",
    "        if model == 'mlp':\n",
    "          train_mlp(x, y)\n",
    "        # Train MLP Beta\n",
    "        elif model == 'mlpbeta':\n",
    "          train_mlpbeta(x,y)\n",
    "    else:\n",
    "      # Train CNN\n",
    "      for x, y in traincnn_ds:\n",
    "        train_cnn(x,y)\n",
    "\n",
    "    if 'mlp' in model:\n",
    "      for x_test, y_test in testmlp_ds:\n",
    "        # Train MLP\n",
    "        if model == 'mlp':\n",
    "          test_mlp(x_test, y_test)\n",
    "        # Train MLP Beta\n",
    "        elif model == 'mlpbeta':\n",
    "          test_mlpbeta(x_test, y_test)\n",
    "    else:\n",
    "      # Train CNN\n",
    "      for x_test, y_test in testcnn_ds:\n",
    "        test_cnn(x_test, y_test)\n",
    "\n",
    "    print(\n",
    "      f'Epoch {epoch + 1}, '\n",
    "      f'Loss: {train_loss.result()}, '\n",
    "      f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "      f'Test Loss: {test_loss.result()}, '\n",
    "      f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a3b9df806ffb9c99dfd499571232d2e3ccda8a03627b2b254cd16611a407c53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf-2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
