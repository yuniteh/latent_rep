{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import os\n",
    "import copy as cp\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from DL_utils import MLP, MLPbeta, CNN, eval_nn, train_mlp, test_mlp, train_mlpbeta, test_mlpbeta, train_cnn, test_cnn\n",
    "\n",
    "import process_data as prd\n",
    "from lda import train_lda, predict, eval_lda, eval_lda_ch\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'AB'\n",
    "with open('train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: traindata_manual/AB2_traindata_2.p\n"
     ]
    }
   ],
   "source": [
    "## Training \n",
    "sub = 2\n",
    "train_grp = 2\n",
    "n_train = 'fullallmix4'\n",
    "train_scale = 5\n",
    "cv_type = 'manual'\n",
    "scaler_load = False\n",
    "feat_type = 'mav'\n",
    "\n",
    "ind = (params[:,0] == sub) & (params[:,3] == train_grp)\n",
    "\n",
    "x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,sub_type,dt=cv_type,load=True,train_grp=train_grp)\n",
    "\n",
    "emg_scale = np.ones((np.size(x_train,1),1))\n",
    "for i in range(np.size(x_train,1)):\n",
    "    emg_scale[i] = 5/np.max(np.abs(x_train[:,i,:]))\n",
    "x_train = x_train*emg_scale\n",
    "x_valid = x_valid*emg_scale\n",
    "\n",
    "x_train_noise, x_train_clean, y_train_clean = prd.add_noise(x_train, p_train, sub, n_train, train_scale)\n",
    "x_valid_noise, x_valid_clean, y_valid_clean = prd.add_noise(x_valid, p_valid, sub, n_train, train_scale)\n",
    "\n",
    "# shuffle data to make even batches\n",
    "x_train_noise, x_train_clean, y_train_clean = shuffle(x_train_noise, x_train_clean, y_train_clean, random_state = 0)\n",
    "\n",
    "# Extract features\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_train_noise_cnn, scaler = prd.extract_scale(x_train_noise,scaler,scaler_load,ft=feat_type,emg_scale=emg_scale) \n",
    "x_valid_noise_cnn, _ = prd.extract_scale(x_valid_noise,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_train_noise_cnn = x_train_noise_cnn.astype('float32')\n",
    "x_valid_noise_cnn = x_valid_noise_cnn.astype('float32')\n",
    "\n",
    "# reshape data for nonconvolutional network\n",
    "x_train_noise_mlp = x_train_noise_cnn.reshape(x_train_noise_cnn.shape[0],-1)\n",
    "x_valid_noise_mlp = x_valid_noise_cnn.reshape(x_valid_noise_cnn.shape[0],-1)\n",
    "\n",
    "# create batches\n",
    "trainmlp_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_mlp, y_train_clean)).batch(128)\n",
    "testmlp_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_mlp, y_valid_clean)).batch(128)\n",
    "traincnn_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_cnn, y_train_clean)).batch(128)\n",
    "testcnn_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_cnn, y_valid_clean)).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "mlp_beta = MLPbeta()\n",
    "cnn = CNN()\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp\n",
      "Epoch 1, Loss: 1.9400993585586548, Accuracy: 16.297618865966797, Test Loss: 1.919284701347351, Test Accuracy: 18.174604415893555\n",
      "Epoch 2, Loss: 1.8843544721603394, Accuracy: 25.361112594604492, Test Loss: 1.8650637865066528, Test Accuracy: 27.841270446777344\n",
      "Epoch 3, Loss: 1.8406009674072266, Accuracy: 32.019840240478516, Test Loss: 1.822227954864502, Test Accuracy: 36.22222137451172\n",
      "Epoch 4, Loss: 1.7912793159484863, Accuracy: 38.2023811340332, Test Loss: 1.7810697555541992, Test Accuracy: 38.69841384887695\n",
      "Epoch 5, Loss: 1.755397915840149, Accuracy: 41.32143020629883, Test Loss: 1.7560169696807861, Test Accuracy: 40.71428298950195\n",
      "Epoch 6, Loss: 1.7384065389633179, Accuracy: 42.5396842956543, Test Loss: 1.7377867698669434, Test Accuracy: 42.14285659790039\n",
      "Epoch 7, Loss: 1.7273625135421753, Accuracy: 43.626983642578125, Test Loss: 1.728888988494873, Test Accuracy: 43.22222137451172\n",
      "Epoch 8, Loss: 1.7178070545196533, Accuracy: 44.69444274902344, Test Loss: 1.723215937614441, Test Accuracy: 43.380950927734375\n",
      "Epoch 9, Loss: 1.70975923538208, Accuracy: 45.488094329833984, Test Loss: 1.7061687707901, Test Accuracy: 45.730159759521484\n",
      "Epoch 10, Loss: 1.702990174293518, Accuracy: 46.05555725097656, Test Loss: 1.6992803812026978, Test Accuracy: 46.20634841918945\n",
      "Epoch 11, Loss: 1.6965080499649048, Accuracy: 46.773807525634766, Test Loss: 1.6980807781219482, Test Accuracy: 46.33333206176758\n",
      "Epoch 12, Loss: 1.6898057460784912, Accuracy: 47.55952453613281, Test Loss: 1.6932177543640137, Test Accuracy: 47.269840240478516\n",
      "Epoch 13, Loss: 1.6828049421310425, Accuracy: 48.20634841918945, Test Loss: 1.6938740015029907, Test Accuracy: 47.06349182128906\n",
      "Epoch 14, Loss: 1.6759743690490723, Accuracy: 48.82936477661133, Test Loss: 1.6892493963241577, Test Accuracy: 47.587303161621094\n",
      "Epoch 15, Loss: 1.668727159500122, Accuracy: 49.662696838378906, Test Loss: 1.6925857067108154, Test Accuracy: 46.77777862548828\n",
      "Epoch 16, Loss: 1.6628191471099854, Accuracy: 50.38888931274414, Test Loss: 1.6871997117996216, Test Accuracy: 47.57143020629883\n",
      "Epoch 17, Loss: 1.6592991352081299, Accuracy: 50.7103157043457, Test Loss: 1.6856876611709595, Test Accuracy: 47.36507797241211\n",
      "Epoch 18, Loss: 1.6563042402267456, Accuracy: 50.94444274902344, Test Loss: 1.6832075119018555, Test Accuracy: 47.269840240478516\n",
      "Epoch 19, Loss: 1.6538341045379639, Accuracy: 51.123016357421875, Test Loss: 1.6855320930480957, Test Accuracy: 47.23809814453125\n",
      "Epoch 20, Loss: 1.6520664691925049, Accuracy: 51.341270446777344, Test Loss: 1.6862289905548096, Test Accuracy: 47.0\n",
      "Epoch 21, Loss: 1.6504895687103271, Accuracy: 51.519840240478516, Test Loss: 1.694597601890564, Test Accuracy: 46.126983642578125\n",
      "Epoch 22, Loss: 1.6487199068069458, Accuracy: 51.634918212890625, Test Loss: 1.6882728338241577, Test Accuracy: 46.761905670166016\n",
      "Epoch 23, Loss: 1.647698163986206, Accuracy: 51.63888931274414, Test Loss: 1.6906646490097046, Test Accuracy: 46.68254089355469\n",
      "Epoch 24, Loss: 1.6459479331970215, Accuracy: 51.892860412597656, Test Loss: 1.685523271560669, Test Accuracy: 47.4444465637207\n",
      "Epoch 25, Loss: 1.645033359527588, Accuracy: 52.00396728515625, Test Loss: 1.6857742071151733, Test Accuracy: 47.349205017089844\n",
      "Epoch 26, Loss: 1.6439013481140137, Accuracy: 52.17063522338867, Test Loss: 1.6805499792099, Test Accuracy: 47.79365158081055\n",
      "Epoch 27, Loss: 1.6424716711044312, Accuracy: 52.32539749145508, Test Loss: 1.6774725914001465, Test Accuracy: 47.96825408935547\n",
      "Epoch 28, Loss: 1.6411008834838867, Accuracy: 52.44841003417969, Test Loss: 1.678432822227478, Test Accuracy: 47.77777862548828\n",
      "Epoch 29, Loss: 1.6395341157913208, Accuracy: 52.591270446777344, Test Loss: 1.6821240186691284, Test Accuracy: 47.63492202758789\n",
      "Epoch 30, Loss: 1.6389554738998413, Accuracy: 52.658729553222656, Test Loss: 1.6806151866912842, Test Accuracy: 47.55555725097656\n",
      "Epoch 31, Loss: 1.6373385190963745, Accuracy: 52.77381134033203, Test Loss: 1.6848944425582886, Test Accuracy: 47.0476188659668\n",
      "Epoch 32, Loss: 1.636194109916687, Accuracy: 52.84920883178711, Test Loss: 1.68233323097229, Test Accuracy: 47.47618865966797\n",
      "Epoch 33, Loss: 1.634753704071045, Accuracy: 53.091270446777344, Test Loss: 1.6795358657836914, Test Accuracy: 47.69841003417969\n",
      "Epoch 34, Loss: 1.6338231563568115, Accuracy: 53.22222137451172, Test Loss: 1.681372046470642, Test Accuracy: 47.63492202758789\n",
      "Epoch 35, Loss: 1.632622480392456, Accuracy: 53.20634841918945, Test Loss: 1.6811721324920654, Test Accuracy: 47.666664123535156\n",
      "Epoch 36, Loss: 1.632011890411377, Accuracy: 53.29762268066406, Test Loss: 1.684181571006775, Test Accuracy: 47.31745910644531\n",
      "Epoch 37, Loss: 1.6309236288070679, Accuracy: 53.35714340209961, Test Loss: 1.6797350645065308, Test Accuracy: 47.650794982910156\n",
      "Epoch 38, Loss: 1.6304341554641724, Accuracy: 53.36111068725586, Test Loss: 1.683718204498291, Test Accuracy: 47.30158615112305\n",
      "Epoch 39, Loss: 1.6295413970947266, Accuracy: 53.57936477661133, Test Loss: 1.6880656480789185, Test Accuracy: 46.873016357421875\n",
      "Epoch 40, Loss: 1.629092812538147, Accuracy: 53.670631408691406, Test Loss: 1.6868470907211304, Test Accuracy: 46.96825408935547\n",
      "Epoch 41, Loss: 1.6286481618881226, Accuracy: 53.591270446777344, Test Loss: 1.6811621189117432, Test Accuracy: 47.47618865966797\n",
      "Epoch 42, Loss: 1.6292797327041626, Accuracy: 53.57936477661133, Test Loss: 1.679656982421875, Test Accuracy: 47.730159759521484\n",
      "Epoch 43, Loss: 1.6276023387908936, Accuracy: 53.71428680419922, Test Loss: 1.6805452108383179, Test Accuracy: 47.873016357421875\n",
      "Epoch 44, Loss: 1.6272157430648804, Accuracy: 53.845237731933594, Test Loss: 1.6811937093734741, Test Accuracy: 47.619049072265625\n",
      "Epoch 45, Loss: 1.6266682147979736, Accuracy: 53.82936477661133, Test Loss: 1.6825944185256958, Test Accuracy: 47.523807525634766\n",
      "Epoch 46, Loss: 1.626347541809082, Accuracy: 53.888885498046875, Test Loss: 1.6778641939163208, Test Accuracy: 47.82539749145508\n",
      "Epoch 47, Loss: 1.625658392906189, Accuracy: 53.920631408691406, Test Loss: 1.6829595565795898, Test Accuracy: 47.47618865966797\n",
      "Epoch 48, Loss: 1.626410961151123, Accuracy: 53.78174591064453, Test Loss: 1.681215763092041, Test Accuracy: 47.492061614990234\n",
      "Epoch 49, Loss: 1.625928282737732, Accuracy: 53.89285659790039, Test Loss: 1.680930495262146, Test Accuracy: 47.5079345703125\n",
      "Epoch 50, Loss: 1.6252580881118774, Accuracy: 53.90475845336914, Test Loss: 1.6805611848831177, Test Accuracy: 47.492061614990234\n",
      "Epoch 51, Loss: 1.625138521194458, Accuracy: 54.01587677001953, Test Loss: 1.6824159622192383, Test Accuracy: 47.46031951904297\n",
      "Epoch 52, Loss: 1.6243840456008911, Accuracy: 54.00396728515625, Test Loss: 1.6885850429534912, Test Accuracy: 46.82539749145508\n",
      "Epoch 53, Loss: 1.6247044801712036, Accuracy: 53.94841384887695, Test Loss: 1.6845394372940063, Test Accuracy: 47.11111068725586\n",
      "Epoch 54, Loss: 1.6239148378372192, Accuracy: 54.12301254272461, Test Loss: 1.6852200031280518, Test Accuracy: 47.0\n",
      "Epoch 55, Loss: 1.6233395338058472, Accuracy: 54.138885498046875, Test Loss: 1.6896287202835083, Test Accuracy: 46.85714340209961\n",
      "Epoch 56, Loss: 1.6237457990646362, Accuracy: 54.095237731933594, Test Loss: 1.6910241842269897, Test Accuracy: 46.63492202758789\n",
      "Epoch 57, Loss: 1.623742699623108, Accuracy: 54.11111068725586, Test Loss: 1.6872782707214355, Test Accuracy: 46.88888931274414\n",
      "Epoch 58, Loss: 1.623284935951233, Accuracy: 54.19444274902344, Test Loss: 1.6926919221878052, Test Accuracy: 46.39682388305664\n",
      "Epoch 59, Loss: 1.6226097345352173, Accuracy: 54.238094329833984, Test Loss: 1.698501467704773, Test Accuracy: 45.904762268066406\n",
      "Epoch 60, Loss: 1.623220682144165, Accuracy: 54.09920883178711, Test Loss: 1.6925712823867798, Test Accuracy: 46.36507797241211\n",
      "Training mlpbeta\n",
      "Epoch 1, Loss: 1.8479316234588623, Accuracy: 30.21428680419922, Test Loss: 1.79298996925354, Test Accuracy: 35.666664123535156\n",
      "Epoch 2, Loss: 1.7282663583755493, Accuracy: 43.46428680419922, Test Loss: 1.7534867525100708, Test Accuracy: 41.23809814453125\n",
      "Epoch 3, Loss: 1.6965080499649048, Accuracy: 46.80952453613281, Test Loss: 1.7280840873718262, Test Accuracy: 43.33333206176758\n",
      "Epoch 4, Loss: 1.6781502962112427, Accuracy: 48.65873336791992, Test Loss: 1.7130852937698364, Test Accuracy: 44.587303161621094\n",
      "Epoch 5, Loss: 1.668340802192688, Accuracy: 49.5476188659668, Test Loss: 1.7048355340957642, Test Accuracy: 44.873016357421875\n",
      "Epoch 6, Loss: 1.6607362031936646, Accuracy: 50.349205017089844, Test Loss: 1.7050285339355469, Test Accuracy: 45.22222137451172\n",
      "Epoch 7, Loss: 1.6491286754608154, Accuracy: 51.67857360839844, Test Loss: 1.683537483215332, Test Accuracy: 47.30158615112305\n",
      "Epoch 8, Loss: 1.6371970176696777, Accuracy: 52.77381134033203, Test Loss: 1.6831002235412598, Test Accuracy: 47.349205017089844\n",
      "Epoch 9, Loss: 1.6281794309616089, Accuracy: 53.72222137451172, Test Loss: 1.6710312366485596, Test Accuracy: 49.269840240478516\n",
      "Epoch 10, Loss: 1.6243767738342285, Accuracy: 54.09920883178711, Test Loss: 1.6768101453781128, Test Accuracy: 48.25396728515625\n",
      "Epoch 11, Loss: 1.620038628578186, Accuracy: 54.34920883178711, Test Loss: 1.674665093421936, Test Accuracy: 48.68254089355469\n",
      "Epoch 12, Loss: 1.6151502132415771, Accuracy: 54.984127044677734, Test Loss: 1.6742914915084839, Test Accuracy: 48.365081787109375\n",
      "Epoch 13, Loss: 1.6071856021881104, Accuracy: 55.67856979370117, Test Loss: 1.6589255332946777, Test Accuracy: 50.095237731933594\n",
      "Epoch 14, Loss: 1.5993478298187256, Accuracy: 56.46825408935547, Test Loss: 1.6519596576690674, Test Accuracy: 50.650794982910156\n",
      "Epoch 15, Loss: 1.5943721532821655, Accuracy: 56.93650817871094, Test Loss: 1.6383622884750366, Test Accuracy: 52.06349563598633\n",
      "Epoch 16, Loss: 1.5887126922607422, Accuracy: 57.56745910644531, Test Loss: 1.629370093345642, Test Accuracy: 52.71428680419922\n",
      "Epoch 17, Loss: 1.5836503505706787, Accuracy: 58.103172302246094, Test Loss: 1.6289153099060059, Test Accuracy: 52.85714340209961\n",
      "Epoch 18, Loss: 1.5854519605636597, Accuracy: 57.880950927734375, Test Loss: 1.6200323104858398, Test Accuracy: 53.968257904052734\n",
      "Epoch 19, Loss: 1.5817348957061768, Accuracy: 58.14682388305664, Test Loss: 1.6220072507858276, Test Accuracy: 53.57142639160156\n",
      "Epoch 20, Loss: 1.5786082744598389, Accuracy: 58.5396842956543, Test Loss: 1.628953456878662, Test Accuracy: 53.04762268066406\n",
      "Epoch 21, Loss: 1.5758862495422363, Accuracy: 58.91270065307617, Test Loss: 1.630902886390686, Test Accuracy: 52.761905670166016\n",
      "Epoch 22, Loss: 1.574293851852417, Accuracy: 58.9444465637207, Test Loss: 1.6210659742355347, Test Accuracy: 54.07936477661133\n",
      "Epoch 23, Loss: 1.5733739137649536, Accuracy: 59.18650817871094, Test Loss: 1.6299625635147095, Test Accuracy: 52.999996185302734\n",
      "Epoch 24, Loss: 1.5716941356658936, Accuracy: 59.19841384887695, Test Loss: 1.6284490823745728, Test Accuracy: 53.158729553222656\n",
      "Epoch 25, Loss: 1.5711344480514526, Accuracy: 59.249996185302734, Test Loss: 1.6264746189117432, Test Accuracy: 53.46031951904297\n",
      "Epoch 26, Loss: 1.5713274478912354, Accuracy: 59.30158615112305, Test Loss: 1.6235709190368652, Test Accuracy: 53.58729934692383\n",
      "Epoch 27, Loss: 1.5677858591079712, Accuracy: 59.68254089355469, Test Loss: 1.6208888292312622, Test Accuracy: 54.19047546386719\n",
      "Epoch 28, Loss: 1.5636168718338013, Accuracy: 60.11111068725586, Test Loss: 1.6178044080734253, Test Accuracy: 54.0476188659668\n",
      "Epoch 29, Loss: 1.5624351501464844, Accuracy: 60.0555534362793, Test Loss: 1.6147944927215576, Test Accuracy: 54.396827697753906\n",
      "Epoch 30, Loss: 1.5594905614852905, Accuracy: 60.468257904052734, Test Loss: 1.6205763816833496, Test Accuracy: 53.888885498046875\n",
      "Epoch 31, Loss: 1.5595780611038208, Accuracy: 60.44444274902344, Test Loss: 1.626327395439148, Test Accuracy: 53.31745910644531\n",
      "Epoch 32, Loss: 1.5565717220306396, Accuracy: 60.71428680419922, Test Loss: 1.6126278638839722, Test Accuracy: 54.619049072265625\n",
      "Epoch 33, Loss: 1.5486565828323364, Accuracy: 61.57143020629883, Test Loss: 1.6091312170028687, Test Accuracy: 55.0476188659668\n",
      "Epoch 34, Loss: 1.5470679998397827, Accuracy: 61.7103157043457, Test Loss: 1.6065837144851685, Test Accuracy: 55.333335876464844\n",
      "Epoch 35, Loss: 1.5419141054153442, Accuracy: 62.17856979370117, Test Loss: 1.6052166223526, Test Accuracy: 55.349205017089844\n",
      "Epoch 36, Loss: 1.535402536392212, Accuracy: 62.900794982910156, Test Loss: 1.599481463432312, Test Accuracy: 56.015872955322266\n",
      "Epoch 37, Loss: 1.5305057764053345, Accuracy: 63.507938385009766, Test Loss: 1.594335675239563, Test Accuracy: 56.5396842956543\n",
      "Epoch 38, Loss: 1.5319936275482178, Accuracy: 63.28174591064453, Test Loss: 1.589216947555542, Test Accuracy: 57.03174591064453\n",
      "Epoch 39, Loss: 1.529220700263977, Accuracy: 63.44841003417969, Test Loss: 1.5867087841033936, Test Accuracy: 57.42856979370117\n",
      "Epoch 40, Loss: 1.5265228748321533, Accuracy: 63.80555725097656, Test Loss: 1.587743878364563, Test Accuracy: 57.33333206176758\n",
      "Epoch 41, Loss: 1.525277853012085, Accuracy: 63.96428298950195, Test Loss: 1.5813820362091064, Test Accuracy: 58.09524154663086\n",
      "Epoch 42, Loss: 1.5213851928710938, Accuracy: 64.41666412353516, Test Loss: 1.5712658166885376, Test Accuracy: 58.9682502746582\n",
      "Epoch 43, Loss: 1.5198596715927124, Accuracy: 64.39682006835938, Test Loss: 1.5787086486816406, Test Accuracy: 58.238094329833984\n",
      "Epoch 44, Loss: 1.5119234323501587, Accuracy: 65.25, Test Loss: 1.5801138877868652, Test Accuracy: 58.0\n",
      "Epoch 45, Loss: 1.512075662612915, Accuracy: 65.19444274902344, Test Loss: 1.5751991271972656, Test Accuracy: 58.761905670166016\n",
      "Epoch 46, Loss: 1.5105646848678589, Accuracy: 65.36508178710938, Test Loss: 1.5733532905578613, Test Accuracy: 59.11111068725586\n",
      "Epoch 47, Loss: 1.507889986038208, Accuracy: 65.63491821289062, Test Loss: 1.5723038911819458, Test Accuracy: 58.82539749145508\n",
      "Epoch 48, Loss: 1.5056145191192627, Accuracy: 65.9126968383789, Test Loss: 1.5730719566345215, Test Accuracy: 58.603172302246094\n",
      "Epoch 49, Loss: 1.5064222812652588, Accuracy: 65.9206314086914, Test Loss: 1.5778552293777466, Test Accuracy: 58.158729553222656\n",
      "Epoch 50, Loss: 1.5038939714431763, Accuracy: 66.11111450195312, Test Loss: 1.5698846578598022, Test Accuracy: 59.079368591308594\n",
      "Epoch 51, Loss: 1.5046000480651855, Accuracy: 66.0, Test Loss: 1.5769413709640503, Test Accuracy: 58.42857360839844\n",
      "Epoch 52, Loss: 1.5012290477752686, Accuracy: 66.34920501708984, Test Loss: 1.5590182542800903, Test Accuracy: 60.095237731933594\n",
      "Epoch 53, Loss: 1.4996232986450195, Accuracy: 66.5079345703125, Test Loss: 1.5711472034454346, Test Accuracy: 58.58729934692383\n",
      "Epoch 54, Loss: 1.4988728761672974, Accuracy: 66.59920501708984, Test Loss: 1.5703740119934082, Test Accuracy: 58.80952453613281\n",
      "Epoch 55, Loss: 1.4996063709259033, Accuracy: 66.4047622680664, Test Loss: 1.5677298307418823, Test Accuracy: 59.25396728515625\n",
      "Epoch 56, Loss: 1.4956640005111694, Accuracy: 66.90079498291016, Test Loss: 1.5713772773742676, Test Accuracy: 58.79365158081055\n",
      "Epoch 57, Loss: 1.4959571361541748, Accuracy: 66.80158996582031, Test Loss: 1.5631152391433716, Test Accuracy: 59.730159759521484\n",
      "Epoch 58, Loss: 1.493115782737732, Accuracy: 67.16667175292969, Test Loss: 1.569283127784729, Test Accuracy: 59.0317497253418\n",
      "Epoch 59, Loss: 1.490578293800354, Accuracy: 67.42063903808594, Test Loss: 1.5688085556030273, Test Accuracy: 59.158729553222656\n",
      "Epoch 60, Loss: 1.4940606355667114, Accuracy: 67.07539367675781, Test Loss: 1.5634132623672485, Test Accuracy: 59.79365158081055\n",
      "Training cnn\n",
      "Epoch 1, Loss: 1.8205970525741577, Accuracy: 32.74603271484375, Test Loss: 1.6964936256408691, Test Accuracy: 46.63492202758789\n",
      "Epoch 2, Loss: 1.6551377773284912, Accuracy: 51.36507797241211, Test Loss: 1.6259857416152954, Test Accuracy: 53.90475845336914\n",
      "Epoch 3, Loss: 1.610402226448059, Accuracy: 55.722225189208984, Test Loss: 1.6029269695281982, Test Accuracy: 55.79364776611328\n",
      "Epoch 4, Loss: 1.593875765800476, Accuracy: 57.0476188659668, Test Loss: 1.5886155366897583, Test Accuracy: 57.39682388305664\n",
      "Epoch 5, Loss: 1.583003044128418, Accuracy: 58.14682388305664, Test Loss: 1.5769870281219482, Test Accuracy: 58.74603271484375\n",
      "Epoch 6, Loss: 1.5726213455200195, Accuracy: 59.32142639160156, Test Loss: 1.5809215307235718, Test Accuracy: 57.984127044677734\n",
      "Epoch 7, Loss: 1.5519452095031738, Accuracy: 61.39682388305664, Test Loss: 1.567820429801941, Test Accuracy: 59.06349563598633\n",
      "Epoch 8, Loss: 1.5383294820785522, Accuracy: 62.80158615112305, Test Loss: 1.5604956150054932, Test Accuracy: 59.873016357421875\n",
      "Epoch 9, Loss: 1.5305546522140503, Accuracy: 63.599205017089844, Test Loss: 1.5494579076766968, Test Accuracy: 61.17460250854492\n",
      "Epoch 10, Loss: 1.5246562957763672, Accuracy: 64.1706314086914, Test Loss: 1.5420318841934204, Test Accuracy: 62.03174591064453\n",
      "Epoch 11, Loss: 1.5213356018066406, Accuracy: 64.4206314086914, Test Loss: 1.5401062965393066, Test Accuracy: 62.0476188659668\n",
      "Epoch 12, Loss: 1.5172719955444336, Accuracy: 64.88888549804688, Test Loss: 1.5385018587112427, Test Accuracy: 61.984127044677734\n",
      "Epoch 13, Loss: 1.5133931636810303, Accuracy: 65.18253326416016, Test Loss: 1.5361140966415405, Test Accuracy: 62.26984405517578\n",
      "Epoch 14, Loss: 1.510713815689087, Accuracy: 65.51587677001953, Test Loss: 1.5334323644638062, Test Accuracy: 62.30158996582031\n",
      "Epoch 15, Loss: 1.5077431201934814, Accuracy: 65.8531723022461, Test Loss: 1.531959891319275, Test Accuracy: 62.85714340209961\n",
      "Epoch 16, Loss: 1.505398154258728, Accuracy: 66.12301635742188, Test Loss: 1.528620719909668, Test Accuracy: 63.349205017089844\n",
      "Epoch 17, Loss: 1.5033793449401855, Accuracy: 66.42459869384766, Test Loss: 1.5267921686172485, Test Accuracy: 63.222225189208984\n",
      "Epoch 18, Loss: 1.5014824867248535, Accuracy: 66.5, Test Loss: 1.525681734085083, Test Accuracy: 63.269840240478516\n",
      "Epoch 19, Loss: 1.4995676279067993, Accuracy: 66.72618865966797, Test Loss: 1.5290991067886353, Test Accuracy: 63.0476188659668\n",
      "Epoch 20, Loss: 1.4985460042953491, Accuracy: 66.81349182128906, Test Loss: 1.528944969177246, Test Accuracy: 63.015872955322266\n",
      "Epoch 21, Loss: 1.4961968660354614, Accuracy: 66.95634460449219, Test Loss: 1.5221208333969116, Test Accuracy: 63.841270446777344\n",
      "Epoch 22, Loss: 1.4939364194869995, Accuracy: 67.20634460449219, Test Loss: 1.521616816520691, Test Accuracy: 64.03174591064453\n",
      "Epoch 23, Loss: 1.4935051202774048, Accuracy: 67.16667175292969, Test Loss: 1.5190637111663818, Test Accuracy: 64.03174591064453\n",
      "Epoch 24, Loss: 1.492576003074646, Accuracy: 67.28968048095703, Test Loss: 1.5282565355300903, Test Accuracy: 62.841270446777344\n",
      "Epoch 25, Loss: 1.4905742406845093, Accuracy: 67.5079345703125, Test Loss: 1.5226833820343018, Test Accuracy: 63.841270446777344\n",
      "Epoch 26, Loss: 1.4899766445159912, Accuracy: 67.51587677001953, Test Loss: 1.5247790813446045, Test Accuracy: 63.39682388305664\n",
      "Epoch 27, Loss: 1.4887590408325195, Accuracy: 67.59127044677734, Test Loss: 1.5144423246383667, Test Accuracy: 64.36507415771484\n",
      "Epoch 28, Loss: 1.4875481128692627, Accuracy: 67.67063903808594, Test Loss: 1.5202029943466187, Test Accuracy: 63.77777862548828\n",
      "Epoch 29, Loss: 1.4867171049118042, Accuracy: 67.84127044677734, Test Loss: 1.5148608684539795, Test Accuracy: 64.17460632324219\n",
      "Epoch 30, Loss: 1.4851146936416626, Accuracy: 68.03571319580078, Test Loss: 1.5303202867507935, Test Accuracy: 63.111106872558594\n",
      "Epoch 31, Loss: 1.4850728511810303, Accuracy: 67.99603271484375, Test Loss: 1.5230278968811035, Test Accuracy: 63.69841003417969\n",
      "Epoch 32, Loss: 1.4832193851470947, Accuracy: 68.19444274902344, Test Loss: 1.5146440267562866, Test Accuracy: 64.53968048095703\n",
      "Epoch 33, Loss: 1.4817044734954834, Accuracy: 68.28571319580078, Test Loss: 1.518212080001831, Test Accuracy: 64.19047546386719\n",
      "Epoch 34, Loss: 1.4795432090759277, Accuracy: 68.61508178710938, Test Loss: 1.5157761573791504, Test Accuracy: 64.30158996582031\n",
      "Epoch 35, Loss: 1.4777034521102905, Accuracy: 68.80158996582031, Test Loss: 1.5218347311019897, Test Accuracy: 63.476192474365234\n",
      "Epoch 36, Loss: 1.4782270193099976, Accuracy: 68.734130859375, Test Loss: 1.516655445098877, Test Accuracy: 64.47618865966797\n",
      "Epoch 37, Loss: 1.476994276046753, Accuracy: 68.8452377319336, Test Loss: 1.524524211883545, Test Accuracy: 63.349205017089844\n",
      "Epoch 38, Loss: 1.4755809307098389, Accuracy: 68.93650817871094, Test Loss: 1.516068935394287, Test Accuracy: 64.31745910644531\n",
      "Epoch 39, Loss: 1.4751986265182495, Accuracy: 69.0, Test Loss: 1.515860915184021, Test Accuracy: 64.41270446777344\n",
      "Epoch 40, Loss: 1.4737073183059692, Accuracy: 69.20635223388672, Test Loss: 1.5186963081359863, Test Accuracy: 64.19047546386719\n",
      "Epoch 41, Loss: 1.473687767982483, Accuracy: 69.15079498291016, Test Loss: 1.520444631576538, Test Accuracy: 63.841270446777344\n",
      "Epoch 42, Loss: 1.4724414348602295, Accuracy: 69.27777862548828, Test Loss: 1.5138555765151978, Test Accuracy: 64.63491821289062\n",
      "Epoch 43, Loss: 1.4721038341522217, Accuracy: 69.31745910644531, Test Loss: 1.5185880661010742, Test Accuracy: 64.14286041259766\n",
      "Epoch 44, Loss: 1.4738836288452148, Accuracy: 69.06745910644531, Test Loss: 1.5169764757156372, Test Accuracy: 64.47618865966797\n",
      "Epoch 45, Loss: 1.4702550172805786, Accuracy: 69.56745910644531, Test Loss: 1.5143418312072754, Test Accuracy: 64.66666412353516\n",
      "Epoch 46, Loss: 1.4715627431869507, Accuracy: 69.23015594482422, Test Loss: 1.5158103704452515, Test Accuracy: 64.61904907226562\n",
      "Epoch 47, Loss: 1.4699143171310425, Accuracy: 69.45237731933594, Test Loss: 1.516015887260437, Test Accuracy: 64.4920654296875\n",
      "Epoch 48, Loss: 1.4698936939239502, Accuracy: 69.6111068725586, Test Loss: 1.5123765468597412, Test Accuracy: 64.79365539550781\n",
      "Epoch 49, Loss: 1.4683470726013184, Accuracy: 69.69444274902344, Test Loss: 1.514603614807129, Test Accuracy: 64.52381134033203\n",
      "Epoch 50, Loss: 1.4680800437927246, Accuracy: 69.69444274902344, Test Loss: 1.5119434595108032, Test Accuracy: 64.87301635742188\n",
      "Epoch 51, Loss: 1.4680440425872803, Accuracy: 69.77381134033203, Test Loss: 1.515863299369812, Test Accuracy: 64.46031951904297\n",
      "Epoch 52, Loss: 1.467574119567871, Accuracy: 69.78174591064453, Test Loss: 1.5122812986373901, Test Accuracy: 64.84127044677734\n",
      "Epoch 53, Loss: 1.4660099744796753, Accuracy: 69.82936096191406, Test Loss: 1.5117307901382446, Test Accuracy: 64.73016357421875\n",
      "Epoch 54, Loss: 1.465410828590393, Accuracy: 69.95635223388672, Test Loss: 1.5092860460281372, Test Accuracy: 65.0\n",
      "Epoch 55, Loss: 1.465101718902588, Accuracy: 70.04365539550781, Test Loss: 1.5057181119918823, Test Accuracy: 65.57142639160156\n",
      "Epoch 56, Loss: 1.4653340578079224, Accuracy: 69.98015594482422, Test Loss: 1.5125902891159058, Test Accuracy: 64.88888549804688\n",
      "Epoch 57, Loss: 1.4636436700820923, Accuracy: 70.22222137451172, Test Loss: 1.5129601955413818, Test Accuracy: 64.76190948486328\n",
      "Epoch 58, Loss: 1.4652886390686035, Accuracy: 69.97222137451172, Test Loss: 1.515792965888977, Test Accuracy: 64.42857360839844\n",
      "Epoch 59, Loss: 1.464941382408142, Accuracy: 70.04761505126953, Test Loss: 1.5106358528137207, Test Accuracy: 64.93650817871094\n",
      "Epoch 60, Loss: 1.4630436897277832, Accuracy: 70.19841003417969, Test Loss: 1.5157885551452637, Test Accuracy: 64.26984405517578\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 60\n",
    "models = ['mlp','mlpbeta','cnn']\n",
    "\n",
    "for model in models:\n",
    "    print('Training ' + model)\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "\n",
    "        # Train MLP\n",
    "        if model == 'mlp':\n",
    "            for x, y in trainmlp_ds:\n",
    "                train_mlp(x, y, mlp, loss_fn, optimizer, train_loss, train_accuracy)\n",
    "            for x_test, y_test in testmlp_ds:\n",
    "                test_mlp(x_test, y_test, mlp, loss_fn, test_loss, test_accuracy)\n",
    "        # Train MLP Beta\n",
    "        elif model == 'mlpbeta':\n",
    "            for x, y in trainmlp_ds:\n",
    "                train_mlpbeta(x, y, mlp_beta, loss_fn, optimizer, train_loss, train_accuracy)\n",
    "            for x_test, y_test in testmlp_ds:\n",
    "                test_mlpbeta(x_test, y_test, mlp_beta, loss_fn, test_loss, test_accuracy)\n",
    "        # Train CNN\n",
    "        elif model == 'cnn':\n",
    "            for x, y in traincnn_ds:\n",
    "                train_cnn(x, y, cnn, loss_fn, optimizer, train_loss, train_accuracy)\n",
    "            for x_test, y_test in testcnn_ds:\n",
    "                test_cnn(x_test, y_test, cnn, loss_fn, test_loss, test_accuracy)\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}, '\n",
    "            f'Loss: {train_loss.result()}, '\n",
    "            f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "            f'Test Loss: {test_loss.result()}, '\n",
    "            f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_enc = mlp.get_layer(name='enc')\n",
    "mlpbeta_enc = mlp_beta.get_layer(name='enc')\n",
    "cnn_enc = cnn.get_layer(name='enc')\n",
    "\n",
    "mlp_aligned = mlp_enc(x_train_noise_mlp).numpy()\n",
    "mlp_beta_aligned = mlpbeta_enc(x_train_noise_mlp).numpy()\n",
    "cnn_aligned = cnn_enc(x_train_noise_cnn).numpy()\n",
    "\n",
    "y_train_aligned = np.argmax(y_train_clean, axis=1)[...,np.newaxis]\n",
    "w_mlp, c_mlp,_, _, _ = train_lda(mlp_aligned,y_train_aligned)\n",
    "w_mlpbeta, c_mlpbeta,_, _, _ = train_lda(mlp_beta_aligned,y_train_aligned)\n",
    "w_cnn, c_cnn,_, _, _ = train_lda(cnn_aligned,y_train_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: traindata_manual/AB2_traindata_4.p\n",
      "MLP ---- Clean Accuracy: 76.31, Noisy Accuracy: 61.20, LDA Clean Accuracy: 73.74, LDA Noisy Accuracy: 60.20\n",
      "MLPB ---- Clean Accuracy: 84.40, Noisy Accuracy: 62.06, LDA Clean Accuracy: 86.57, LDA Noisy Accuracy: 59.66\n",
      "CNN ---- Clean Accuracy: 86.03, Noisy Accuracy: 66.46, LDA Clean Accuracy: 88.00, LDA Noisy Accuracy: 63.97\n"
     ]
    }
   ],
   "source": [
    "test_grp = 4\n",
    "cv_type = 'manual'\n",
    "n_test = 'partposrealmixeven24'\n",
    "\n",
    "with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "    real_noise_temp, _ = pickle.load(f)\n",
    "\n",
    "_, x_test, _, _, p_test, _ = prd.train_data_split(raw,params,sub,sub_type,dt=cv_type,train_grp=test_grp)\n",
    "clean_size = int(np.size(x_test,axis=0))\n",
    "x_test = x_test*emg_scale\n",
    "\n",
    "x_test_noise, x_test_clean, y_test_clean = prd.add_noise(x_test, p_test, sub, n_test, 1, real_noise=real_noise_temp, emg_scale = emg_scale)\n",
    "x_test_cnn, _ = prd.extract_scale(x_test_noise,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_test_cnn = x_test_cnn.astype('float32')\n",
    "x_test_mlp = x_test_cnn.reshape(x_test_cnn.shape[0],-1)\n",
    "\n",
    "mlp_test_aligned = mlp_enc(x_test_mlp).numpy()\n",
    "mlpbeta_test_aligned = mlpbeta_enc(x_test_mlp).numpy()\n",
    "cnn_test_aligned = cnn_enc(x_test_cnn).numpy()\n",
    "y_test_aligned = np.argmax(y_test_clean, axis=1)[...,np.newaxis]\n",
    "\n",
    "clean_acc, noisy_acc = eval_nn(x_test_mlp, y_test_clean,mlp,clean_size)\n",
    "clean_lda = eval_lda(w_mlp,c_mlp,mlp_test_aligned[:clean_size,...],y_test_aligned[:clean_size,...])\n",
    "noisy_lda = eval_lda(w_mlp,c_mlp,mlp_test_aligned[clean_size:,...],y_test_aligned[clean_size:,...])\n",
    "print(\n",
    "    f'MLP ---- '\n",
    "    f'Clean Accuracy: {clean_acc * 100:.2f}, '\n",
    "    f'Noisy Accuracy: {noisy_acc * 100:.2f}, '\n",
    "    f'LDA Clean Accuracy: {clean_lda * 100:.2f}, '\n",
    "    f'LDA Noisy Accuracy: {noisy_lda * 100:.2f}'\n",
    ")\n",
    "\n",
    "clean_acc, noisy_acc = eval_nn(x_test_mlp, y_test_clean,mlp_beta,clean_size)\n",
    "clean_lda = eval_lda(w_mlpbeta,c_mlpbeta,mlpbeta_test_aligned[:clean_size,...],y_test_aligned[:clean_size,...])\n",
    "noisy_lda = eval_lda(w_mlpbeta,c_mlpbeta,mlpbeta_test_aligned[clean_size:,...],y_test_aligned[clean_size:,...])\n",
    "print(\n",
    "    f'MLPB ---- '\n",
    "    f'Clean Accuracy: {clean_acc * 100:.2f}, '\n",
    "    f'Noisy Accuracy: {noisy_acc * 100:.2f}, '\n",
    "    f'LDA Clean Accuracy: {clean_lda * 100:.2f}, '\n",
    "    f'LDA Noisy Accuracy: {noisy_lda * 100:.2f}'\n",
    ")\n",
    "\n",
    "clean_acc, noisy_acc = eval_nn(x_test_cnn, y_test_clean,cnn,clean_size)\n",
    "clean_lda = eval_lda(w_cnn,c_cnn,cnn_test_aligned[:clean_size,...],y_test_aligned[:clean_size,...])\n",
    "noisy_lda = eval_lda(w_cnn,c_cnn,cnn_test_aligned[clean_size:,...],y_test_aligned[clean_size:,...])\n",
    "print(\n",
    "    f'CNN ---- '\n",
    "    f'Clean Accuracy: {clean_acc * 100:.2f}, '\n",
    "    f'Noisy Accuracy: {noisy_acc * 100:.2f}, '\n",
    "    f'LDA Clean Accuracy: {clean_lda * 100:.2f}, '\n",
    "    f'LDA Noisy Accuracy: {noisy_lda * 100:.2f}'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a3b9df806ffb9c99dfd499571232d2e3ccda8a03627b2b254cd16611a407c53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf-2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
