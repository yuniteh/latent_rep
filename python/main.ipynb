{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import os\n",
    "import copy as cp\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from DL_utils import MLP, MLPbeta, CNN, eval_nn, train_mlp, test_mlp, train_mlpbeta, test_mlpbeta, train_cnn, test_cnn\n",
    "\n",
    "import process_data as prd\n",
    "from lda import train_lda, predict, eval_lda, eval_lda_ch\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'AB'\n",
    "with open('train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: traindata_manual/AB2_traindata_2.p\n"
     ]
    }
   ],
   "source": [
    "## Training \n",
    "sub = 2\n",
    "train_grp = 2\n",
    "n_train = 'fullallmix4'\n",
    "train_scale = 5\n",
    "cv_type = 'manual'\n",
    "scaler_load = False\n",
    "feat_type = 'mav'\n",
    "\n",
    "ind = (params[:,0] == sub) & (params[:,3] == train_grp)\n",
    "\n",
    "x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,sub_type,dt=cv_type,load=True,train_grp=train_grp)\n",
    "\n",
    "emg_scale = np.ones((np.size(x_train,1),1))\n",
    "for i in range(np.size(x_train,1)):\n",
    "    emg_scale[i] = 5/np.max(np.abs(x_train[:,i,:]))\n",
    "x_train = x_train*emg_scale\n",
    "x_valid = x_valid*emg_scale\n",
    "\n",
    "x_train_noise, x_train_clean, y_train_clean = prd.add_noise(x_train, p_train, sub, n_train, train_scale)\n",
    "x_valid_noise, x_valid_clean, y_valid_clean = prd.add_noise(x_valid, p_valid, sub, n_train, train_scale)\n",
    "\n",
    "# shuffle data to make even batches\n",
    "x_train_noise, x_train_clean, y_train_clean = shuffle(x_train_noise, x_train_clean, y_train_clean, random_state = 0)\n",
    "\n",
    "# Extract features\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_train_noise_cnn, scaler = prd.extract_scale(x_train_noise,scaler,scaler_load,ft=feat_type,emg_scale=emg_scale) \n",
    "x_valid_noise_cnn, _ = prd.extract_scale(x_valid_noise,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_train_noise_cnn = x_train_noise_cnn.astype('float32')\n",
    "x_valid_noise_cnn = x_valid_noise_cnn.astype('float32')\n",
    "\n",
    "# reshape data for nonconvolutional network\n",
    "x_train_noise_mlp = x_train_noise_cnn.reshape(x_train_noise_cnn.shape[0],-1)\n",
    "x_valid_noise_mlp = x_valid_noise_cnn.reshape(x_valid_noise_cnn.shape[0],-1)\n",
    "\n",
    "# create batches\n",
    "trainmlp_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_mlp, y_train_clean)).batch(128)\n",
    "testmlp_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_mlp, y_valid_clean)).batch(128)\n",
    "traincnn_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_cnn, y_train_clean)).batch(128)\n",
    "testcnn_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_cnn, y_valid_clean)).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "mlp_beta = MLPbeta()\n",
    "cnn = CNN()\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN TEST MLP\n",
    "@tf.function\n",
    "def train_mlp(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_out = mlp(x)\n",
    "        loss = loss_fn(y, y_out)\n",
    "    gradients = tape.gradient(loss, mlp.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, mlp.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_mlp(x, y):\n",
    "    y_out = mlp(x)\n",
    "    t_loss = loss_fn(y, y_out)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(y, y_out)\n",
    "\n",
    "## TRAIN TEST MLP BETA\n",
    "@tf.function\n",
    "def train_mlpbeta(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_out = mlp_beta(x)\n",
    "        loss = loss_fn(y, y_out)\n",
    "    gradients = tape.gradient(loss, mlp_beta.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, mlp_beta.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_mlpbeta(x, y):\n",
    "    y_out = mlp_beta(x)\n",
    "    t_loss = loss_fn(y, y_out)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(y, y_out)\n",
    "\n",
    "## TRAIN TEST CNN\n",
    "@tf.function\n",
    "def train_cnn(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_out = cnn(x)\n",
    "        loss = loss_fn(y, y_out)\n",
    "    gradients = tape.gradient(loss, cnn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, cnn.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_cnn(x, y):\n",
    "    y_out = cnn(x)\n",
    "    t_loss = loss_fn(y, y_out)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(y, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp\n",
      "Epoch 1, Loss: 1.9436055421829224, Accuracy: 15.567461013793945, Test Loss: 1.9376263618469238, Test Accuracy: 17.873016357421875\n",
      "Epoch 2, Loss: 1.9159562587738037, Accuracy: 21.91269874572754, Test Loss: 1.881170392036438, Test Accuracy: 25.587303161621094\n",
      "Epoch 3, Loss: 1.845521092414856, Accuracy: 29.738096237182617, Test Loss: 1.814572811126709, Test Accuracy: 34.0476188659668\n",
      "Epoch 4, Loss: 1.796665906906128, Accuracy: 35.4603157043457, Test Loss: 1.7839698791503906, Test Accuracy: 36.777774810791016\n",
      "Epoch 5, Loss: 1.7720528841018677, Accuracy: 38.4523811340332, Test Loss: 1.7745262384414673, Test Accuracy: 36.5396842956543\n",
      "Epoch 6, Loss: 1.7582334280014038, Accuracy: 39.81349182128906, Test Loss: 1.7709163427352905, Test Accuracy: 38.20634841918945\n",
      "Epoch 7, Loss: 1.7474658489227295, Accuracy: 41.32539749145508, Test Loss: 1.7668397426605225, Test Accuracy: 37.73015594482422\n",
      "Epoch 8, Loss: 1.7361502647399902, Accuracy: 42.31349182128906, Test Loss: 1.7665700912475586, Test Accuracy: 38.11111068725586\n",
      "Epoch 9, Loss: 1.7286432981491089, Accuracy: 43.130950927734375, Test Loss: 1.7664169073104858, Test Accuracy: 38.19047546386719\n",
      "Epoch 10, Loss: 1.7234508991241455, Accuracy: 43.72222137451172, Test Loss: 1.7644882202148438, Test Accuracy: 38.619049072265625\n",
      "Epoch 11, Loss: 1.7199784517288208, Accuracy: 44.06349182128906, Test Loss: 1.763736605644226, Test Accuracy: 38.80952453613281\n",
      "Epoch 12, Loss: 1.7167938947677612, Accuracy: 44.30158615112305, Test Loss: 1.76273512840271, Test Accuracy: 38.80952453613281\n",
      "Epoch 13, Loss: 1.7138603925704956, Accuracy: 44.658729553222656, Test Loss: 1.7622592449188232, Test Accuracy: 38.65079116821289\n",
      "Epoch 14, Loss: 1.7108879089355469, Accuracy: 44.94841384887695, Test Loss: 1.7622607946395874, Test Accuracy: 38.80952453613281\n",
      "Epoch 15, Loss: 1.7078557014465332, Accuracy: 45.2896842956543, Test Loss: 1.7622424364089966, Test Accuracy: 38.730159759521484\n",
      "Epoch 16, Loss: 1.7047761678695679, Accuracy: 45.63888931274414, Test Loss: 1.75950026512146, Test Accuracy: 38.492061614990234\n",
      "Epoch 17, Loss: 1.7017186880111694, Accuracy: 45.876983642578125, Test Loss: 1.7563385963439941, Test Accuracy: 38.873016357421875\n",
      "Epoch 18, Loss: 1.6984840631484985, Accuracy: 46.29365158081055, Test Loss: 1.7476189136505127, Test Accuracy: 39.80952453613281\n",
      "Epoch 19, Loss: 1.6952000856399536, Accuracy: 46.69841384887695, Test Loss: 1.7443128824234009, Test Accuracy: 40.28571701049805\n",
      "Epoch 20, Loss: 1.6934655904769897, Accuracy: 46.880950927734375, Test Loss: 1.744221806526184, Test Accuracy: 40.4920654296875\n",
      "Epoch 21, Loss: 1.6915874481201172, Accuracy: 47.099205017089844, Test Loss: 1.7414147853851318, Test Accuracy: 40.60317611694336\n",
      "Epoch 22, Loss: 1.6899908781051636, Accuracy: 47.22618865966797, Test Loss: 1.7391180992126465, Test Accuracy: 40.85714340209961\n",
      "Epoch 23, Loss: 1.688866138458252, Accuracy: 47.408729553222656, Test Loss: 1.7382625341415405, Test Accuracy: 41.14285659790039\n",
      "Epoch 24, Loss: 1.687444806098938, Accuracy: 47.53571319580078, Test Loss: 1.7358311414718628, Test Accuracy: 41.349205017089844\n",
      "Epoch 25, Loss: 1.686760425567627, Accuracy: 47.63095474243164, Test Loss: 1.7329860925674438, Test Accuracy: 41.9523811340332\n",
      "Epoch 26, Loss: 1.6859705448150635, Accuracy: 47.55952453613281, Test Loss: 1.7308588027954102, Test Accuracy: 42.14285659790039\n",
      "Epoch 27, Loss: 1.6849809885025024, Accuracy: 47.70635223388672, Test Loss: 1.7346017360687256, Test Accuracy: 41.841270446777344\n",
      "Epoch 28, Loss: 1.683905005455017, Accuracy: 47.761905670166016, Test Loss: 1.7343143224716187, Test Accuracy: 41.841270446777344\n",
      "Epoch 29, Loss: 1.6830558776855469, Accuracy: 47.837303161621094, Test Loss: 1.7322964668273926, Test Accuracy: 41.984127044677734\n",
      "Epoch 30, Loss: 1.6813881397247314, Accuracy: 47.96825408935547, Test Loss: 1.7295243740081787, Test Accuracy: 42.365081787109375\n",
      "Epoch 31, Loss: 1.679733395576477, Accuracy: 48.17063522338867, Test Loss: 1.7295160293579102, Test Accuracy: 42.603172302246094\n",
      "Epoch 32, Loss: 1.6775498390197754, Accuracy: 48.30952453613281, Test Loss: 1.719700574874878, Test Accuracy: 43.79365158081055\n",
      "Epoch 33, Loss: 1.6756168603897095, Accuracy: 48.595237731933594, Test Loss: 1.716615915298462, Test Accuracy: 44.19047546386719\n",
      "Epoch 34, Loss: 1.6740913391113281, Accuracy: 48.78571319580078, Test Loss: 1.7121015787124634, Test Accuracy: 44.619049072265625\n",
      "Epoch 35, Loss: 1.6719032526016235, Accuracy: 48.91666793823242, Test Loss: 1.7044994831085205, Test Accuracy: 45.22222137451172\n",
      "Epoch 36, Loss: 1.6676859855651855, Accuracy: 49.43650817871094, Test Loss: 1.6926774978637695, Test Accuracy: 46.269840240478516\n",
      "Epoch 37, Loss: 1.6563270092010498, Accuracy: 50.35714340209961, Test Loss: 1.6778039932250977, Test Accuracy: 47.69841003417969\n",
      "Epoch 38, Loss: 1.6512129306793213, Accuracy: 51.05555725097656, Test Loss: 1.6769776344299316, Test Accuracy: 48.0\n",
      "Epoch 39, Loss: 1.6487956047058105, Accuracy: 51.265872955322266, Test Loss: 1.6726126670837402, Test Accuracy: 48.69841384887695\n",
      "Epoch 40, Loss: 1.6467963457107544, Accuracy: 51.5396842956543, Test Loss: 1.672781229019165, Test Accuracy: 48.14285659790039\n",
      "Epoch 41, Loss: 1.644849419593811, Accuracy: 51.603172302246094, Test Loss: 1.665816068649292, Test Accuracy: 49.06349182128906\n",
      "Epoch 42, Loss: 1.6435167789459229, Accuracy: 51.72222137451172, Test Loss: 1.6646381616592407, Test Accuracy: 49.333335876464844\n",
      "Epoch 43, Loss: 1.6416139602661133, Accuracy: 52.02381134033203, Test Loss: 1.6579008102416992, Test Accuracy: 50.11111068725586\n",
      "Epoch 44, Loss: 1.6397705078125, Accuracy: 52.27381134033203, Test Loss: 1.6611372232437134, Test Accuracy: 49.63492202758789\n",
      "Epoch 45, Loss: 1.6383743286132812, Accuracy: 52.5317497253418, Test Loss: 1.6637517213821411, Test Accuracy: 49.11111068725586\n",
      "Epoch 46, Loss: 1.635818362236023, Accuracy: 52.68253707885742, Test Loss: 1.666347622871399, Test Accuracy: 48.841270446777344\n",
      "Epoch 47, Loss: 1.634853482246399, Accuracy: 52.82539749145508, Test Loss: 1.6679261922836304, Test Accuracy: 48.79364776611328\n",
      "Epoch 48, Loss: 1.6330803632736206, Accuracy: 53.08333206176758, Test Loss: 1.6676045656204224, Test Accuracy: 48.77777862548828\n",
      "Epoch 49, Loss: 1.6320346593856812, Accuracy: 53.095237731933594, Test Loss: 1.6650238037109375, Test Accuracy: 49.11111068725586\n",
      "Epoch 50, Loss: 1.631075143814087, Accuracy: 53.2579345703125, Test Loss: 1.6672439575195312, Test Accuracy: 48.841270446777344\n",
      "Epoch 51, Loss: 1.6298141479492188, Accuracy: 53.34920883178711, Test Loss: 1.6596282720565796, Test Accuracy: 49.76190185546875\n",
      "Epoch 52, Loss: 1.6274538040161133, Accuracy: 53.54762268066406, Test Loss: 1.6608991622924805, Test Accuracy: 49.333335876464844\n",
      "Epoch 53, Loss: 1.6264642477035522, Accuracy: 53.54365158081055, Test Loss: 1.6599076986312866, Test Accuracy: 49.650794982910156\n",
      "Epoch 54, Loss: 1.6250227689743042, Accuracy: 53.82539749145508, Test Loss: 1.660149097442627, Test Accuracy: 49.603172302246094\n",
      "Epoch 55, Loss: 1.624640941619873, Accuracy: 53.81349182128906, Test Loss: 1.6570143699645996, Test Accuracy: 49.88888931274414\n",
      "Epoch 56, Loss: 1.6236289739608765, Accuracy: 53.92460250854492, Test Loss: 1.6514561176300049, Test Accuracy: 50.63492202758789\n",
      "Epoch 57, Loss: 1.6229158639907837, Accuracy: 54.07142639160156, Test Loss: 1.648085594177246, Test Accuracy: 50.904762268066406\n",
      "Epoch 58, Loss: 1.621922254562378, Accuracy: 54.18254089355469, Test Loss: 1.6475541591644287, Test Accuracy: 51.0\n",
      "Epoch 59, Loss: 1.6218348741531372, Accuracy: 54.13492202758789, Test Loss: 1.646712064743042, Test Accuracy: 51.15873336791992\n",
      "Epoch 60, Loss: 1.62060546875, Accuracy: 54.238094329833984, Test Loss: 1.6463623046875, Test Accuracy: 51.06349182128906\n",
      "Training mlpbeta\n",
      "Epoch 1, Loss: 1.8698740005493164, Accuracy: 26.678571701049805, Test Loss: 1.8081865310668945, Test Accuracy: 35.06349182128906\n",
      "Epoch 2, Loss: 1.7533725500106812, Accuracy: 41.06349182128906, Test Loss: 1.7185853719711304, Test Accuracy: 45.31745910644531\n",
      "Epoch 3, Loss: 1.7218902111053467, Accuracy: 43.86111068725586, Test Loss: 1.7144969701766968, Test Accuracy: 43.841270446777344\n",
      "Epoch 4, Loss: 1.7036315202713013, Accuracy: 45.43650817871094, Test Loss: 1.6962356567382812, Test Accuracy: 46.88888931274414\n",
      "Epoch 5, Loss: 1.6844227313995361, Accuracy: 47.92857360839844, Test Loss: 1.6802138090133667, Test Accuracy: 48.19047927856445\n",
      "Epoch 6, Loss: 1.6731868982315063, Accuracy: 48.94841384887695, Test Loss: 1.6991407871246338, Test Accuracy: 45.03174591064453\n",
      "Epoch 7, Loss: 1.6661838293075562, Accuracy: 49.55952453613281, Test Loss: 1.7223336696624756, Test Accuracy: 42.9523811340332\n",
      "Epoch 8, Loss: 1.6582645177841187, Accuracy: 50.43254089355469, Test Loss: 1.7183279991149902, Test Accuracy: 43.126983642578125\n",
      "Epoch 9, Loss: 1.6488792896270752, Accuracy: 51.52381134033203, Test Loss: 1.6884921789169312, Test Accuracy: 46.42856979370117\n",
      "Epoch 10, Loss: 1.641456127166748, Accuracy: 52.269840240478516, Test Loss: 1.6466331481933594, Test Accuracy: 51.46031951904297\n",
      "Epoch 11, Loss: 1.631338357925415, Accuracy: 53.238094329833984, Test Loss: 1.6472234725952148, Test Accuracy: 51.07936096191406\n",
      "Epoch 12, Loss: 1.6242876052856445, Accuracy: 53.876983642578125, Test Loss: 1.63826322555542, Test Accuracy: 52.04761505126953\n",
      "Epoch 13, Loss: 1.6196668148040771, Accuracy: 54.39285659790039, Test Loss: 1.6431044340133667, Test Accuracy: 51.587303161621094\n",
      "Epoch 14, Loss: 1.6162899732589722, Accuracy: 54.73809051513672, Test Loss: 1.6273800134658813, Test Accuracy: 53.238094329833984\n",
      "Epoch 15, Loss: 1.6111823320388794, Accuracy: 55.138885498046875, Test Loss: 1.6316512823104858, Test Accuracy: 52.93650817871094\n",
      "Epoch 16, Loss: 1.608944296836853, Accuracy: 55.4603157043457, Test Loss: 1.6317352056503296, Test Accuracy: 52.80952453613281\n",
      "Epoch 17, Loss: 1.6059038639068604, Accuracy: 55.76984405517578, Test Loss: 1.6189080476760864, Test Accuracy: 53.69841384887695\n",
      "Epoch 18, Loss: 1.604610562324524, Accuracy: 55.78174591064453, Test Loss: 1.617732286453247, Test Accuracy: 53.93650436401367\n",
      "Epoch 19, Loss: 1.6020523309707642, Accuracy: 56.19444274902344, Test Loss: 1.6127302646636963, Test Accuracy: 54.25396728515625\n",
      "Epoch 20, Loss: 1.5997419357299805, Accuracy: 56.43254089355469, Test Loss: 1.6161433458328247, Test Accuracy: 54.238094329833984\n",
      "Epoch 21, Loss: 1.6019690036773682, Accuracy: 56.162696838378906, Test Loss: 1.6147183179855347, Test Accuracy: 54.31746292114258\n",
      "Epoch 22, Loss: 1.6000298261642456, Accuracy: 56.23015594482422, Test Loss: 1.607518196105957, Test Accuracy: 54.60317611694336\n",
      "Epoch 23, Loss: 1.5969138145446777, Accuracy: 56.619049072265625, Test Loss: 1.607967734336853, Test Accuracy: 54.58729934692383\n",
      "Epoch 24, Loss: 1.5980437994003296, Accuracy: 56.56745910644531, Test Loss: 1.6033424139022827, Test Accuracy: 55.650794982910156\n",
      "Epoch 25, Loss: 1.5941699743270874, Accuracy: 56.9920654296875, Test Loss: 1.6071165800094604, Test Accuracy: 55.06349182128906\n",
      "Epoch 26, Loss: 1.5909899473190308, Accuracy: 57.25, Test Loss: 1.6030082702636719, Test Accuracy: 55.57143020629883\n",
      "Epoch 27, Loss: 1.5902550220489502, Accuracy: 57.33333206176758, Test Loss: 1.6073997020721436, Test Accuracy: 54.80952453613281\n",
      "Epoch 28, Loss: 1.5895566940307617, Accuracy: 57.4444465637207, Test Loss: 1.6010828018188477, Test Accuracy: 55.650794982910156\n",
      "Epoch 29, Loss: 1.588103175163269, Accuracy: 57.55952453613281, Test Loss: 1.601181149482727, Test Accuracy: 55.4603157043457\n",
      "Epoch 30, Loss: 1.5862131118774414, Accuracy: 57.70634841918945, Test Loss: 1.5972820520401, Test Accuracy: 56.126983642578125\n",
      "Epoch 31, Loss: 1.5851114988327026, Accuracy: 57.80158615112305, Test Loss: 1.5964715480804443, Test Accuracy: 56.20635223388672\n",
      "Epoch 32, Loss: 1.583785891532898, Accuracy: 57.95634841918945, Test Loss: 1.5985087156295776, Test Accuracy: 56.07936477661133\n",
      "Epoch 33, Loss: 1.5849206447601318, Accuracy: 57.78571319580078, Test Loss: 1.5945801734924316, Test Accuracy: 56.28571319580078\n",
      "Epoch 34, Loss: 1.5810503959655762, Accuracy: 58.24603271484375, Test Loss: 1.5950500965118408, Test Accuracy: 56.095237731933594\n",
      "Epoch 35, Loss: 1.5796202421188354, Accuracy: 58.47222137451172, Test Loss: 1.5934529304504395, Test Accuracy: 56.57143020629883\n",
      "Epoch 36, Loss: 1.576796054840088, Accuracy: 58.77381134033203, Test Loss: 1.6009389162063599, Test Accuracy: 55.92063522338867\n",
      "Epoch 37, Loss: 1.5793880224227905, Accuracy: 58.265869140625, Test Loss: 1.5936180353164673, Test Accuracy: 56.412696838378906\n",
      "Epoch 38, Loss: 1.5772074460983276, Accuracy: 58.68650817871094, Test Loss: 1.5973283052444458, Test Accuracy: 56.17460632324219\n",
      "Epoch 39, Loss: 1.579046368598938, Accuracy: 58.499996185302734, Test Loss: 1.595068097114563, Test Accuracy: 56.30158615112305\n",
      "Epoch 40, Loss: 1.5744882822036743, Accuracy: 58.916664123535156, Test Loss: 1.6030102968215942, Test Accuracy: 55.71428680419922\n",
      "Epoch 41, Loss: 1.5758086442947388, Accuracy: 58.63095474243164, Test Loss: 1.5953730344772339, Test Accuracy: 56.33333206176758\n",
      "Epoch 42, Loss: 1.5732704401016235, Accuracy: 59.04365158081055, Test Loss: 1.594504714012146, Test Accuracy: 56.380950927734375\n",
      "Epoch 43, Loss: 1.5730173587799072, Accuracy: 59.126983642578125, Test Loss: 1.5955321788787842, Test Accuracy: 56.4603157043457\n",
      "Epoch 44, Loss: 1.5726374387741089, Accuracy: 59.115081787109375, Test Loss: 1.5949711799621582, Test Accuracy: 56.36507797241211\n",
      "Epoch 45, Loss: 1.5717319250106812, Accuracy: 59.103172302246094, Test Loss: 1.5922425985336304, Test Accuracy: 56.507938385009766\n",
      "Epoch 46, Loss: 1.5720826387405396, Accuracy: 59.14285659790039, Test Loss: 1.5954773426055908, Test Accuracy: 56.44444274902344\n",
      "Epoch 47, Loss: 1.5704225301742554, Accuracy: 59.36111068725586, Test Loss: 1.6061750650405884, Test Accuracy: 55.06349182128906\n",
      "Epoch 48, Loss: 1.57035231590271, Accuracy: 59.33333206176758, Test Loss: 1.6028835773468018, Test Accuracy: 55.60317611694336\n",
      "Epoch 49, Loss: 1.5675702095031738, Accuracy: 59.63095474243164, Test Loss: 1.5914933681488037, Test Accuracy: 56.904762268066406\n",
      "Epoch 50, Loss: 1.5678461790084839, Accuracy: 59.591270446777344, Test Loss: 1.5869544744491577, Test Accuracy: 57.36507797241211\n",
      "Epoch 51, Loss: 1.5654445886611938, Accuracy: 59.85714340209961, Test Loss: 1.6015690565109253, Test Accuracy: 55.63492202758789\n",
      "Epoch 52, Loss: 1.5664762258529663, Accuracy: 59.646827697753906, Test Loss: 1.596250057220459, Test Accuracy: 56.31745910644531\n",
      "Epoch 53, Loss: 1.564706563949585, Accuracy: 59.845237731933594, Test Loss: 1.5894339084625244, Test Accuracy: 56.80952835083008\n",
      "Epoch 54, Loss: 1.5619651079177856, Accuracy: 60.13095474243164, Test Loss: 1.5937528610229492, Test Accuracy: 56.42856979370117\n",
      "Epoch 55, Loss: 1.559850811958313, Accuracy: 60.32539749145508, Test Loss: 1.5862972736358643, Test Accuracy: 57.22222137451172\n",
      "Epoch 56, Loss: 1.5585554838180542, Accuracy: 60.484130859375, Test Loss: 1.5823174715042114, Test Accuracy: 57.46031951904297\n",
      "Epoch 57, Loss: 1.5576720237731934, Accuracy: 60.626983642578125, Test Loss: 1.587504267692566, Test Accuracy: 57.07936096191406\n",
      "Epoch 58, Loss: 1.5590929985046387, Accuracy: 60.42857360839844, Test Loss: 1.5815831422805786, Test Accuracy: 57.85714340209961\n",
      "Epoch 59, Loss: 1.5563839673995972, Accuracy: 60.773807525634766, Test Loss: 1.5907877683639526, Test Accuracy: 56.76190185546875\n",
      "Epoch 60, Loss: 1.5563567876815796, Accuracy: 60.67856979370117, Test Loss: 1.585435152053833, Test Accuracy: 57.39682388305664\n",
      "Training cnn\n",
      "Epoch 1, Loss: 1.8427706956863403, Accuracy: 29.742061614990234, Test Loss: 1.7598967552185059, Test Accuracy: 39.55555725097656\n",
      "Epoch 2, Loss: 1.7207552194595337, Accuracy: 44.78174591064453, Test Loss: 1.7280343770980835, Test Accuracy: 42.015872955322266\n",
      "Epoch 3, Loss: 1.6692922115325928, Accuracy: 49.72222137451172, Test Loss: 1.6847301721572876, Test Accuracy: 47.396827697753906\n",
      "Epoch 4, Loss: 1.6471507549285889, Accuracy: 51.95634841918945, Test Loss: 1.6684982776641846, Test Accuracy: 48.88888931274414\n",
      "Epoch 5, Loss: 1.6356269121170044, Accuracy: 52.980159759521484, Test Loss: 1.6553714275360107, Test Accuracy: 50.476192474365234\n",
      "Epoch 6, Loss: 1.627363920211792, Accuracy: 53.7976188659668, Test Loss: 1.6522027254104614, Test Accuracy: 50.60317611694336\n",
      "Epoch 7, Loss: 1.62050461769104, Accuracy: 54.480159759521484, Test Loss: 1.6478005647659302, Test Accuracy: 51.25396728515625\n",
      "Epoch 8, Loss: 1.6140872240066528, Accuracy: 55.150794982910156, Test Loss: 1.6452888250350952, Test Accuracy: 51.52381134033203\n",
      "Epoch 9, Loss: 1.6065850257873535, Accuracy: 55.88492202758789, Test Loss: 1.630873680114746, Test Accuracy: 52.634918212890625\n",
      "Epoch 10, Loss: 1.5877702236175537, Accuracy: 57.81745910644531, Test Loss: 1.6135261058807373, Test Accuracy: 54.44444274902344\n",
      "Epoch 11, Loss: 1.5813790559768677, Accuracy: 58.36904525756836, Test Loss: 1.6100306510925293, Test Accuracy: 54.857139587402344\n",
      "Epoch 12, Loss: 1.576577067375183, Accuracy: 58.80158615112305, Test Loss: 1.606377124786377, Test Accuracy: 54.96825408935547\n",
      "Epoch 13, Loss: 1.5729389190673828, Accuracy: 59.126983642578125, Test Loss: 1.603470802307129, Test Accuracy: 55.222225189208984\n",
      "Epoch 14, Loss: 1.568352222442627, Accuracy: 59.66666793823242, Test Loss: 1.596738338470459, Test Accuracy: 56.06349182128906\n",
      "Epoch 15, Loss: 1.5643924474716187, Accuracy: 60.115081787109375, Test Loss: 1.5922574996948242, Test Accuracy: 56.63492202758789\n",
      "Epoch 16, Loss: 1.560926079750061, Accuracy: 60.38095474243164, Test Loss: 1.5888512134552002, Test Accuracy: 57.0\n",
      "Epoch 17, Loss: 1.5579514503479004, Accuracy: 60.7579345703125, Test Loss: 1.584909200668335, Test Accuracy: 57.33333206176758\n",
      "Epoch 18, Loss: 1.5552291870117188, Accuracy: 60.984127044677734, Test Loss: 1.5798779726028442, Test Accuracy: 57.80952453613281\n",
      "Epoch 19, Loss: 1.552402377128601, Accuracy: 61.2976188659668, Test Loss: 1.5747448205947876, Test Accuracy: 58.55555725097656\n",
      "Epoch 20, Loss: 1.5504817962646484, Accuracy: 61.43650817871094, Test Loss: 1.5722602605819702, Test Accuracy: 59.0317497253418\n",
      "Epoch 21, Loss: 1.5482690334320068, Accuracy: 61.595237731933594, Test Loss: 1.5717289447784424, Test Accuracy: 58.873016357421875\n",
      "Epoch 22, Loss: 1.5461312532424927, Accuracy: 61.71428680419922, Test Loss: 1.5701167583465576, Test Accuracy: 59.0317497253418\n",
      "Epoch 23, Loss: 1.5428084135055542, Accuracy: 62.23809814453125, Test Loss: 1.569493293762207, Test Accuracy: 59.17460250854492\n",
      "Epoch 24, Loss: 1.540509819984436, Accuracy: 62.496028900146484, Test Loss: 1.5713081359863281, Test Accuracy: 58.79365158081055\n",
      "Epoch 25, Loss: 1.5378309488296509, Accuracy: 62.77381134033203, Test Loss: 1.566091775894165, Test Accuracy: 59.476192474365234\n",
      "Epoch 26, Loss: 1.5358431339263916, Accuracy: 62.912696838378906, Test Loss: 1.5713169574737549, Test Accuracy: 59.015869140625\n",
      "Epoch 27, Loss: 1.5340254306793213, Accuracy: 63.130950927734375, Test Loss: 1.569262981414795, Test Accuracy: 59.365081787109375\n",
      "Epoch 28, Loss: 1.5329084396362305, Accuracy: 63.28571319580078, Test Loss: 1.565526008605957, Test Accuracy: 59.761905670166016\n",
      "Epoch 29, Loss: 1.531753420829773, Accuracy: 63.33333206176758, Test Loss: 1.5676138401031494, Test Accuracy: 59.396827697753906\n",
      "Epoch 30, Loss: 1.5297762155532837, Accuracy: 63.56745910644531, Test Loss: 1.5610078573226929, Test Accuracy: 59.79365158081055\n",
      "Epoch 31, Loss: 1.5280125141143799, Accuracy: 63.746028900146484, Test Loss: 1.559187889099121, Test Accuracy: 59.873016357421875\n",
      "Epoch 32, Loss: 1.526804804801941, Accuracy: 63.912696838378906, Test Loss: 1.5578887462615967, Test Accuracy: 60.01587677001953\n",
      "Epoch 33, Loss: 1.5248830318450928, Accuracy: 64.07936096191406, Test Loss: 1.5569071769714355, Test Accuracy: 60.17460250854492\n",
      "Epoch 34, Loss: 1.5241997241973877, Accuracy: 64.03571319580078, Test Loss: 1.5571813583374023, Test Accuracy: 59.95237731933594\n",
      "Epoch 35, Loss: 1.5215790271759033, Accuracy: 64.31745910644531, Test Loss: 1.5550265312194824, Test Accuracy: 60.365081787109375\n",
      "Epoch 36, Loss: 1.5204163789749146, Accuracy: 64.48809814453125, Test Loss: 1.5580974817276, Test Accuracy: 60.095237731933594\n",
      "Epoch 37, Loss: 1.5184121131896973, Accuracy: 64.73809814453125, Test Loss: 1.555570363998413, Test Accuracy: 60.31746292114258\n",
      "Epoch 38, Loss: 1.51682710647583, Accuracy: 64.9206314086914, Test Loss: 1.5508294105529785, Test Accuracy: 60.95238494873047\n",
      "Epoch 39, Loss: 1.514824390411377, Accuracy: 65.05952453613281, Test Loss: 1.5511767864227295, Test Accuracy: 60.95238494873047\n",
      "Epoch 40, Loss: 1.512925148010254, Accuracy: 65.22618865966797, Test Loss: 1.5505849123001099, Test Accuracy: 61.03174591064453\n",
      "Epoch 41, Loss: 1.5129013061523438, Accuracy: 65.31745910644531, Test Loss: 1.5498390197753906, Test Accuracy: 61.11111068725586\n",
      "Epoch 42, Loss: 1.5115469694137573, Accuracy: 65.38095092773438, Test Loss: 1.5527563095092773, Test Accuracy: 60.58729934692383\n",
      "Epoch 43, Loss: 1.5107877254486084, Accuracy: 65.42460632324219, Test Loss: 1.550095796585083, Test Accuracy: 60.9365119934082\n",
      "Epoch 44, Loss: 1.5100657939910889, Accuracy: 65.55555725097656, Test Loss: 1.5482723712921143, Test Accuracy: 61.22222137451172\n",
      "Epoch 45, Loss: 1.5094051361083984, Accuracy: 65.60713958740234, Test Loss: 1.5505388975143433, Test Accuracy: 61.03174591064453\n",
      "Epoch 46, Loss: 1.5092445611953735, Accuracy: 65.5952377319336, Test Loss: 1.5564159154891968, Test Accuracy: 60.269840240478516\n",
      "Epoch 47, Loss: 1.5068053007125854, Accuracy: 65.8968276977539, Test Loss: 1.5563786029815674, Test Accuracy: 60.28571701049805\n",
      "Epoch 48, Loss: 1.5071467161178589, Accuracy: 65.76983642578125, Test Loss: 1.5562344789505005, Test Accuracy: 60.4603157043457\n",
      "Epoch 49, Loss: 1.50632643699646, Accuracy: 65.96825408935547, Test Loss: 1.5537865161895752, Test Accuracy: 60.66666793823242\n",
      "Epoch 50, Loss: 1.5064328908920288, Accuracy: 65.92857360839844, Test Loss: 1.553551197052002, Test Accuracy: 60.77777862548828\n",
      "Epoch 51, Loss: 1.5040210485458374, Accuracy: 66.19444274902344, Test Loss: 1.550346851348877, Test Accuracy: 61.095237731933594\n",
      "Epoch 52, Loss: 1.502701997756958, Accuracy: 66.19444274902344, Test Loss: 1.547568678855896, Test Accuracy: 61.34920883178711\n",
      "Epoch 53, Loss: 1.503522276878357, Accuracy: 66.16667175292969, Test Loss: 1.553877830505371, Test Accuracy: 60.58729934692383\n",
      "Epoch 54, Loss: 1.503273606300354, Accuracy: 66.20237731933594, Test Loss: 1.5524680614471436, Test Accuracy: 60.77777862548828\n",
      "Epoch 55, Loss: 1.5006893873214722, Accuracy: 66.3531723022461, Test Loss: 1.543901801109314, Test Accuracy: 61.69841384887695\n",
      "Epoch 56, Loss: 1.500396728515625, Accuracy: 66.49603271484375, Test Loss: 1.5587451457977295, Test Accuracy: 60.19047546386719\n",
      "Epoch 57, Loss: 1.499994158744812, Accuracy: 66.5793685913086, Test Loss: 1.5489416122436523, Test Accuracy: 60.87301254272461\n",
      "Epoch 58, Loss: 1.4999228715896606, Accuracy: 66.58333587646484, Test Loss: 1.5461581945419312, Test Accuracy: 61.333335876464844\n",
      "Epoch 59, Loss: 1.4993853569030762, Accuracy: 66.59920501708984, Test Loss: 1.550758719444275, Test Accuracy: 60.650794982910156\n",
      "Epoch 60, Loss: 1.5003730058670044, Accuracy: 66.43650817871094, Test Loss: 1.5613276958465576, Test Accuracy: 59.730159759521484\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 60\n",
    "models = ['mlp','mlpbeta','cnn']\n",
    "\n",
    "for model in models:\n",
    "    print('Training ' + model)\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "\n",
    "        # Train MLP\n",
    "        if model == 'mlp':\n",
    "            for x, y in trainmlp_ds:\n",
    "                train_mlp(x, y)\n",
    "            for x_test, y_test in testmlp_ds:\n",
    "                test_mlp(x_test, y_test)\n",
    "        # Train MLP Beta\n",
    "        elif model == 'mlpbeta':\n",
    "            for x, y in trainmlp_ds:\n",
    "                train_mlpbeta(x, y)\n",
    "            for x_test, y_test in testmlp_ds:\n",
    "                test_mlpbeta(x_test, y_test)\n",
    "        # Train CNN\n",
    "        elif model == 'cnn':\n",
    "            for x, y in traincnn_ds:\n",
    "                train_cnn(x,y)\n",
    "            for x_test, y_test in testcnn_ds:\n",
    "                test_cnn(x_test, y_test)\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}, '\n",
    "            f'Loss: {train_loss.result()}, '\n",
    "            f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "            f'Test Loss: {test_loss.result()}, '\n",
    "            f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp\n",
      "Epoch 1, Loss: 1.9400993585586548, Accuracy: 16.297618865966797, Test Loss: 1.919284701347351, Test Accuracy: 18.174604415893555\n",
      "Epoch 2, Loss: 1.8843544721603394, Accuracy: 25.361112594604492, Test Loss: 1.8650637865066528, Test Accuracy: 27.841270446777344\n",
      "Epoch 3, Loss: 1.8406009674072266, Accuracy: 32.019840240478516, Test Loss: 1.822227954864502, Test Accuracy: 36.22222137451172\n",
      "Epoch 4, Loss: 1.7912793159484863, Accuracy: 38.2023811340332, Test Loss: 1.7810697555541992, Test Accuracy: 38.69841384887695\n",
      "Epoch 5, Loss: 1.755397915840149, Accuracy: 41.32143020629883, Test Loss: 1.7560169696807861, Test Accuracy: 40.71428298950195\n",
      "Epoch 6, Loss: 1.7384065389633179, Accuracy: 42.5396842956543, Test Loss: 1.7377867698669434, Test Accuracy: 42.14285659790039\n",
      "Epoch 7, Loss: 1.7273625135421753, Accuracy: 43.626983642578125, Test Loss: 1.728888988494873, Test Accuracy: 43.22222137451172\n",
      "Epoch 8, Loss: 1.7178070545196533, Accuracy: 44.69444274902344, Test Loss: 1.723215937614441, Test Accuracy: 43.380950927734375\n",
      "Epoch 9, Loss: 1.70975923538208, Accuracy: 45.488094329833984, Test Loss: 1.7061687707901, Test Accuracy: 45.730159759521484\n",
      "Epoch 10, Loss: 1.702990174293518, Accuracy: 46.05555725097656, Test Loss: 1.6992803812026978, Test Accuracy: 46.20634841918945\n",
      "Epoch 11, Loss: 1.6965080499649048, Accuracy: 46.773807525634766, Test Loss: 1.6980807781219482, Test Accuracy: 46.33333206176758\n",
      "Epoch 12, Loss: 1.6898057460784912, Accuracy: 47.55952453613281, Test Loss: 1.6932177543640137, Test Accuracy: 47.269840240478516\n",
      "Epoch 13, Loss: 1.6828049421310425, Accuracy: 48.20634841918945, Test Loss: 1.6938740015029907, Test Accuracy: 47.06349182128906\n",
      "Epoch 14, Loss: 1.6759743690490723, Accuracy: 48.82936477661133, Test Loss: 1.6892493963241577, Test Accuracy: 47.587303161621094\n",
      "Epoch 15, Loss: 1.668727159500122, Accuracy: 49.662696838378906, Test Loss: 1.6925857067108154, Test Accuracy: 46.77777862548828\n",
      "Epoch 16, Loss: 1.6628191471099854, Accuracy: 50.38888931274414, Test Loss: 1.6871997117996216, Test Accuracy: 47.57143020629883\n",
      "Epoch 17, Loss: 1.6592991352081299, Accuracy: 50.7103157043457, Test Loss: 1.6856876611709595, Test Accuracy: 47.36507797241211\n",
      "Epoch 18, Loss: 1.6563042402267456, Accuracy: 50.94444274902344, Test Loss: 1.6832075119018555, Test Accuracy: 47.269840240478516\n",
      "Epoch 19, Loss: 1.6538341045379639, Accuracy: 51.123016357421875, Test Loss: 1.6855320930480957, Test Accuracy: 47.23809814453125\n",
      "Epoch 20, Loss: 1.6520664691925049, Accuracy: 51.341270446777344, Test Loss: 1.6862289905548096, Test Accuracy: 47.0\n",
      "Epoch 21, Loss: 1.6504895687103271, Accuracy: 51.519840240478516, Test Loss: 1.694597601890564, Test Accuracy: 46.126983642578125\n",
      "Epoch 22, Loss: 1.6487199068069458, Accuracy: 51.634918212890625, Test Loss: 1.6882728338241577, Test Accuracy: 46.761905670166016\n",
      "Epoch 23, Loss: 1.647698163986206, Accuracy: 51.63888931274414, Test Loss: 1.6906646490097046, Test Accuracy: 46.68254089355469\n",
      "Epoch 24, Loss: 1.6459479331970215, Accuracy: 51.892860412597656, Test Loss: 1.685523271560669, Test Accuracy: 47.4444465637207\n",
      "Epoch 25, Loss: 1.645033359527588, Accuracy: 52.00396728515625, Test Loss: 1.6857742071151733, Test Accuracy: 47.349205017089844\n",
      "Epoch 26, Loss: 1.6439013481140137, Accuracy: 52.17063522338867, Test Loss: 1.6805499792099, Test Accuracy: 47.79365158081055\n",
      "Epoch 27, Loss: 1.6424716711044312, Accuracy: 52.32539749145508, Test Loss: 1.6774725914001465, Test Accuracy: 47.96825408935547\n",
      "Epoch 28, Loss: 1.6411008834838867, Accuracy: 52.44841003417969, Test Loss: 1.678432822227478, Test Accuracy: 47.77777862548828\n",
      "Epoch 29, Loss: 1.6395341157913208, Accuracy: 52.591270446777344, Test Loss: 1.6821240186691284, Test Accuracy: 47.63492202758789\n",
      "Epoch 30, Loss: 1.6389554738998413, Accuracy: 52.658729553222656, Test Loss: 1.6806151866912842, Test Accuracy: 47.55555725097656\n",
      "Epoch 31, Loss: 1.6373385190963745, Accuracy: 52.77381134033203, Test Loss: 1.6848944425582886, Test Accuracy: 47.0476188659668\n",
      "Epoch 32, Loss: 1.636194109916687, Accuracy: 52.84920883178711, Test Loss: 1.68233323097229, Test Accuracy: 47.47618865966797\n",
      "Epoch 33, Loss: 1.634753704071045, Accuracy: 53.091270446777344, Test Loss: 1.6795358657836914, Test Accuracy: 47.69841003417969\n",
      "Epoch 34, Loss: 1.6338231563568115, Accuracy: 53.22222137451172, Test Loss: 1.681372046470642, Test Accuracy: 47.63492202758789\n",
      "Epoch 35, Loss: 1.632622480392456, Accuracy: 53.20634841918945, Test Loss: 1.6811721324920654, Test Accuracy: 47.666664123535156\n",
      "Epoch 36, Loss: 1.632011890411377, Accuracy: 53.29762268066406, Test Loss: 1.684181571006775, Test Accuracy: 47.31745910644531\n",
      "Epoch 37, Loss: 1.6309236288070679, Accuracy: 53.35714340209961, Test Loss: 1.6797350645065308, Test Accuracy: 47.650794982910156\n",
      "Epoch 38, Loss: 1.6304341554641724, Accuracy: 53.36111068725586, Test Loss: 1.683718204498291, Test Accuracy: 47.30158615112305\n",
      "Epoch 39, Loss: 1.6295413970947266, Accuracy: 53.57936477661133, Test Loss: 1.6880656480789185, Test Accuracy: 46.873016357421875\n",
      "Epoch 40, Loss: 1.629092812538147, Accuracy: 53.670631408691406, Test Loss: 1.6868470907211304, Test Accuracy: 46.96825408935547\n",
      "Epoch 41, Loss: 1.6286481618881226, Accuracy: 53.591270446777344, Test Loss: 1.6811621189117432, Test Accuracy: 47.47618865966797\n",
      "Epoch 42, Loss: 1.6292797327041626, Accuracy: 53.57936477661133, Test Loss: 1.679656982421875, Test Accuracy: 47.730159759521484\n",
      "Epoch 43, Loss: 1.6276023387908936, Accuracy: 53.71428680419922, Test Loss: 1.6805452108383179, Test Accuracy: 47.873016357421875\n",
      "Epoch 44, Loss: 1.6272157430648804, Accuracy: 53.845237731933594, Test Loss: 1.6811937093734741, Test Accuracy: 47.619049072265625\n",
      "Epoch 45, Loss: 1.6266682147979736, Accuracy: 53.82936477661133, Test Loss: 1.6825944185256958, Test Accuracy: 47.523807525634766\n",
      "Epoch 46, Loss: 1.626347541809082, Accuracy: 53.888885498046875, Test Loss: 1.6778641939163208, Test Accuracy: 47.82539749145508\n",
      "Epoch 47, Loss: 1.625658392906189, Accuracy: 53.920631408691406, Test Loss: 1.6829595565795898, Test Accuracy: 47.47618865966797\n",
      "Epoch 48, Loss: 1.626410961151123, Accuracy: 53.78174591064453, Test Loss: 1.681215763092041, Test Accuracy: 47.492061614990234\n",
      "Epoch 49, Loss: 1.625928282737732, Accuracy: 53.89285659790039, Test Loss: 1.680930495262146, Test Accuracy: 47.5079345703125\n",
      "Epoch 50, Loss: 1.6252580881118774, Accuracy: 53.90475845336914, Test Loss: 1.6805611848831177, Test Accuracy: 47.492061614990234\n",
      "Epoch 51, Loss: 1.625138521194458, Accuracy: 54.01587677001953, Test Loss: 1.6824159622192383, Test Accuracy: 47.46031951904297\n",
      "Epoch 52, Loss: 1.6243840456008911, Accuracy: 54.00396728515625, Test Loss: 1.6885850429534912, Test Accuracy: 46.82539749145508\n",
      "Epoch 53, Loss: 1.6247044801712036, Accuracy: 53.94841384887695, Test Loss: 1.6845394372940063, Test Accuracy: 47.11111068725586\n",
      "Epoch 54, Loss: 1.6239148378372192, Accuracy: 54.12301254272461, Test Loss: 1.6852200031280518, Test Accuracy: 47.0\n",
      "Epoch 55, Loss: 1.6233395338058472, Accuracy: 54.138885498046875, Test Loss: 1.6896287202835083, Test Accuracy: 46.85714340209961\n",
      "Epoch 56, Loss: 1.6237457990646362, Accuracy: 54.095237731933594, Test Loss: 1.6910241842269897, Test Accuracy: 46.63492202758789\n",
      "Epoch 57, Loss: 1.623742699623108, Accuracy: 54.11111068725586, Test Loss: 1.6872782707214355, Test Accuracy: 46.88888931274414\n",
      "Epoch 58, Loss: 1.623284935951233, Accuracy: 54.19444274902344, Test Loss: 1.6926919221878052, Test Accuracy: 46.39682388305664\n",
      "Epoch 59, Loss: 1.6226097345352173, Accuracy: 54.238094329833984, Test Loss: 1.698501467704773, Test Accuracy: 45.904762268066406\n",
      "Epoch 60, Loss: 1.623220682144165, Accuracy: 54.09920883178711, Test Loss: 1.6925712823867798, Test Accuracy: 46.36507797241211\n",
      "Training mlpbeta\n",
      "Epoch 1, Loss: 1.8479316234588623, Accuracy: 30.21428680419922, Test Loss: 1.79298996925354, Test Accuracy: 35.666664123535156\n",
      "Epoch 2, Loss: 1.7282663583755493, Accuracy: 43.46428680419922, Test Loss: 1.7534867525100708, Test Accuracy: 41.23809814453125\n",
      "Epoch 3, Loss: 1.6965080499649048, Accuracy: 46.80952453613281, Test Loss: 1.7280840873718262, Test Accuracy: 43.33333206176758\n",
      "Epoch 4, Loss: 1.6781502962112427, Accuracy: 48.65873336791992, Test Loss: 1.7130852937698364, Test Accuracy: 44.587303161621094\n",
      "Epoch 5, Loss: 1.668340802192688, Accuracy: 49.5476188659668, Test Loss: 1.7048355340957642, Test Accuracy: 44.873016357421875\n",
      "Epoch 6, Loss: 1.6607362031936646, Accuracy: 50.349205017089844, Test Loss: 1.7050285339355469, Test Accuracy: 45.22222137451172\n",
      "Epoch 7, Loss: 1.6491286754608154, Accuracy: 51.67857360839844, Test Loss: 1.683537483215332, Test Accuracy: 47.30158615112305\n",
      "Epoch 8, Loss: 1.6371970176696777, Accuracy: 52.77381134033203, Test Loss: 1.6831002235412598, Test Accuracy: 47.349205017089844\n",
      "Epoch 9, Loss: 1.6281794309616089, Accuracy: 53.72222137451172, Test Loss: 1.6710312366485596, Test Accuracy: 49.269840240478516\n",
      "Epoch 10, Loss: 1.6243767738342285, Accuracy: 54.09920883178711, Test Loss: 1.6768101453781128, Test Accuracy: 48.25396728515625\n",
      "Epoch 11, Loss: 1.620038628578186, Accuracy: 54.34920883178711, Test Loss: 1.674665093421936, Test Accuracy: 48.68254089355469\n",
      "Epoch 12, Loss: 1.6151502132415771, Accuracy: 54.984127044677734, Test Loss: 1.6742914915084839, Test Accuracy: 48.365081787109375\n",
      "Epoch 13, Loss: 1.6071856021881104, Accuracy: 55.67856979370117, Test Loss: 1.6589255332946777, Test Accuracy: 50.095237731933594\n",
      "Epoch 14, Loss: 1.5993478298187256, Accuracy: 56.46825408935547, Test Loss: 1.6519596576690674, Test Accuracy: 50.650794982910156\n",
      "Epoch 15, Loss: 1.5943721532821655, Accuracy: 56.93650817871094, Test Loss: 1.6383622884750366, Test Accuracy: 52.06349563598633\n",
      "Epoch 16, Loss: 1.5887126922607422, Accuracy: 57.56745910644531, Test Loss: 1.629370093345642, Test Accuracy: 52.71428680419922\n",
      "Epoch 17, Loss: 1.5836503505706787, Accuracy: 58.103172302246094, Test Loss: 1.6289153099060059, Test Accuracy: 52.85714340209961\n",
      "Epoch 18, Loss: 1.5854519605636597, Accuracy: 57.880950927734375, Test Loss: 1.6200323104858398, Test Accuracy: 53.968257904052734\n",
      "Epoch 19, Loss: 1.5817348957061768, Accuracy: 58.14682388305664, Test Loss: 1.6220072507858276, Test Accuracy: 53.57142639160156\n",
      "Epoch 20, Loss: 1.5786082744598389, Accuracy: 58.5396842956543, Test Loss: 1.628953456878662, Test Accuracy: 53.04762268066406\n",
      "Epoch 21, Loss: 1.5758862495422363, Accuracy: 58.91270065307617, Test Loss: 1.630902886390686, Test Accuracy: 52.761905670166016\n",
      "Epoch 22, Loss: 1.574293851852417, Accuracy: 58.9444465637207, Test Loss: 1.6210659742355347, Test Accuracy: 54.07936477661133\n",
      "Epoch 23, Loss: 1.5733739137649536, Accuracy: 59.18650817871094, Test Loss: 1.6299625635147095, Test Accuracy: 52.999996185302734\n",
      "Epoch 24, Loss: 1.5716941356658936, Accuracy: 59.19841384887695, Test Loss: 1.6284490823745728, Test Accuracy: 53.158729553222656\n",
      "Epoch 25, Loss: 1.5711344480514526, Accuracy: 59.249996185302734, Test Loss: 1.6264746189117432, Test Accuracy: 53.46031951904297\n",
      "Epoch 26, Loss: 1.5713274478912354, Accuracy: 59.30158615112305, Test Loss: 1.6235709190368652, Test Accuracy: 53.58729934692383\n",
      "Epoch 27, Loss: 1.5677858591079712, Accuracy: 59.68254089355469, Test Loss: 1.6208888292312622, Test Accuracy: 54.19047546386719\n",
      "Epoch 28, Loss: 1.5636168718338013, Accuracy: 60.11111068725586, Test Loss: 1.6178044080734253, Test Accuracy: 54.0476188659668\n",
      "Epoch 29, Loss: 1.5624351501464844, Accuracy: 60.0555534362793, Test Loss: 1.6147944927215576, Test Accuracy: 54.396827697753906\n",
      "Epoch 30, Loss: 1.5594905614852905, Accuracy: 60.468257904052734, Test Loss: 1.6205763816833496, Test Accuracy: 53.888885498046875\n",
      "Epoch 31, Loss: 1.5595780611038208, Accuracy: 60.44444274902344, Test Loss: 1.626327395439148, Test Accuracy: 53.31745910644531\n",
      "Epoch 32, Loss: 1.5565717220306396, Accuracy: 60.71428680419922, Test Loss: 1.6126278638839722, Test Accuracy: 54.619049072265625\n",
      "Epoch 33, Loss: 1.5486565828323364, Accuracy: 61.57143020629883, Test Loss: 1.6091312170028687, Test Accuracy: 55.0476188659668\n",
      "Epoch 34, Loss: 1.5470679998397827, Accuracy: 61.7103157043457, Test Loss: 1.6065837144851685, Test Accuracy: 55.333335876464844\n",
      "Epoch 35, Loss: 1.5419141054153442, Accuracy: 62.17856979370117, Test Loss: 1.6052166223526, Test Accuracy: 55.349205017089844\n",
      "Epoch 36, Loss: 1.535402536392212, Accuracy: 62.900794982910156, Test Loss: 1.599481463432312, Test Accuracy: 56.015872955322266\n",
      "Epoch 37, Loss: 1.5305057764053345, Accuracy: 63.507938385009766, Test Loss: 1.594335675239563, Test Accuracy: 56.5396842956543\n",
      "Epoch 38, Loss: 1.5319936275482178, Accuracy: 63.28174591064453, Test Loss: 1.589216947555542, Test Accuracy: 57.03174591064453\n",
      "Epoch 39, Loss: 1.529220700263977, Accuracy: 63.44841003417969, Test Loss: 1.5867087841033936, Test Accuracy: 57.42856979370117\n",
      "Epoch 40, Loss: 1.5265228748321533, Accuracy: 63.80555725097656, Test Loss: 1.587743878364563, Test Accuracy: 57.33333206176758\n",
      "Epoch 41, Loss: 1.525277853012085, Accuracy: 63.96428298950195, Test Loss: 1.5813820362091064, Test Accuracy: 58.09524154663086\n",
      "Epoch 42, Loss: 1.5213851928710938, Accuracy: 64.41666412353516, Test Loss: 1.5712658166885376, Test Accuracy: 58.9682502746582\n",
      "Epoch 43, Loss: 1.5198596715927124, Accuracy: 64.39682006835938, Test Loss: 1.5787086486816406, Test Accuracy: 58.238094329833984\n",
      "Epoch 44, Loss: 1.5119234323501587, Accuracy: 65.25, Test Loss: 1.5801138877868652, Test Accuracy: 58.0\n",
      "Epoch 45, Loss: 1.512075662612915, Accuracy: 65.19444274902344, Test Loss: 1.5751991271972656, Test Accuracy: 58.761905670166016\n",
      "Epoch 46, Loss: 1.5105646848678589, Accuracy: 65.36508178710938, Test Loss: 1.5733532905578613, Test Accuracy: 59.11111068725586\n",
      "Epoch 47, Loss: 1.507889986038208, Accuracy: 65.63491821289062, Test Loss: 1.5723038911819458, Test Accuracy: 58.82539749145508\n",
      "Epoch 48, Loss: 1.5056145191192627, Accuracy: 65.9126968383789, Test Loss: 1.5730719566345215, Test Accuracy: 58.603172302246094\n",
      "Epoch 49, Loss: 1.5064222812652588, Accuracy: 65.9206314086914, Test Loss: 1.5778552293777466, Test Accuracy: 58.158729553222656\n",
      "Epoch 50, Loss: 1.5038939714431763, Accuracy: 66.11111450195312, Test Loss: 1.5698846578598022, Test Accuracy: 59.079368591308594\n",
      "Epoch 51, Loss: 1.5046000480651855, Accuracy: 66.0, Test Loss: 1.5769413709640503, Test Accuracy: 58.42857360839844\n",
      "Epoch 52, Loss: 1.5012290477752686, Accuracy: 66.34920501708984, Test Loss: 1.5590182542800903, Test Accuracy: 60.095237731933594\n",
      "Epoch 53, Loss: 1.4996232986450195, Accuracy: 66.5079345703125, Test Loss: 1.5711472034454346, Test Accuracy: 58.58729934692383\n",
      "Epoch 54, Loss: 1.4988728761672974, Accuracy: 66.59920501708984, Test Loss: 1.5703740119934082, Test Accuracy: 58.80952453613281\n",
      "Epoch 55, Loss: 1.4996063709259033, Accuracy: 66.4047622680664, Test Loss: 1.5677298307418823, Test Accuracy: 59.25396728515625\n",
      "Epoch 56, Loss: 1.4956640005111694, Accuracy: 66.90079498291016, Test Loss: 1.5713772773742676, Test Accuracy: 58.79365158081055\n",
      "Epoch 57, Loss: 1.4959571361541748, Accuracy: 66.80158996582031, Test Loss: 1.5631152391433716, Test Accuracy: 59.730159759521484\n",
      "Epoch 58, Loss: 1.493115782737732, Accuracy: 67.16667175292969, Test Loss: 1.569283127784729, Test Accuracy: 59.0317497253418\n",
      "Epoch 59, Loss: 1.490578293800354, Accuracy: 67.42063903808594, Test Loss: 1.5688085556030273, Test Accuracy: 59.158729553222656\n",
      "Epoch 60, Loss: 1.4940606355667114, Accuracy: 67.07539367675781, Test Loss: 1.5634132623672485, Test Accuracy: 59.79365158081055\n",
      "Training cnn\n",
      "Epoch 1, Loss: 1.8205970525741577, Accuracy: 32.74603271484375, Test Loss: 1.6964936256408691, Test Accuracy: 46.63492202758789\n",
      "Epoch 2, Loss: 1.6551377773284912, Accuracy: 51.36507797241211, Test Loss: 1.6259857416152954, Test Accuracy: 53.90475845336914\n",
      "Epoch 3, Loss: 1.610402226448059, Accuracy: 55.722225189208984, Test Loss: 1.6029269695281982, Test Accuracy: 55.79364776611328\n",
      "Epoch 4, Loss: 1.593875765800476, Accuracy: 57.0476188659668, Test Loss: 1.5886155366897583, Test Accuracy: 57.39682388305664\n",
      "Epoch 5, Loss: 1.583003044128418, Accuracy: 58.14682388305664, Test Loss: 1.5769870281219482, Test Accuracy: 58.74603271484375\n",
      "Epoch 6, Loss: 1.5726213455200195, Accuracy: 59.32142639160156, Test Loss: 1.5809215307235718, Test Accuracy: 57.984127044677734\n",
      "Epoch 7, Loss: 1.5519452095031738, Accuracy: 61.39682388305664, Test Loss: 1.567820429801941, Test Accuracy: 59.06349563598633\n",
      "Epoch 8, Loss: 1.5383294820785522, Accuracy: 62.80158615112305, Test Loss: 1.5604956150054932, Test Accuracy: 59.873016357421875\n",
      "Epoch 9, Loss: 1.5305546522140503, Accuracy: 63.599205017089844, Test Loss: 1.5494579076766968, Test Accuracy: 61.17460250854492\n",
      "Epoch 10, Loss: 1.5246562957763672, Accuracy: 64.1706314086914, Test Loss: 1.5420318841934204, Test Accuracy: 62.03174591064453\n",
      "Epoch 11, Loss: 1.5213356018066406, Accuracy: 64.4206314086914, Test Loss: 1.5401062965393066, Test Accuracy: 62.0476188659668\n",
      "Epoch 12, Loss: 1.5172719955444336, Accuracy: 64.88888549804688, Test Loss: 1.5385018587112427, Test Accuracy: 61.984127044677734\n",
      "Epoch 13, Loss: 1.5133931636810303, Accuracy: 65.18253326416016, Test Loss: 1.5361140966415405, Test Accuracy: 62.26984405517578\n",
      "Epoch 14, Loss: 1.510713815689087, Accuracy: 65.51587677001953, Test Loss: 1.5334323644638062, Test Accuracy: 62.30158996582031\n",
      "Epoch 15, Loss: 1.5077431201934814, Accuracy: 65.8531723022461, Test Loss: 1.531959891319275, Test Accuracy: 62.85714340209961\n",
      "Epoch 16, Loss: 1.505398154258728, Accuracy: 66.12301635742188, Test Loss: 1.528620719909668, Test Accuracy: 63.349205017089844\n",
      "Epoch 17, Loss: 1.5033793449401855, Accuracy: 66.42459869384766, Test Loss: 1.5267921686172485, Test Accuracy: 63.222225189208984\n",
      "Epoch 18, Loss: 1.5014824867248535, Accuracy: 66.5, Test Loss: 1.525681734085083, Test Accuracy: 63.269840240478516\n",
      "Epoch 19, Loss: 1.4995676279067993, Accuracy: 66.72618865966797, Test Loss: 1.5290991067886353, Test Accuracy: 63.0476188659668\n",
      "Epoch 20, Loss: 1.4985460042953491, Accuracy: 66.81349182128906, Test Loss: 1.528944969177246, Test Accuracy: 63.015872955322266\n",
      "Epoch 21, Loss: 1.4961968660354614, Accuracy: 66.95634460449219, Test Loss: 1.5221208333969116, Test Accuracy: 63.841270446777344\n",
      "Epoch 22, Loss: 1.4939364194869995, Accuracy: 67.20634460449219, Test Loss: 1.521616816520691, Test Accuracy: 64.03174591064453\n",
      "Epoch 23, Loss: 1.4935051202774048, Accuracy: 67.16667175292969, Test Loss: 1.5190637111663818, Test Accuracy: 64.03174591064453\n",
      "Epoch 24, Loss: 1.492576003074646, Accuracy: 67.28968048095703, Test Loss: 1.5282565355300903, Test Accuracy: 62.841270446777344\n",
      "Epoch 25, Loss: 1.4905742406845093, Accuracy: 67.5079345703125, Test Loss: 1.5226833820343018, Test Accuracy: 63.841270446777344\n",
      "Epoch 26, Loss: 1.4899766445159912, Accuracy: 67.51587677001953, Test Loss: 1.5247790813446045, Test Accuracy: 63.39682388305664\n",
      "Epoch 27, Loss: 1.4887590408325195, Accuracy: 67.59127044677734, Test Loss: 1.5144423246383667, Test Accuracy: 64.36507415771484\n",
      "Epoch 28, Loss: 1.4875481128692627, Accuracy: 67.67063903808594, Test Loss: 1.5202029943466187, Test Accuracy: 63.77777862548828\n",
      "Epoch 29, Loss: 1.4867171049118042, Accuracy: 67.84127044677734, Test Loss: 1.5148608684539795, Test Accuracy: 64.17460632324219\n",
      "Epoch 30, Loss: 1.4851146936416626, Accuracy: 68.03571319580078, Test Loss: 1.5303202867507935, Test Accuracy: 63.111106872558594\n",
      "Epoch 31, Loss: 1.4850728511810303, Accuracy: 67.99603271484375, Test Loss: 1.5230278968811035, Test Accuracy: 63.69841003417969\n",
      "Epoch 32, Loss: 1.4832193851470947, Accuracy: 68.19444274902344, Test Loss: 1.5146440267562866, Test Accuracy: 64.53968048095703\n",
      "Epoch 33, Loss: 1.4817044734954834, Accuracy: 68.28571319580078, Test Loss: 1.518212080001831, Test Accuracy: 64.19047546386719\n",
      "Epoch 34, Loss: 1.4795432090759277, Accuracy: 68.61508178710938, Test Loss: 1.5157761573791504, Test Accuracy: 64.30158996582031\n",
      "Epoch 35, Loss: 1.4777034521102905, Accuracy: 68.80158996582031, Test Loss: 1.5218347311019897, Test Accuracy: 63.476192474365234\n",
      "Epoch 36, Loss: 1.4782270193099976, Accuracy: 68.734130859375, Test Loss: 1.516655445098877, Test Accuracy: 64.47618865966797\n",
      "Epoch 37, Loss: 1.476994276046753, Accuracy: 68.8452377319336, Test Loss: 1.524524211883545, Test Accuracy: 63.349205017089844\n",
      "Epoch 38, Loss: 1.4755809307098389, Accuracy: 68.93650817871094, Test Loss: 1.516068935394287, Test Accuracy: 64.31745910644531\n",
      "Epoch 39, Loss: 1.4751986265182495, Accuracy: 69.0, Test Loss: 1.515860915184021, Test Accuracy: 64.41270446777344\n",
      "Epoch 40, Loss: 1.4737073183059692, Accuracy: 69.20635223388672, Test Loss: 1.5186963081359863, Test Accuracy: 64.19047546386719\n",
      "Epoch 41, Loss: 1.473687767982483, Accuracy: 69.15079498291016, Test Loss: 1.520444631576538, Test Accuracy: 63.841270446777344\n",
      "Epoch 42, Loss: 1.4724414348602295, Accuracy: 69.27777862548828, Test Loss: 1.5138555765151978, Test Accuracy: 64.63491821289062\n",
      "Epoch 43, Loss: 1.4721038341522217, Accuracy: 69.31745910644531, Test Loss: 1.5185880661010742, Test Accuracy: 64.14286041259766\n",
      "Epoch 44, Loss: 1.4738836288452148, Accuracy: 69.06745910644531, Test Loss: 1.5169764757156372, Test Accuracy: 64.47618865966797\n",
      "Epoch 45, Loss: 1.4702550172805786, Accuracy: 69.56745910644531, Test Loss: 1.5143418312072754, Test Accuracy: 64.66666412353516\n",
      "Epoch 46, Loss: 1.4715627431869507, Accuracy: 69.23015594482422, Test Loss: 1.5158103704452515, Test Accuracy: 64.61904907226562\n",
      "Epoch 47, Loss: 1.4699143171310425, Accuracy: 69.45237731933594, Test Loss: 1.516015887260437, Test Accuracy: 64.4920654296875\n",
      "Epoch 48, Loss: 1.4698936939239502, Accuracy: 69.6111068725586, Test Loss: 1.5123765468597412, Test Accuracy: 64.79365539550781\n",
      "Epoch 49, Loss: 1.4683470726013184, Accuracy: 69.69444274902344, Test Loss: 1.514603614807129, Test Accuracy: 64.52381134033203\n",
      "Epoch 50, Loss: 1.4680800437927246, Accuracy: 69.69444274902344, Test Loss: 1.5119434595108032, Test Accuracy: 64.87301635742188\n",
      "Epoch 51, Loss: 1.4680440425872803, Accuracy: 69.77381134033203, Test Loss: 1.515863299369812, Test Accuracy: 64.46031951904297\n",
      "Epoch 52, Loss: 1.467574119567871, Accuracy: 69.78174591064453, Test Loss: 1.5122812986373901, Test Accuracy: 64.84127044677734\n",
      "Epoch 53, Loss: 1.4660099744796753, Accuracy: 69.82936096191406, Test Loss: 1.5117307901382446, Test Accuracy: 64.73016357421875\n",
      "Epoch 54, Loss: 1.465410828590393, Accuracy: 69.95635223388672, Test Loss: 1.5092860460281372, Test Accuracy: 65.0\n",
      "Epoch 55, Loss: 1.465101718902588, Accuracy: 70.04365539550781, Test Loss: 1.5057181119918823, Test Accuracy: 65.57142639160156\n",
      "Epoch 56, Loss: 1.4653340578079224, Accuracy: 69.98015594482422, Test Loss: 1.5125902891159058, Test Accuracy: 64.88888549804688\n",
      "Epoch 57, Loss: 1.4636436700820923, Accuracy: 70.22222137451172, Test Loss: 1.5129601955413818, Test Accuracy: 64.76190948486328\n",
      "Epoch 58, Loss: 1.4652886390686035, Accuracy: 69.97222137451172, Test Loss: 1.515792965888977, Test Accuracy: 64.42857360839844\n",
      "Epoch 59, Loss: 1.464941382408142, Accuracy: 70.04761505126953, Test Loss: 1.5106358528137207, Test Accuracy: 64.93650817871094\n",
      "Epoch 60, Loss: 1.4630436897277832, Accuracy: 70.19841003417969, Test Loss: 1.5157885551452637, Test Accuracy: 64.26984405517578\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 60\n",
    "models = ['mlp','mlpbeta','cnn']\n",
    "\n",
    "for model in models:\n",
    "    print('Training ' + model)\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "\n",
    "        # Train MLP\n",
    "        if model == 'mlp':\n",
    "            for x, y in trainmlp_ds:\n",
    "                train_mlp(x, y, mlp, loss_fn, optimizer, train_loss, train_accuracy)\n",
    "            for x_test, y_test in testmlp_ds:\n",
    "                test_mlp(x_test, y_test, mlp, loss_fn, test_loss, test_accuracy)\n",
    "        # Train MLP Beta\n",
    "        elif model == 'mlpbeta':\n",
    "            for x, y in trainmlp_ds:\n",
    "                train_mlpbeta(x, y, mlp_beta, loss_fn, optimizer, train_loss, train_accuracy)\n",
    "            for x_test, y_test in testmlp_ds:\n",
    "                test_mlpbeta(x_test, y_test, mlp_beta, loss_fn, test_loss, test_accuracy)\n",
    "        # Train CNN\n",
    "        elif model == 'cnn':\n",
    "            for x, y in traincnn_ds:\n",
    "                train_cnn(x, y, cnn, loss_fn, optimizer, train_loss, train_accuracy)\n",
    "            for x_test, y_test in testcnn_ds:\n",
    "                test_cnn(x_test, y_test, cnn, loss_fn, test_loss, test_accuracy)\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}, '\n",
    "            f'Loss: {train_loss.result()}, '\n",
    "            f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "            f'Test Loss: {test_loss.result()}, '\n",
    "            f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_enc = mlp.get_layer(name='enc')\n",
    "mlpbeta_enc = mlp_beta.get_layer(name='enc')\n",
    "cnn_enc = cnn.get_layer(name='enc')\n",
    "\n",
    "mlp_aligned = mlp_enc(x_train_noise_mlp).numpy()\n",
    "mlp_beta_aligned = mlpbeta_enc(x_train_noise_mlp).numpy()\n",
    "cnn_aligned = cnn_enc(x_train_noise_cnn).numpy()\n",
    "\n",
    "y_train_aligned = np.argmax(y_train_clean, axis=1)[...,np.newaxis]\n",
    "w_mlp, c_mlp,_, _, _ = train_lda(mlp_aligned,y_train_aligned)\n",
    "w_mlpbeta, c_mlpbeta,_, _, _ = train_lda(mlp_beta_aligned,y_train_aligned)\n",
    "w_cnn, c_cnn,_, _, _ = train_lda(cnn_aligned,y_train_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: traindata_manual/AB2_traindata_4.p\n",
      "MLP ---- Clean Accuracy: 76.31, Noisy Accuracy: 61.20, LDA Clean Accuracy: 73.74, LDA Noisy Accuracy: 60.20\n",
      "MLPB ---- Clean Accuracy: 84.40, Noisy Accuracy: 62.06, LDA Clean Accuracy: 86.57, LDA Noisy Accuracy: 59.66\n",
      "CNN ---- Clean Accuracy: 86.03, Noisy Accuracy: 66.46, LDA Clean Accuracy: 88.00, LDA Noisy Accuracy: 63.97\n"
     ]
    }
   ],
   "source": [
    "test_grp = 4\n",
    "cv_type = 'manual'\n",
    "n_test = 'partposrealmixeven24'\n",
    "\n",
    "with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "    real_noise_temp, _ = pickle.load(f)\n",
    "\n",
    "_, x_test, _, _, p_test, _ = prd.train_data_split(raw,params,sub,sub_type,dt=cv_type,train_grp=test_grp)\n",
    "clean_size = int(np.size(x_test,axis=0))\n",
    "x_test = x_test*emg_scale\n",
    "\n",
    "x_test_noise, x_test_clean, y_test_clean = prd.add_noise(x_test, p_test, sub, n_test, 1, real_noise=real_noise_temp, emg_scale = emg_scale)\n",
    "x_test_cnn, _ = prd.extract_scale(x_test_noise,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_test_cnn = x_test_cnn.astype('float32')\n",
    "x_test_mlp = x_test_cnn.reshape(x_test_cnn.shape[0],-1)\n",
    "\n",
    "mlp_test_aligned = mlp_enc(x_test_mlp).numpy()\n",
    "mlpbeta_test_aligned = mlpbeta_enc(x_test_mlp).numpy()\n",
    "cnn_test_aligned = cnn_enc(x_test_cnn).numpy()\n",
    "y_test_aligned = np.argmax(y_test_clean, axis=1)[...,np.newaxis]\n",
    "\n",
    "clean_acc, noisy_acc = eval_nn(x_test_mlp, y_test_clean,mlp,clean_size)\n",
    "clean_lda = eval_lda(w_mlp,c_mlp,mlp_test_aligned[:clean_size,...],y_test_aligned[:clean_size,...])\n",
    "noisy_lda = eval_lda(w_mlp,c_mlp,mlp_test_aligned[clean_size:,...],y_test_aligned[clean_size:,...])\n",
    "print(\n",
    "    f'MLP ---- '\n",
    "    f'Clean Accuracy: {clean_acc * 100:.2f}, '\n",
    "    f'Noisy Accuracy: {noisy_acc * 100:.2f}, '\n",
    "    f'LDA Clean Accuracy: {clean_lda * 100:.2f}, '\n",
    "    f'LDA Noisy Accuracy: {noisy_lda * 100:.2f}'\n",
    ")\n",
    "\n",
    "clean_acc, noisy_acc = eval_nn(x_test_mlp, y_test_clean,mlp_beta,clean_size)\n",
    "clean_lda = eval_lda(w_mlpbeta,c_mlpbeta,mlpbeta_test_aligned[:clean_size,...],y_test_aligned[:clean_size,...])\n",
    "noisy_lda = eval_lda(w_mlpbeta,c_mlpbeta,mlpbeta_test_aligned[clean_size:,...],y_test_aligned[clean_size:,...])\n",
    "print(\n",
    "    f'MLPB ---- '\n",
    "    f'Clean Accuracy: {clean_acc * 100:.2f}, '\n",
    "    f'Noisy Accuracy: {noisy_acc * 100:.2f}, '\n",
    "    f'LDA Clean Accuracy: {clean_lda * 100:.2f}, '\n",
    "    f'LDA Noisy Accuracy: {noisy_lda * 100:.2f}'\n",
    ")\n",
    "\n",
    "clean_acc, noisy_acc = eval_nn(x_test_cnn, y_test_clean,cnn,clean_size)\n",
    "clean_lda = eval_lda(w_cnn,c_cnn,cnn_test_aligned[:clean_size,...],y_test_aligned[:clean_size,...])\n",
    "noisy_lda = eval_lda(w_cnn,c_cnn,cnn_test_aligned[clean_size:,...],y_test_aligned[clean_size:,...])\n",
    "print(\n",
    "    f'CNN ---- '\n",
    "    f'Clean Accuracy: {clean_acc * 100:.2f}, '\n",
    "    f'Noisy Accuracy: {noisy_acc * 100:.2f}, '\n",
    "    f'LDA Clean Accuracy: {clean_lda * 100:.2f}, '\n",
    "    f'LDA Noisy Accuracy: {noisy_lda * 100:.2f}'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a3b9df806ffb9c99dfd499571232d2e3ccda8a03627b2b254cd16611a407c53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf-2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
