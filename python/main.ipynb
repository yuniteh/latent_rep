{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import os\n",
    "import copy as cp\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from DL_utils import MLP, MLPbeta, CNN\n",
    "\n",
    "import process_data as prd\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'TR'\n",
    "with open('train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: traindata_manual/TR1_traindata_2.p\n"
     ]
    }
   ],
   "source": [
    "## Training \n",
    "sub = 1\n",
    "train_grp = 2\n",
    "n_train = 'fullallmix4'\n",
    "train_scale = 5\n",
    "cv_type = 'manual'\n",
    "scaler_load = False\n",
    "feat_type = 'feat'\n",
    "\n",
    "ind = (params[:,0] == sub) & (params[:,3] == train_grp)\n",
    "\n",
    "x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,sub_type,dt=cv_type,load=True,train_grp=train_grp)\n",
    "\n",
    "emg_scale = np.ones((np.size(x_train,1),1))\n",
    "for i in range(np.size(x_train,1)):\n",
    "    emg_scale[i] = 5/np.max(np.abs(x_train[:,i,:]))\n",
    "x_train = x_train*emg_scale\n",
    "x_valid = x_valid*emg_scale\n",
    "\n",
    "x_train_noise, x_train_clean, y_train_clean = prd.add_noise(x_train, p_train, sub, n_train, train_scale)\n",
    "x_valid_noise, x_valid_clean, y_valid_clean = prd.add_noise(x_train, p_train, sub, n_train, train_scale)\n",
    "\n",
    "x_train_noise[x_train_noise > 5] = 5\n",
    "x_train_noise[x_train_noise < -5] = -5\n",
    "x_train_clean[x_train_clean > 5] = 5\n",
    "x_train_clean[x_train_clean < -5] = -5\n",
    "\n",
    "x_valid_noise[x_valid_noise > 5] = 5\n",
    "x_valid_noise[x_valid_noise < -5] = -5\n",
    "x_valid_clean[x_valid_clean > 5] = 5\n",
    "x_valid_clean[x_valid_clean < -5] = -5\n",
    "\n",
    "# shuffle data to make even batches\n",
    "x_train_noise, x_train_clean, y_train_clean = shuffle(x_train_noise, x_train_clean, y_train_clean, random_state = 0)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Extract features\n",
    "x_train_noise_cnn, scaler = prd.extract_scale(x_train_noise,scaler,scaler_load,ft=feat_type,emg_scale=emg_scale) \n",
    "x_train_clean_cnn, _ = prd.extract_scale(x_train_clean,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_valid_noise_cnn, _ = prd.extract_scale(x_valid_noise,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "x_valid_clean_cnn, _ = prd.extract_scale(x_valid_clean,scaler,ft=feat_type,emg_scale=emg_scale)\n",
    "\n",
    "# reshape data for nonconvolutional network\n",
    "x_train_noise_mlp = x_train_noise_cnn.reshape(x_train_noise_cnn.shape[0],-1).astype('float32')\n",
    "x_valid_noise_mlp = x_valid_noise_cnn.reshape(x_valid_noise_cnn.shape[0],-1).astype('float32')\n",
    "\n",
    "# create batches\n",
    "trainmlp_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_mlp, y_train_clean)).batch(128)\n",
    "testmlp_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_mlp, y_valid_clean)).batch(128)\n",
    "traincnn_ds = tf.data.Dataset.from_tensor_slices((x_train_noise_cnn.astype('float32'), y_train_clean)).batch(128)\n",
    "testcnn_ds = tf.data.Dataset.from_tensor_slices((x_valid_noise_cnn.astype('float32'), y_valid_clean)).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "mlp_beta = MLPbeta()\n",
    "cnn = CNN()\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "## TRAIN TEST MLP\n",
    "@tf.function\n",
    "def train_mlp(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_out = mlp(x)\n",
    "    loss = loss_fn(y, y_out)\n",
    "  gradients = tape.gradient(loss, mlp.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, mlp.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_mlp(x, y):\n",
    "  y_out = mlp(x)\n",
    "  t_loss = loss_fn(y, y_out)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(y, y_out)\n",
    "\n",
    "## TRAIN TEST MLP BETA\n",
    "@tf.function\n",
    "def train_mlpbeta(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_out = mlp_beta(x)\n",
    "    loss = loss_fn(y, y_out)\n",
    "  gradients = tape.gradient(loss, mlp_beta.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, mlp_beta.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_mlpbeta(x, y):\n",
    "  y_out = mlp_beta(x)\n",
    "  t_loss = loss_fn(y, y_out)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(y, y_out)\n",
    "\n",
    "## TRAIN TEST CNN\n",
    "@tf.function\n",
    "def train_cnn(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_out = cnn(x)\n",
    "    loss = loss_fn(y, y_out)\n",
    "  gradients = tape.gradient(loss, cnn.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, cnn.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(y, y_out)\n",
    "\n",
    "@tf.function\n",
    "def test_cnn(x, y):\n",
    "  y_out = cnn(x)\n",
    "  t_loss = loss_fn(y, y_out)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(y, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp\n",
      "Epoch 1, Loss: 1.9034225940704346, Accuracy: 21.26984214782715, Test Loss: 1.8293886184692383, Test Accuracy: 31.85317611694336\n",
      "Epoch 2, Loss: 1.8008241653442383, Accuracy: 34.1944465637207, Test Loss: 1.777256727218628, Test Accuracy: 38.0079345703125\n",
      "Epoch 3, Loss: 1.7644926309585571, Accuracy: 38.587303161621094, Test Loss: 1.7517445087432861, Test Accuracy: 39.849205017089844\n",
      "Epoch 4, Loss: 1.7467396259307861, Accuracy: 39.82936477661133, Test Loss: 1.7399359941482544, Test Accuracy: 41.511905670166016\n",
      "Epoch 5, Loss: 1.735770583152771, Accuracy: 41.66270065307617, Test Loss: 1.729448914527893, Test Accuracy: 42.82539749145508\n",
      "Epoch 6, Loss: 1.7257333993911743, Accuracy: 43.07142639160156, Test Loss: 1.7185297012329102, Test Accuracy: 44.17460250854492\n",
      "Epoch 7, Loss: 1.7110884189605713, Accuracy: 44.984127044677734, Test Loss: 1.6991959810256958, Test Accuracy: 46.22222137451172\n",
      "Epoch 8, Loss: 1.6936591863632202, Accuracy: 46.86507797241211, Test Loss: 1.681715726852417, Test Accuracy: 48.43254089355469\n",
      "Epoch 9, Loss: 1.6766983270645142, Accuracy: 48.53571319580078, Test Loss: 1.663426160812378, Test Accuracy: 50.05952072143555\n",
      "Epoch 10, Loss: 1.660576581954956, Accuracy: 49.984127044677734, Test Loss: 1.653201699256897, Test Accuracy: 50.380950927734375\n",
      "Training mlpbeta\n",
      "Epoch 1, Loss: 1.8244006633758545, Accuracy: 30.7738094329834, Test Loss: 1.7730284929275513, Test Accuracy: 36.57539749145508\n",
      "Epoch 2, Loss: 1.732863426208496, Accuracy: 41.70635223388672, Test Loss: 1.6898136138916016, Test Accuracy: 46.599205017089844\n",
      "Epoch 3, Loss: 1.6764869689941406, Accuracy: 47.666664123535156, Test Loss: 1.66713285446167, Test Accuracy: 48.77777862548828\n",
      "Epoch 4, Loss: 1.6505091190338135, Accuracy: 50.527774810791016, Test Loss: 1.6477515697479248, Test Accuracy: 51.027774810791016\n",
      "Epoch 5, Loss: 1.6339173316955566, Accuracy: 52.265869140625, Test Loss: 1.6347905397415161, Test Accuracy: 52.23412322998047\n",
      "Epoch 6, Loss: 1.6187971830368042, Accuracy: 53.86904525756836, Test Loss: 1.6196215152740479, Test Accuracy: 54.011905670166016\n",
      "Epoch 7, Loss: 1.6042059659957886, Accuracy: 55.43650817871094, Test Loss: 1.6178252696990967, Test Accuracy: 53.81349182128906\n",
      "Epoch 8, Loss: 1.5995622873306274, Accuracy: 55.857147216796875, Test Loss: 1.5816831588745117, Test Accuracy: 57.92063522338867\n",
      "Epoch 9, Loss: 1.5847721099853516, Accuracy: 57.46031951904297, Test Loss: 1.5786211490631104, Test Accuracy: 58.15079116821289\n",
      "Epoch 10, Loss: 1.5740342140197754, Accuracy: 58.380950927734375, Test Loss: 1.5626038312911987, Test Accuracy: 59.79365158081055\n",
      "Training cnn\n",
      "Epoch 1, Loss: 1.7709814310073853, Accuracy: 37.873016357421875, Test Loss: 1.6402966976165771, Test Accuracy: 52.30952453613281\n",
      "Epoch 2, Loss: 1.5751768350601196, Accuracy: 59.376983642578125, Test Loss: 1.5320870876312256, Test Accuracy: 63.634918212890625\n",
      "Epoch 3, Loss: 1.4925163984298706, Accuracy: 67.5873031616211, Test Loss: 1.4772361516952515, Test Accuracy: 69.06745910644531\n",
      "Epoch 4, Loss: 1.4606964588165283, Accuracy: 70.77777862548828, Test Loss: 1.4540760517120361, Test Accuracy: 71.4206314086914\n",
      "Epoch 5, Loss: 1.4435850381851196, Accuracy: 72.44841766357422, Test Loss: 1.4398208856582642, Test Accuracy: 72.76190185546875\n",
      "Epoch 6, Loss: 1.430701732635498, Accuracy: 73.65079498291016, Test Loss: 1.4244334697723389, Test Accuracy: 74.43254089355469\n",
      "Epoch 7, Loss: 1.4208165407180786, Accuracy: 74.69047546386719, Test Loss: 1.4189759492874146, Test Accuracy: 74.8611068725586\n",
      "Epoch 8, Loss: 1.4149283170700073, Accuracy: 75.15872955322266, Test Loss: 1.4092408418655396, Test Accuracy: 75.79365539550781\n",
      "Epoch 9, Loss: 1.4078725576400757, Accuracy: 75.94047546386719, Test Loss: 1.4041743278503418, Test Accuracy: 76.24603271484375\n",
      "Epoch 10, Loss: 1.4026716947555542, Accuracy: 76.47222137451172, Test Loss: 1.4022616147994995, Test Accuracy: 76.50396728515625\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "models = ['mlp','mlpbeta','cnn']\n",
    "\n",
    "for model in models:\n",
    "  print('Training ' + model)\n",
    "  # Train MLP\n",
    "  for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    if 'mlp' in model:\n",
    "      for x, y in trainmlp_ds:\n",
    "        # Train MLP\n",
    "        if model == 'mlp':\n",
    "          train_mlp(x, y)\n",
    "        # Train MLP Beta\n",
    "        elif model == 'mlpbeta':\n",
    "          train_mlpbeta(x,y)\n",
    "    else:\n",
    "      # Train CNN\n",
    "      for x, y in traincnn_ds:\n",
    "        train_cnn(x,y)\n",
    "\n",
    "    if 'mlp' in model:\n",
    "      for x_test, y_test in testmlp_ds:\n",
    "        # Train MLP\n",
    "        if model == 'mlp':\n",
    "          test_mlp(x_test, y_test)\n",
    "        # Train MLP Beta\n",
    "        elif model == 'mlpbeta':\n",
    "          test_mlpbeta(x_test, y_test)\n",
    "    else:\n",
    "      # Train CNN\n",
    "      for x_test, y_test in testcnn_ds:\n",
    "        test_cnn(x_test, y_test)\n",
    "\n",
    "    print(\n",
    "      f'Epoch {epoch + 1}, '\n",
    "      f'Loss: {train_loss.result()}, '\n",
    "      f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "      f'Test Loss: {test_loss.result()}, '\n",
    "      f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a3b9df806ffb9c99dfd499571232d2e3ccda8a03627b2b254cd16611a407c53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf-2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
