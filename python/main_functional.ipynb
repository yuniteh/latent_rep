{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import latent.loop as loop\n",
    "import latent.session_functional as session\n",
    "import latent.utils.plot_utils as plot_utils \n",
    "import latent.utils.stats_utils as stat\n",
    "import latent.utils.data_utils as prd\n",
    "import latent.ml.dl_functional as dl\n",
    "from latent.ml.lda import train_lda\n",
    "import os\n",
    "import copy as cp\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "set_gpu()\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "%matplotlib qt\n",
    "mpl.rc('font', family='serif') \n",
    "mpl.rc('font', serif='Palatino Linotype') \n",
    "mpl.rc('font', size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'AB'\n",
    "with open('traindata/train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through training\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim':4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "\n",
    "for i in range(5):\n",
    "    train_out = [None] * np.max(params[:,0])\n",
    "\n",
    "    # loop through subjects\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        print('sub: ' + str(sub_i))\n",
    "        train_out[sub_i-1] = train_sess.loop_cv(raw,params,sub=sub_i,mod=['all'])\n",
    "        gc.collect()\n",
    "    \n",
    "    with open('AB_aug_' + str(i) + '.p', 'wb') as f:\n",
    "        pickle.dump([train_out],f)\n",
    "    \n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_all = [None] * 5\n",
    "aug_all = [None] * 5\n",
    "for i in range(5):\n",
    "    with open('AB_timings_' + str(i)+ '.p', 'rb') as f:\n",
    "        time_all[i] = pickle.load(f)\n",
    "    with open('AB_aug_' + str(i)+ '.p', 'rb') as f:\n",
    "        aug_all[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sae = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_cnn = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_lda = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_aug = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "\n",
    "it = 0\n",
    "for i in range(5):\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        sum_sae[it] = time_all[i][0][sub_i-1]['sae_time'] + time_all[i][0][sub_i-1]['sae_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_cnn[it] = time_all[i][0][sub_i-1]['cnn_time'] + time_all[i][0][sub_i-1]['cnn_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_lda[it] = time_all[i][0][sub_i-1]['lda_time']\n",
    "        sum_aug[it] = time_all[i][0][sub_i-1]['aug lda time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        it += 1\n",
    "\n",
    "mean_sae = np.nanmean(sum_sae)\n",
    "mean_cnn = np.nanmean(sum_cnn)\n",
    "mean_lda = np.nanmean(sum_lda)\n",
    "mean_aug = np.nanmean(sum_aug)\n",
    "\n",
    "std_sae = np.nanstd(sum_sae)\n",
    "std_cnn = np.nanstd(sum_cnn)\n",
    "std_lda = np.nanstd(sum_lda)\n",
    "std_aug = np.nanstd(sum_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensions of inputs\n",
    "sub = 5\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim': 4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "\n",
    "\n",
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'posrealmixeven','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt': 'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict)\n",
    "ntype = 'posrealmixeven'\n",
    "addon = False\n",
    "traintest = 'trainnoise'\n",
    "\n",
    "if not addon:\n",
    "    x_clean_lda = np.array([]).reshape(0,6)\n",
    "    x_clean_noise = np.array([]).reshape(0,6)\n",
    "    x_clean_sae = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "    x_clean_cnn = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "    y_clean = np.array([]).reshape(0,1)\n",
    "    y_noise_clean = np.array([]).reshape(0,1)\n",
    "    max_i = 2\n",
    "\n",
    "    if traintest == 'testnoise':\n",
    "        x_noisy_lda = np.array([]).reshape(0,6)\n",
    "        x_noisy_noise = np.array([]).reshape(0,6)\n",
    "        x_noisy_sae = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "        x_noisy_cnn = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "        y_noisy = np.array([]).reshape(0,1)\n",
    "        max_i = 5\n",
    "\n",
    "if ntype == 'flat':\n",
    "    test_max = 2\n",
    "else:\n",
    "    test_max = 6\n",
    "\n",
    "for i in range(1,max_i):\n",
    "    if traintest == 'testnoise':\n",
    "        test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "        red_out = test_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    else:\n",
    "        red_out = train_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    for key,val in red_out.items():\n",
    "        exec(key + '=val')\n",
    "    x_clean_lda = np.vstack([x_test_lda_red[:clean_size_lda,:], x_clean_lda])\n",
    "    x_clean_noise = np.vstack([x_test_noise_red[:clean_size,:], x_clean_noise])\n",
    "    x_clean_sae = np.vstack([x_test_sae_red[:clean_size,:], x_clean_sae])\n",
    "    x_clean_cnn = np.vstack([x_test_cnn_red[:clean_size,:], x_clean_cnn])\n",
    "    y_clean = np.vstack([y_test[:clean_size_lda,:], y_clean])\n",
    "    y_noise_clean = np.vstack([y_test_noise[:clean_size,:], y_noise_clean])\n",
    "    print(clean_size)\n",
    "    print(clean_size_lda)\n",
    "\n",
    "    x_noisy_lda = np.vstack([x_test_lda_red[clean_size_lda:,:], x_noisy_lda])\n",
    "    x_noisy_noise = np.vstack([x_test_noise_red[clean_size:,:], x_noisy_noise])\n",
    "    x_noisy_sae = np.vstack([x_test_sae_red[clean_size:,:], x_noisy_sae])\n",
    "    x_noisy_cnn = np.vstack([x_test_cnn_red[clean_size:,:], x_noisy_cnn])\n",
    "    y_noisy = np.vstack([y_test[clean_size_lda:,:], y_noisy])\n",
    "\n",
    "x_all_lda = np.vstack([x_clean_lda,x_noisy_lda])\n",
    "x_all_noise = np.vstack([x_clean_noise,x_noisy_noise])\n",
    "x_all_sae = np.vstack([x_clean_sae,x_noisy_sae])\n",
    "x_all_cnn = np.vstack([x_clean_cnn,x_noisy_cnn])\n",
    "y_all = np.vstack([y_clean, y_noisy])\n",
    "\n",
    "lda_lims = tuple(np.vstack((np.min(x_all_lda[:,:3],axis=0),np.max(x_all_lda[:,:3],axis=0))).T)\n",
    "noise_lims = tuple(np.vstack((np.min(x_all_noise[:,:3],axis=0),np.max(x_all_noise[:,:3],axis=0))).T)\n",
    "sae_lims = tuple(np.vstack((np.min(x_all_sae[:,:3],axis=0),np.max(x_all_sae[:,:3],axis=0))).T)\n",
    "cnn_lims = tuple(np.vstack((np.min(x_all_cnn[:,:3],axis=0),np.max(x_all_cnn[:,:3],axis=0))).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced dimensions\n",
    "dim = 3\n",
    "train_downsamp = clean_size//clean_size_lda\n",
    "std_lim = False\n",
    "mult = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plot_utils.plot_latent_rep(x_clean_lda, y_clean,fig,loc=1,lims=lda_lims,downsamp=train_downsamp,dim=dim, lim_min=lda_min, lim_max=lda_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_noise, y_noise_clean,fig,loc=2,lims=noise_lims,downsamp=train_downsamp,dim=dim, lim_min=noise_min, lim_max=noise_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_sae, y_noise_clean,fig,loc=3,lims=sae_lims,dim=dim,downsamp=train_downsamp, lim_min=sae_min, lim_max=sae_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_cnn, y_noise_clean,fig,loc=4,lims=cnn_lims,dim=dim,downsamp=train_downsamp, lim_min=cnn_min, lim_max=cnn_max,std_lim=std_lim,mult = mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsamp = 2\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "lda_min, lda_max = plot_utils.plot_latent_rep(x_noisy_lda, y_noisy,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "noise_min, noise_max = plot_utils.plot_latent_rep(x_noisy_noise, y_noisy,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "sae_min, sae_max = plot_utils.plot_latent_rep(x_noisy_sae, y_noisy,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "cnn_min, cnn_max = plot_utils.plot_latent_rep(x_noisy_cnn, y_noisy,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_utils.plot_latent_rep(x_all_lda, y_all,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_noise, y_all,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_sae, y_all,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_cnn, y_all,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "    real_noise_temp, _ = pickle.load(f)\n",
    "    \n",
    "plot_utils.plot_all_noise(real_noise_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noise = ['breaknm','break','contact','move']\n",
    "\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(12, 4)) \n",
    "gs = gridspec.GridSpec(8, 3)\n",
    "\n",
    "for i in range(4):\n",
    "    ntype = 'posreal' + all_noise[i]\n",
    "    with open(sub_type + '_' + ntype + '1.p', 'rb') as f:\n",
    "        xtestnoise,xtest,y_out = pickle.load(f)\n",
    "    plot_utils.plot_noisy(xtestnoise,xtest,y_out,iter=i, gs=gs)\n",
    "\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.2, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_2_all_emgscalelim_noisescalelim/temp/AB1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB8_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB9_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB10_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB11_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB12_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB13_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB14_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB8_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB9_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB10_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB11_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB12_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB13_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB14_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB8_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB9_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB10_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB11_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB12_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB13_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB14_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB8_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB9_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB10_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB11_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB12_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB13_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/AB14_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:70: RuntimeWarning: Mean of empty slice\n",
      "C:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:71: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "# sub_type = 'AB'\n",
    "test_dict = {'sub_type':sub_type,'dt':'manual', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partgauss4','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "test_all = ['noisescalelim']\n",
    "load = True\n",
    "if load:\n",
    "    posi_max = 2\n",
    "else:\n",
    "    posi_max = 5\n",
    "\n",
    "for dt in dt_all:\n",
    "    test_sess.dt = dt\n",
    "    for j in range(1):\n",
    "        test_sess.mod_dt = mod_all[j]\n",
    "        test_sess.test_dt = test_all[j]\n",
    "        for posi in range(1,posi_max):\n",
    "            ntype = 'posrealmixeven'\n",
    "            \n",
    "            if not load:\n",
    "                ntype += str(posi)\n",
    "\n",
    "            if ntype[:3] == 'pos' and not load:\n",
    "                i_start = 4\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "            elif ntype == 'flat' or 'mix' in ntype or 'real' in ntype:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "            else:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "\n",
    "            for i in range(i_start,i_end):\n",
    "                if load and 'pos' in ntype:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "                else:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i)    \n",
    "\n",
    "                if load:\n",
    "                    for sub in range(1,np.max(params[:,0])+1):\n",
    "                        foldername = test_sess.create_foldername(ftype='results')\n",
    "                        foldername += '/temp'\n",
    "                        # foldername += '/jner_aug'\n",
    "                        filename = test_sess.create_filename(foldername, 1, sub)\n",
    "                        print(filename + '_' + test_sess.n_test)\n",
    "                        if os.path.isfile(filename + '_' + test_sess.n_test + '_subresults.p'):\n",
    "                            with open(filename + '_' + test_sess.n_test + '_subresults.p', 'rb') as f:\n",
    "                                temp_all, temp_noise, temp_clean = pickle.load(f)\n",
    "                            acc_all[sub-1,i-i_start,:,:], acc_clean[sub-1,i-i_start,:,:], acc_noise[sub-1,i-i_start,:,:] = np.squeeze(temp_all),np.squeeze(temp_clean),np.squeeze(temp_noise)\n",
    "                else:\n",
    "                    # test_out, x_test_noise, x_test_clean, y_test_clean = test_sess.loop_test(raw, params)\n",
    "                    test_out = test_sess.loop_test(raw, params)\n",
    "                    print(test_out)\n",
    "                    for key,val in test_out.items():\n",
    "                        exec(key + '=val')\n",
    "\n",
    "            ave_pos_noise= np.nanmean(acc_noise,axis=0)\n",
    "            ave_pos_clean = np.nanmean(acc_clean,axis=0)\n",
    "            ave_noise= np.nanmean(acc_noise,axis=2)\n",
    "            ave_clean = np.nanmean(acc_clean,axis=2)\n",
    "            ave_gauss_noise = np.nanmean(ave_noise,axis=0)\n",
    "            ave_gauss_clean = np.nanmean(ave_clean,axis=0)\n",
    "\n",
    "            if load:\n",
    "                plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type)\n",
    "\n",
    "            if 'gauss' in ntype:\n",
    "                ave_gauss= cp.deepcopy(ave_noise)\n",
    "            elif 'flat' in ntype:\n",
    "                ave_flat = cp.deepcopy(ave_noise)\n",
    "            elif '60hz' in ntype:\n",
    "                ave_60hz = cp.deepcopy(ave_noise)\n",
    "            elif 'mix' in ntype:\n",
    "                ave_mix = cp.deepcopy(ave_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_noise2 = cp.deepcopy(ave_noise)\n",
    "ave_clean2 = cp.deepcopy(ave_clean)\n",
    "acc_clean2 = cp.deepcopy(acc_clean)\n",
    "acc_noise2 = cp.deepcopy(acc_noise)\n",
    "# ave_mix2 = cp.deepcopy(ave_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_noise2[:,:,4] = ave_noise[:,:,6]\n",
    "ave_clean2[:,:,4] = ave_clean[:,:,6]\n",
    "ave_noise2[:,:,5] = ave_noise[:,:,7]\n",
    "ave_clean2[:,:,5] = ave_clean[:,:,7]\n",
    "acc_clean2[...,4] = acc_clean[...,6]\n",
    "acc_noise2[...,4] = acc_noise[...,6]\n",
    "acc_clean2[...,5] = acc_clean[...,7]\n",
    "acc_noise2[...,5] = acc_noise[...,7]\n",
    "# ave_mix2[:,:,4] = ave_mix[:,:,6]\n",
    "# ave_mix2[:,:,5] = ave_mix[:,:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_nn_results(ave_noise,ave_clean,ave_noise2, ave_clean2, test_sess.n_train,ntype,test_sess.sub_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yteh\\Documents\\work\\git\\projects\\latent_rep\\python\\latent\\utils\\plot_utils.py:358: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax[i].spines['top'].set_visible(False)\n"
     ]
    }
   ],
   "source": [
    "plot_utils.plot_aug_results(ave_noise,ave_clean,ave_noise2, ave_clean2, test_sess.n_train,ntype,test_sess.sub_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = 1/25.4 \n",
    "w = 210\n",
    "h = w/2\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*mm, h*mm)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2.75])\n",
    "plot_utils.plot_electrode_results_aug(ave_noise2,ave_clean2,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "diff_mix,c ,c1 = plot_utils.plot_summary_aug(ave_clean2,ave_noise2,gs=gs[1])\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "px = 1/plt.rcParams['figure.dpi']  # pixel in inches\n",
    "w = 1200\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*px, h*px)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "acc, std = plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "mm = 1/25.4 \n",
    "w = 200\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*mm, h*mm)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,0.2,200)\n",
    "temp = []\n",
    "gauss = []\n",
    "fig, ax = plt.subplots(11,1)\n",
    "for a in range(1,6):\n",
    "    temp.append(a*np.sin(2*np.pi*60*x))\n",
    "    gauss.append(np.random.normal(0,a,len(x)))\n",
    "    ax[a-1].plot(x*1000,temp[a-1],'b',label='A = ' + str(a))\n",
    "    ax[a+4].plot(x*1000,gauss[a-1],label='A = ' + str(a))\n",
    "\n",
    "ax[-1].plot(x*1000,np.zeros(x.shape))\n",
    "# ax.legend()\n",
    "for i in range(11):\n",
    "    if i > 0: \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_yticklabels([])\n",
    "    if i < 10:\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_xticklabels([])\n",
    "    ax[i].set_ylim([-5,5])\n",
    "    ax[i].set_xlim([0,200])\n",
    "ax[-1].set_xlabel('Time (ms)')\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent.ml.lda import predict, train_lda\n",
    "from latent.ml.dl_subclass import MLP, CNN\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partposrealmixeven14','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "sae_time = [None] * np.max(params[:,0])\n",
    "cnn_time = [None] * np.max(params[:,0])\n",
    "lda_time = [None] * np.max(params[:,0])\n",
    "aug_time = [None] * np.max(params[:,0])\n",
    "\n",
    "# set number of models to test\n",
    "mod_tot = 15\n",
    "# set testing noise type\n",
    "noise_type = test_sess.n_test[4:-1]\n",
    "print(noise_type)\n",
    "\n",
    "# load real_noise\n",
    "if 'real' in noise_type:\n",
    "    with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "        real_noise_temp, _ = pickle.load(f)\n",
    "\n",
    "cv_tot = 1\n",
    "test_sess.max_cv = cv_tot + 1\n",
    "\n",
    "filename = 0\n",
    "\n",
    "# Set folder\n",
    "foldername = test_sess.create_foldername()\n",
    "resultsfolder = test_sess.create_foldername(ftype='results')\n",
    "\n",
    "num_feats = 10\n",
    "\n",
    "# loop through subjects\n",
    "sub = 1\n",
    "# index based on training group and subject\n",
    "ind = (params[:,0] == sub) & (params[:,3] == test_sess.train_grp)\n",
    "\n",
    "# Check if training data exists\n",
    "if np.sum(ind):\n",
    "    # loop through cvs\n",
    "    filename = test_sess.create_filename(foldername, 1, sub)\n",
    "\n",
    "    x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,test_sess.sub_type,dt=test_sess.dt,train_grp=test_sess.train_grp)\n",
    "    filename = 'subclass/models/TR' + str(sub) + '_tdar'\n",
    "    with open(filename + '.p', 'rb') as f:\n",
    "        mlp_w, _, cnn_w, w_sae, c_sae, _, _, w_cnn, c_cnn, w, c, w_noise, c_noise, emg_scale, scaler, mu_class, C = pickle.load(f)\n",
    "    # Load saved data\n",
    "    # with open(filename + '.p', 'rb') as f:\n",
    "    #     scaler, svae_w, svae_enc_w, svae_dec_w, svae_clf_w, sae_w, sae_enc_w, sae_clf_w, cnn_w, cnn_enc_w, cnn_clf_w, vcnn_w, vcnn_enc_w, vcnn_clf_w, ecnn_w, ecnn_enc_w, ecnn_clf_w, w_svae, c_svae, w_sae, c_sae, w_cnn, c_cnn, w_vcnn, c_vcnn, w_ecnn, c_ecnn, w, c, w_noise, c_noise, mu, C, qda, qda_noise,emg_scale = pickle.load(f)   \n",
    "\n",
    "    # Add noise to training data\n",
    "    y_shape = np.max(p_train[:,4])\n",
    "\n",
    "    sae = MLP(n_class=y_shape)\n",
    "    cnn = CNN(n_class=y_shape)\n",
    "    \n",
    "    # Build models and set weights\n",
    "    # sae, sae_enc, sae_clf = dl.build_sae(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "    # cnn, cnn_enc, cnn_clf = dl.build_cnn(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "\n",
    "    # sae.set_weights(sae_w)\n",
    "    # sae_enc.set_weights(sae_enc_w)\n",
    "    # sae_clf.set_weights(sae_clf_w)\n",
    "\n",
    "    # cnn.set_weights(cnn_w)\n",
    "    # cnn_enc.set_weights(cnn_enc_w)\n",
    "    # cnn_clf.set_weights(cnn_clf_w)\n",
    "\n",
    "    # set test on validation data for cv mode\n",
    "    x_test = x_test*emg_scale\n",
    "\n",
    "    # loop through test levels\n",
    "    noisefolder = test_sess.create_foldername(ftype='testnoise')\n",
    "    noisefolder = 'testdata/' + noisefolder\n",
    "    noisefile = test_sess.create_filename(noisefolder,1, sub, ftype='testnoise', test_scale=1)\n",
    "    if os.path.isfile(noisefile + '.p'):\n",
    "        print('loading data')\n",
    "        with open(noisefile + '.p','rb') as f:\n",
    "            x_test_vae, x_test_clean_vae, x_test_lda, y_test_clean = pickle.load(f) \n",
    "        test_load = True\n",
    "    x_temp = np.transpose(x_test_lda.reshape((x_test_lda.shape[0],num_feats,-1)),(0,2,1))[...,np.newaxis]\n",
    "    x_test_vae = scaler.transform(x_temp.reshape(x_temp.shape[0]*x_temp.shape[1],-1)).reshape(x_temp.shape)\n",
    "\n",
    "    # Reshape for nonconvolutional SAE\n",
    "    x_test_dlsae = x_test_vae.reshape(x_test_vae.shape[0],-1)\n",
    "\n",
    "    sae(x_test_dlsae[:1,...].astype('float32'))\n",
    "    cnn(x_test_vae[:1,...].astype('float32'))\n",
    "    sae.set_weights(mlp_w)\n",
    "    cnn.set_weights(cnn_w)\n",
    "    sae_enc = sae.enc\n",
    "    cnn_enc = cnn.enc\n",
    "    ## for timing\n",
    "    %timeit predict(sae_enc(x_test_dlsae[[0],...].astype('float32')).numpy(),w_sae,c_sae)\n",
    "\n",
    "    %timeit predict(cnn_enc(x_test_vae[[0],...].astype('float32')).numpy(),w_cnn,c_cnn)\n",
    "\n",
    "    # lda_start = time.time()\n",
    "    # temp_out = predict(x_test_lda[[0],...], w, c)\n",
    "    # lda_temp = timeit.timeit(lambda: predict(x_test_lda[[0],...], w, c),number= 100)\n",
    "    %timeit predict(x_test_lda[[0],...], w, c)\n",
    "\n",
    "    %timeit predict(x_test_lda[[0],...], w_noise, c_noise)\n",
    "\n",
    "    temp_x = x_test_lda[[0],...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mask = np.ones(6,dtype=bool) \n",
    "for i in range(1):\n",
    "    mask[0] = 0\n",
    "maskmu = np.tile(mask,4)\n",
    "test_data = temp_x[:,maskmu]\n",
    "C_temp = C[maskmu,:]\n",
    "C_in = C_temp[:,maskmu]\n",
    "w_temp, c_temp = train_lda(test_data,1,mu_bool = True, mu_class = mu[:,maskmu], C = C_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_diff = acc[:,7] - acc[:,14]\n",
    "sae_diff_tr = acc_tr[:,7] - acc_tr[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr = cp.deepcopy(acc)\n",
    "std_tr = cp.deepcopy(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_summary(ave_clean,ave_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs. position\n",
    "plot_utils.plot_pos_results(ave_pos_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Mixed Linear Model Regression Results\n",
      "===============================================================================\n",
      "Model:                    MixedLM         Dependent Variable:         acc      \n",
      "No. Observations:         210             Method:                     REML     \n",
      "No. Groups:               6               Scale:                      69.6034  \n",
      "Min. group size:          35              Log-Likelihood:             -728.6782\n",
      "Max. group size:          35              Converged:                  Yes      \n",
      "Mean group size:          35.0                                                 \n",
      "-------------------------------------------------------------------------------\n",
      "                                    Coef.  Std.Err.   z    P>|z|  [0.025 0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept                           34.974    4.087  8.557 0.000  26.963 42.984\n",
      "C(mod, Treatment(10))[T.4.0]         3.263    3.731  0.875 0.382  -4.050 10.576\n",
      "C(mod, Treatment(10))[T.5.0]        -2.333    3.731 -0.625 0.532  -9.646  4.980\n",
      "C(mod, Treatment(10))[T.6.0]        -7.330    3.731 -1.965 0.049 -14.643 -0.018\n",
      "C(mod, Treatment(10))[T.7.0]       -15.093    3.731 -4.045 0.000 -22.406 -7.780\n",
      "C(mod, Treatment(10))[T.11.0]        5.095    3.731  1.366 0.172  -2.218 12.408\n",
      "C(mod, Treatment(10))[T.14.0]      -14.602    3.731 -3.914 0.000 -21.914 -7.289\n",
      "elec                                12.542    1.077 11.645 0.000  10.431 14.653\n",
      "C(mod, Treatment(10))[T.4.0]:elec   -1.508    1.523 -0.990 0.322  -4.494  1.477\n",
      "C(mod, Treatment(10))[T.5.0]:elec   -0.059    1.523 -0.039 0.969  -3.044  2.927\n",
      "C(mod, Treatment(10))[T.6.0]:elec   -5.803    1.523 -3.810 0.000  -8.788 -2.818\n",
      "C(mod, Treatment(10))[T.7.0]:elec   -6.278    1.523 -4.121 0.000  -9.263 -3.292\n",
      "C(mod, Treatment(10))[T.11.0]:elec  -7.642    1.523 -5.017 0.000 -10.627 -4.656\n",
      "C(mod, Treatment(10))[T.14.0]:elec  -8.222    1.523 -5.398 0.000 -11.207 -5.236\n",
      "Group Var                           58.465    4.643                            \n",
      "===============================================================================\n",
      "\n",
      "0.0\n",
      "                  Mixed Linear Model Regression Results\n",
      "=========================================================================\n",
      "Model:                  MixedLM       Dependent Variable:       acc      \n",
      "No. Observations:       42            Method:                   REML     \n",
      "No. Groups:             6             Scale:                    13.2858  \n",
      "Min. group size:        7             Log-Likelihood:           -111.9486\n",
      "Max. group size:        7             Converged:                Yes      \n",
      "Mean group size:        7.0                                              \n",
      "-------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------------\n",
      "Intercept                      21.898    5.019  4.363 0.000 12.061 31.734\n",
      "C(mod, Treatment(10))[T.4.0]    4.558    2.104  2.166 0.030  0.434  8.683\n",
      "C(mod, Treatment(10))[T.5.0]   -0.132    2.104 -0.063 0.950 -4.257  3.992\n",
      "C(mod, Treatment(10))[T.6.0]    6.182    2.104  2.938 0.003  2.058 10.307\n",
      "C(mod, Treatment(10))[T.7.0]   -0.805    2.104 -0.382 0.702 -4.929  3.320\n",
      "C(mod, Treatment(10))[T.11.0]  18.985    2.104  9.021 0.000 14.860 23.109\n",
      "C(mod, Treatment(10))[T.14.0]   0.000    2.104  0.000 1.000 -4.125  4.125\n",
      "Group Var                     137.841   26.189                           \n",
      "=========================================================================\n",
      "\n",
      "1.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       acc      \n",
      "No. Observations:         42            Method:                   REML     \n",
      "No. Groups:               6             Scale:                    51.7255  \n",
      "Min. group size:          7             Log-Likelihood:           -130.7503\n",
      "Max. group size:          7             Converged:                Yes      \n",
      "Mean group size:          7.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.   z    P>|z|  [0.025  0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                      58.262    4.442 13.116 0.000  49.555  66.968\n",
      "C(mod, Treatment(10))[T.4.0]    0.474    4.152  0.114 0.909  -7.665   8.612\n",
      "C(mod, Treatment(10))[T.5.0]   -4.611    4.152 -1.110 0.267 -12.749   3.528\n",
      "C(mod, Treatment(10))[T.6.0]  -24.061    4.152 -5.795 0.000 -32.199 -15.922\n",
      "C(mod, Treatment(10))[T.7.0]  -32.529    4.152 -7.834 0.000 -40.667 -24.390\n",
      "C(mod, Treatment(10))[T.11.0] -13.914    4.152 -3.351 0.001 -22.053  -5.776\n",
      "C(mod, Treatment(10))[T.14.0] -34.143    4.152 -8.223 0.000 -42.282 -26.005\n",
      "Group Var                      66.673    7.035                             \n",
      "===========================================================================\n",
      "\n",
      "2.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        42             Method:                    REML     \n",
      "No. Groups:              6              Scale:                     39.5428  \n",
      "Min. group size:         7              Log-Likelihood:            -126.1156\n",
      "Max. group size:         7              Converged:                 Yes      \n",
      "Mean group size:         7.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      69.517    3.916  17.752 0.000  61.841  77.192\n",
      "C(mod, Treatment(10))[T.4.0]   -0.670    3.631  -0.185 0.854  -7.786   6.446\n",
      "C(mod, Treatment(10))[T.5.0]   -4.014    3.631  -1.106 0.269 -11.130   3.101\n",
      "C(mod, Treatment(10))[T.6.0]  -28.842    3.631  -7.944 0.000 -35.957 -21.726\n",
      "C(mod, Treatment(10))[T.7.0]  -38.349    3.631 -10.563 0.000 -45.465 -31.233\n",
      "C(mod, Treatment(10))[T.11.0] -20.230    3.631  -5.572 0.000 -27.346 -13.114\n",
      "C(mod, Treatment(10))[T.14.0] -42.278    3.631 -11.645 0.000 -49.393 -35.162\n",
      "Group Var                      52.467    6.313                              \n",
      "============================================================================\n",
      "\n",
      "3.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        42             Method:                    REML     \n",
      "No. Groups:              6              Scale:                     26.6884  \n",
      "Min. group size:         7              Log-Likelihood:            -119.6288\n",
      "Max. group size:         7              Converged:                 Yes      \n",
      "Mean group size:         7.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      73.748    3.386  21.781 0.000  67.111  80.384\n",
      "C(mod, Treatment(10))[T.4.0]   -0.770    2.983  -0.258 0.796  -6.616   5.076\n",
      "C(mod, Treatment(10))[T.5.0]   -1.526    2.983  -0.512 0.609  -7.372   4.320\n",
      "C(mod, Treatment(10))[T.6.0]  -26.195    2.983  -8.783 0.000 -32.041 -20.349\n",
      "C(mod, Treatment(10))[T.7.0]  -36.202    2.983 -12.138 0.000 -42.048 -30.357\n",
      "C(mod, Treatment(10))[T.11.0] -19.202    2.983  -6.438 0.000 -25.048 -13.357\n",
      "C(mod, Treatment(10))[T.14.0] -41.251    2.983 -13.830 0.000 -47.097 -35.405\n",
      "Group Var                      42.096    6.071                              \n",
      "============================================================================\n",
      "\n",
      "4.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        42             Method:                    REML     \n",
      "No. Groups:              6              Scale:                     25.2459  \n",
      "Min. group size:         7              Log-Likelihood:            -118.0055\n",
      "Max. group size:         7              Converged:                 Yes      \n",
      "Mean group size:         7.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      76.865    3.031  25.362 0.000  70.925  82.806\n",
      "C(mod, Treatment(10))[T.4.0]   -2.362    2.901  -0.814 0.416  -8.048   3.324\n",
      "C(mod, Treatment(10))[T.5.0]   -1.968    2.901  -0.678 0.498  -7.654   3.718\n",
      "C(mod, Treatment(10))[T.6.0]  -21.765    2.901  -7.503 0.000 -27.451 -16.080\n",
      "C(mod, Treatment(10))[T.7.0]  -30.356    2.901 -10.464 0.000 -36.042 -24.670\n",
      "C(mod, Treatment(10))[T.11.0] -16.580    2.901  -5.715 0.000 -22.265 -10.894\n",
      "C(mod, Treatment(10))[T.14.0] -37.555    2.901 -12.946 0.000 -43.241 -31.870\n",
      "Group Var                      29.865    4.551                              \n",
      "============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = stat.create_dataframe(acc_clean2,acc_noise2)\n",
    "df = stat.get_mods(df)\n",
    "all_md = stat.run_fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    # print(all_md[str(i) + '.0'].pvalues)\n",
    "    print(all_md[str(i) + '.0'].pvalues*5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a3b9df806ffb9c99dfd499571232d2e3ccda8a03627b2b254cd16611a407c53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf-2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
