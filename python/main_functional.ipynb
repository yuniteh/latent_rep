{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import latent.loop as loop\n",
    "import latent.session_functional as session\n",
    "import latent.utils.plot_utils as plot_utils \n",
    "import latent.utils.stats_utils as stat\n",
    "import latent.utils.data_utils as prd\n",
    "import latent.ml.dl_functional as dl\n",
    "from latent.ml.lda import train_lda\n",
    "import os\n",
    "import copy as cp\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "set_gpu()\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "%matplotlib qt\n",
    "mpl.rc('font', family='serif') \n",
    "mpl.rc('font', serif='Palatino Linotype') \n",
    "mpl.rc('font', size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'TR'\n",
    "with open('traindata/train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through training\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim':4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "\n",
    "for i in range(5):\n",
    "    train_out = [None] * np.max(params[:,0])\n",
    "\n",
    "    # loop through subjects\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        print('sub: ' + str(sub_i))\n",
    "        train_out[sub_i-1] = train_sess.loop_cv(raw,params,sub=sub_i,mod=['all'])\n",
    "        gc.collect()\n",
    "    \n",
    "    with open('AB_aug_' + str(i) + '.p', 'wb') as f:\n",
    "        pickle.dump([train_out],f)\n",
    "    \n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_all = [None] * 5\n",
    "aug_all = [None] * 5\n",
    "for i in range(5):\n",
    "    with open('AB_timings_' + str(i)+ '.p', 'rb') as f:\n",
    "        time_all[i] = pickle.load(f)\n",
    "    with open('AB_aug_' + str(i)+ '.p', 'rb') as f:\n",
    "        aug_all[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sae = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_cnn = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_lda = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_aug = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "\n",
    "it = 0\n",
    "for i in range(5):\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        sum_sae[it] = time_all[i][0][sub_i-1]['sae_time'] + time_all[i][0][sub_i-1]['sae_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_cnn[it] = time_all[i][0][sub_i-1]['cnn_time'] + time_all[i][0][sub_i-1]['cnn_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_lda[it] = time_all[i][0][sub_i-1]['lda_time']\n",
    "        sum_aug[it] = time_all[i][0][sub_i-1]['aug lda time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        it += 1\n",
    "\n",
    "mean_sae = np.nanmean(sum_sae)\n",
    "mean_cnn = np.nanmean(sum_cnn)\n",
    "mean_lda = np.nanmean(sum_lda)\n",
    "mean_aug = np.nanmean(sum_aug)\n",
    "\n",
    "std_sae = np.nanstd(sum_sae)\n",
    "std_cnn = np.nanstd(sum_cnn)\n",
    "std_lda = np.nanstd(sum_lda)\n",
    "std_aug = np.nanstd(sum_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensions of inputs\n",
    "sub = 5\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim': 4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "\n",
    "\n",
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'posrealmixeven','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt': 'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict)\n",
    "ntype = 'posrealmixeven'\n",
    "addon = False\n",
    "traintest = 'trainnoise'\n",
    "\n",
    "if not addon:\n",
    "    x_clean_lda = np.array([]).reshape(0,6)\n",
    "    x_clean_noise = np.array([]).reshape(0,6)\n",
    "    x_clean_sae = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "    x_clean_cnn = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "    y_clean = np.array([]).reshape(0,1)\n",
    "    y_noise_clean = np.array([]).reshape(0,1)\n",
    "    max_i = 2\n",
    "\n",
    "    if traintest == 'testnoise':\n",
    "        x_noisy_lda = np.array([]).reshape(0,6)\n",
    "        x_noisy_noise = np.array([]).reshape(0,6)\n",
    "        x_noisy_sae = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "        x_noisy_cnn = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "        y_noisy = np.array([]).reshape(0,1)\n",
    "        max_i = 5\n",
    "\n",
    "if ntype == 'flat':\n",
    "    test_max = 2\n",
    "else:\n",
    "    test_max = 6\n",
    "\n",
    "for i in range(1,max_i):\n",
    "    if traintest == 'testnoise':\n",
    "        test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "        red_out = test_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    else:\n",
    "        red_out = train_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    for key,val in red_out.items():\n",
    "        exec(key + '=val')\n",
    "    x_clean_lda = np.vstack([x_test_lda_red[:clean_size_lda,:], x_clean_lda])\n",
    "    x_clean_noise = np.vstack([x_test_noise_red[:clean_size,:], x_clean_noise])\n",
    "    x_clean_sae = np.vstack([x_test_sae_red[:clean_size,:], x_clean_sae])\n",
    "    x_clean_cnn = np.vstack([x_test_cnn_red[:clean_size,:], x_clean_cnn])\n",
    "    y_clean = np.vstack([y_test[:clean_size_lda,:], y_clean])\n",
    "    y_noise_clean = np.vstack([y_test_noise[:clean_size,:], y_noise_clean])\n",
    "    print(clean_size)\n",
    "    print(clean_size_lda)\n",
    "\n",
    "    x_noisy_lda = np.vstack([x_test_lda_red[clean_size_lda:,:], x_noisy_lda])\n",
    "    x_noisy_noise = np.vstack([x_test_noise_red[clean_size:,:], x_noisy_noise])\n",
    "    x_noisy_sae = np.vstack([x_test_sae_red[clean_size:,:], x_noisy_sae])\n",
    "    x_noisy_cnn = np.vstack([x_test_cnn_red[clean_size:,:], x_noisy_cnn])\n",
    "    y_noisy = np.vstack([y_test[clean_size_lda:,:], y_noisy])\n",
    "\n",
    "x_all_lda = np.vstack([x_clean_lda,x_noisy_lda])\n",
    "x_all_noise = np.vstack([x_clean_noise,x_noisy_noise])\n",
    "x_all_sae = np.vstack([x_clean_sae,x_noisy_sae])\n",
    "x_all_cnn = np.vstack([x_clean_cnn,x_noisy_cnn])\n",
    "y_all = np.vstack([y_clean, y_noisy])\n",
    "\n",
    "lda_lims = tuple(np.vstack((np.min(x_all_lda[:,:3],axis=0),np.max(x_all_lda[:,:3],axis=0))).T)\n",
    "noise_lims = tuple(np.vstack((np.min(x_all_noise[:,:3],axis=0),np.max(x_all_noise[:,:3],axis=0))).T)\n",
    "sae_lims = tuple(np.vstack((np.min(x_all_sae[:,:3],axis=0),np.max(x_all_sae[:,:3],axis=0))).T)\n",
    "cnn_lims = tuple(np.vstack((np.min(x_all_cnn[:,:3],axis=0),np.max(x_all_cnn[:,:3],axis=0))).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced dimensions\n",
    "dim = 3\n",
    "train_downsamp = clean_size//clean_size_lda\n",
    "std_lim = False\n",
    "mult = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plot_utils.plot_latent_rep(x_clean_lda, y_clean,fig,loc=1,lims=lda_lims,downsamp=train_downsamp,dim=dim, lim_min=lda_min, lim_max=lda_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_noise, y_noise_clean,fig,loc=2,lims=noise_lims,downsamp=train_downsamp,dim=dim, lim_min=noise_min, lim_max=noise_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_sae, y_noise_clean,fig,loc=3,lims=sae_lims,dim=dim,downsamp=train_downsamp, lim_min=sae_min, lim_max=sae_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_cnn, y_noise_clean,fig,loc=4,lims=cnn_lims,dim=dim,downsamp=train_downsamp, lim_min=cnn_min, lim_max=cnn_max,std_lim=std_lim,mult = mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsamp = 2\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "lda_min, lda_max = plot_utils.plot_latent_rep(x_noisy_lda, y_noisy,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "noise_min, noise_max = plot_utils.plot_latent_rep(x_noisy_noise, y_noisy,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "sae_min, sae_max = plot_utils.plot_latent_rep(x_noisy_sae, y_noisy,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "cnn_min, cnn_max = plot_utils.plot_latent_rep(x_noisy_cnn, y_noisy,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_utils.plot_latent_rep(x_all_lda, y_all,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_noise, y_all,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_sae, y_all,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_cnn, y_all,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "    real_noise_temp, _ = pickle.load(f)\n",
    "    \n",
    "plot_utils.plot_all_noise(real_noise_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noise = ['breaknm','break','contact','move']\n",
    "\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(12, 4)) \n",
    "gs = gridspec.GridSpec(8, 3)\n",
    "\n",
    "for i in range(4):\n",
    "    ntype = 'posreal' + all_noise[i]\n",
    "    with open(sub_type + '_' + ntype + '1.p', 'rb') as f:\n",
    "        xtestnoise,xtest,y_out = pickle.load(f)\n",
    "    plot_utils.plot_noisy(xtestnoise,xtest,y_out,iter=i, gs=gs)\n",
    "\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.2, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_2_all_emgscalelim_noisescalelim/temp/TR1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/temp/TR7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:70: RuntimeWarning: Mean of empty slice\n",
      "c:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:71: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "# sub_type = 'AB'\n",
    "test_dict = {'sub_type':sub_type,'dt':'manual', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partgauss4','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "test_all = ['noisescalelim']\n",
    "load = True\n",
    "if load:\n",
    "    posi_max = 2\n",
    "else:\n",
    "    posi_max = 5\n",
    "\n",
    "for dt in dt_all:\n",
    "    test_sess.dt = dt\n",
    "    for j in range(1):\n",
    "        test_sess.mod_dt = mod_all[j]\n",
    "        test_sess.test_dt = test_all[j]\n",
    "        for posi in range(1,posi_max):\n",
    "            ntype = 'posrealmixeven'\n",
    "            \n",
    "            if not load:\n",
    "                ntype += str(posi)\n",
    "\n",
    "            if ntype[:3] == 'pos' and not load:\n",
    "                i_start = 4\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "            elif ntype == 'flat' or 'mix' in ntype or 'real' in ntype:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "            else:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "\n",
    "            for i in range(i_start,i_end):\n",
    "                if load and 'pos' in ntype:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "                else:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i)    \n",
    "\n",
    "                if load:\n",
    "                    for sub in range(1,np.max(params[:,0])+1):\n",
    "                        foldername = test_sess.create_foldername(ftype='results')\n",
    "                        # foldername += '/rev2_noreg'\n",
    "                        foldername += '/temp'\n",
    "                        filename = test_sess.create_filename(foldername, 1, sub)\n",
    "                        print(filename + '_' + test_sess.n_test)\n",
    "                        if os.path.isfile(filename + '_' + test_sess.n_test + '_subresults.p'):\n",
    "                            with open(filename + '_' + test_sess.n_test + '_subresults.p', 'rb') as f:\n",
    "                                temp_all, temp_noise, temp_clean = pickle.load(f)\n",
    "                            acc_all[sub-1,i-i_start,:,:], acc_clean[sub-1,i-i_start,:,:], acc_noise[sub-1,i-i_start,:,:] = np.squeeze(temp_all),np.squeeze(temp_clean),np.squeeze(temp_noise)\n",
    "                else:\n",
    "                    # test_out, x_test_noise, x_test_clean, y_test_clean = test_sess.loop_test(raw, params)\n",
    "                    test_out = test_sess.loop_test(raw, params)\n",
    "                    # print(test_out)\n",
    "                    for key,val in test_out.items():\n",
    "                        exec(key + '=val')\n",
    "\n",
    "            ave_pos_noise= np.nanmean(acc_noise,axis=0)\n",
    "            ave_pos_clean = np.nanmean(acc_clean,axis=0)\n",
    "            ave_noise= np.nanmean(acc_noise,axis=2)\n",
    "            ave_clean = np.nanmean(acc_clean,axis=2)\n",
    "            ave_gauss_noise = np.nanmean(ave_noise,axis=0)\n",
    "            ave_gauss_clean = np.nanmean(ave_clean,axis=0)\n",
    "\n",
    "            if load:\n",
    "                plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type)\n",
    "\n",
    "            if 'gauss' in ntype:\n",
    "                ave_gauss= cp.deepcopy(ave_noise)\n",
    "            elif 'flat' in ntype:\n",
    "                ave_flat = cp.deepcopy(ave_noise)\n",
    "            elif '60hz' in ntype:\n",
    "                ave_60hz = cp.deepcopy(ave_noise)\n",
    "            elif 'mix' in ntype:\n",
    "                ave_mix = cp.deepcopy(ave_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_noise2 = cp.deepcopy(ave_noise)\n",
    "ave_clean2 = cp.deepcopy(ave_clean)\n",
    "acc_clean2 = cp.deepcopy(acc_clean)\n",
    "acc_noise2 = cp.deepcopy(acc_noise)\n",
    "# ave_mix2 = cp.deepcopy(ave_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_noise2[:,:,4] = ave_noise[:,:,6]\n",
    "ave_clean2[:,:,4] = ave_clean[:,:,6]\n",
    "ave_noise2[:,:,5] = ave_noise[:,:,7]\n",
    "ave_clean2[:,:,5] = ave_clean[:,:,7]\n",
    "acc_clean2[...,4] = acc_clean[...,6]\n",
    "acc_noise2[...,4] = acc_noise[...,6]\n",
    "acc_clean2[...,5] = acc_clean[...,7]\n",
    "acc_noise2[...,5] = acc_noise[...,7]\n",
    "# ave_mix2[:,:,4] = ave_mix[:,:,6]\n",
    "# ave_mix2[:,:,5] = ave_mix[:,:,7]\n",
    "# ave_noise2[:,:,11] = ave_noise[:,:,11]\n",
    "# ave_clean2[:,:,11] = ave_clean[:,:,11]\n",
    "# acc_clean2[...,11] = acc_clean[...,11]\n",
    "# acc_noise2[...,11] = acc_noise[...,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_nn_results(ave_noise,ave_clean,ave_noise2, ave_clean2, test_sess.n_train,ntype,test_sess.sub_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_aug_results(ave_noise,ave_clean,ave_noise2, ave_clean2, test_sess.n_train,ntype,test_sess.sub_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = 1/25.4 \n",
    "w = 210\n",
    "h = w/2\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*mm, h*mm)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2.75])\n",
    "plot_utils.plot_electrode_results_aug(ave_noise2,ave_clean2,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "diff_mix,c ,c1 = plot_utils.plot_summary_aug(ave_clean2,ave_noise2,gs=gs[1])\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "px = 1/plt.rcParams['figure.dpi']  # pixel in inches\n",
    "w = 1200\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*px, h*px)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "acc, std = plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "mm = 1/25.4 \n",
    "w = 200\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*mm, h*mm)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,0.2,200)\n",
    "temp = []\n",
    "gauss = []\n",
    "fig, ax = plt.subplots(11,1)\n",
    "for a in range(1,6):\n",
    "    temp.append(a*np.sin(2*np.pi*60*x))\n",
    "    gauss.append(np.random.normal(0,a,len(x)))\n",
    "    ax[a-1].plot(x*1000,temp[a-1],'b',label='A = ' + str(a))\n",
    "    ax[a+4].plot(x*1000,gauss[a-1],label='A = ' + str(a))\n",
    "\n",
    "ax[-1].plot(x*1000,np.zeros(x.shape))\n",
    "# ax.legend()\n",
    "for i in range(11):\n",
    "    if i > 0: \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_yticklabels([])\n",
    "    if i < 10:\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_xticklabels([])\n",
    "    ax[i].set_ylim([-5,5])\n",
    "    ax[i].set_xlim([0,200])\n",
    "ax[-1].set_xlabel('Time (ms)')\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent.ml.lda import predict, train_lda\n",
    "from latent.ml.dl_subclass import MLP, CNN\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partposrealmixeven14','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "sae_time = [None] * np.max(params[:,0])\n",
    "cnn_time = [None] * np.max(params[:,0])\n",
    "lda_time = [None] * np.max(params[:,0])\n",
    "aug_time = [None] * np.max(params[:,0])\n",
    "\n",
    "# set number of models to test\n",
    "mod_tot = 15\n",
    "# set testing noise type\n",
    "noise_type = test_sess.n_test[4:-1]\n",
    "print(noise_type)\n",
    "\n",
    "# load real_noise\n",
    "if 'real' in noise_type:\n",
    "    with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "        real_noise_temp, _ = pickle.load(f)\n",
    "\n",
    "cv_tot = 1\n",
    "test_sess.max_cv = cv_tot + 1\n",
    "\n",
    "filename = 0\n",
    "\n",
    "# Set folder\n",
    "foldername = test_sess.create_foldername()\n",
    "resultsfolder = test_sess.create_foldername(ftype='results')\n",
    "\n",
    "num_feats = 10\n",
    "\n",
    "# loop through subjects\n",
    "sub = 1\n",
    "# index based on training group and subject\n",
    "ind = (params[:,0] == sub) & (params[:,3] == test_sess.train_grp)\n",
    "\n",
    "# Check if training data exists\n",
    "if np.sum(ind):\n",
    "    # loop through cvs\n",
    "    filename = test_sess.create_filename(foldername, 1, sub)\n",
    "\n",
    "    x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,test_sess.sub_type,dt=test_sess.dt,train_grp=test_sess.train_grp)\n",
    "    filename = 'subclass/models/TR' + str(sub) + '_tdar'\n",
    "    with open(filename + '.p', 'rb') as f:\n",
    "        mlp_w, _, cnn_w, w_sae, c_sae, _, _, w_cnn, c_cnn, w, c, w_noise, c_noise, emg_scale, scaler, mu_class, C = pickle.load(f)\n",
    "    # Load saved data\n",
    "    # with open(filename + '.p', 'rb') as f:\n",
    "    #     scaler, svae_w, svae_enc_w, svae_dec_w, svae_clf_w, sae_w, sae_enc_w, sae_clf_w, cnn_w, cnn_enc_w, cnn_clf_w, vcnn_w, vcnn_enc_w, vcnn_clf_w, ecnn_w, ecnn_enc_w, ecnn_clf_w, w_svae, c_svae, w_sae, c_sae, w_cnn, c_cnn, w_vcnn, c_vcnn, w_ecnn, c_ecnn, w, c, w_noise, c_noise, mu, C, qda, qda_noise,emg_scale = pickle.load(f)   \n",
    "\n",
    "    # Add noise to training data\n",
    "    y_shape = np.max(p_train[:,4])\n",
    "\n",
    "    sae = MLP(n_class=y_shape)\n",
    "    cnn = CNN(n_class=y_shape)\n",
    "    \n",
    "    # Build models and set weights\n",
    "    # sae, sae_enc, sae_clf = dl.build_sae(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "    # cnn, cnn_enc, cnn_clf = dl.build_cnn(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "\n",
    "    # sae.set_weights(sae_w)\n",
    "    # sae_enc.set_weights(sae_enc_w)\n",
    "    # sae_clf.set_weights(sae_clf_w)\n",
    "\n",
    "    # cnn.set_weights(cnn_w)\n",
    "    # cnn_enc.set_weights(cnn_enc_w)\n",
    "    # cnn_clf.set_weights(cnn_clf_w)\n",
    "\n",
    "    # set test on validation data for cv mode\n",
    "    x_test = x_test*emg_scale\n",
    "\n",
    "    # loop through test levels\n",
    "    noisefolder = test_sess.create_foldername(ftype='testnoise')\n",
    "    noisefolder = 'testdata/' + noisefolder\n",
    "    noisefile = test_sess.create_filename(noisefolder,1, sub, ftype='testnoise', test_scale=1)\n",
    "    if os.path.isfile(noisefile + '.p'):\n",
    "        print('loading data')\n",
    "        with open(noisefile + '.p','rb') as f:\n",
    "            x_test_vae, x_test_clean_vae, x_test_lda, y_test_clean = pickle.load(f) \n",
    "        test_load = True\n",
    "    x_temp = np.transpose(x_test_lda.reshape((x_test_lda.shape[0],num_feats,-1)),(0,2,1))[...,np.newaxis]\n",
    "    x_test_vae = scaler.transform(x_temp.reshape(x_temp.shape[0]*x_temp.shape[1],-1)).reshape(x_temp.shape)\n",
    "\n",
    "    # Reshape for nonconvolutional SAE\n",
    "    x_test_dlsae = x_test_vae.reshape(x_test_vae.shape[0],-1)\n",
    "\n",
    "    sae(x_test_dlsae[:1,...].astype('float32'))\n",
    "    cnn(x_test_vae[:1,...].astype('float32'))\n",
    "    sae.set_weights(mlp_w)\n",
    "    cnn.set_weights(cnn_w)\n",
    "    sae_enc = sae.enc\n",
    "    cnn_enc = cnn.enc\n",
    "    ## for timing\n",
    "    %timeit predict(sae_enc(x_test_dlsae[[0],...].astype('float32')).numpy(),w_sae,c_sae)\n",
    "\n",
    "    %timeit predict(cnn_enc(x_test_vae[[0],...].astype('float32')).numpy(),w_cnn,c_cnn)\n",
    "\n",
    "    # lda_start = time.time()\n",
    "    # temp_out = predict(x_test_lda[[0],...], w, c)\n",
    "    # lda_temp = timeit.timeit(lambda: predict(x_test_lda[[0],...], w, c),number= 100)\n",
    "    %timeit predict(x_test_lda[[0],...], w, c)\n",
    "\n",
    "    %timeit predict(x_test_lda[[0],...], w_noise, c_noise)\n",
    "\n",
    "    temp_x = x_test_lda[[0],...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.nanmean(ave_noise2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01875627, 0.01520981, 0.01875627, 0.01875627, 0.01981864,\n",
       "       0.01766341, 0.01465204, 0.01627478, 0.01627478, 0.01627478,\n",
       "       0.01422465, 0.01221415, 0.01422465, 0.01422465, 0.01422465])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanstd(np.nanmean(ave_clean2,axis=1),axis=0)/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test2 = np.nanmean(np.nanmean(ave_clean2,axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.hstack((ave_clean2[:,[0],:],ave_noise2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77169048],\n",
       "       [0.73663095],\n",
       "       [0.68446429],\n",
       "       [0.62946429],\n",
       "       [0.55695238]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(temp[:,:,[7]],axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78102381, 0.41516667, 0.30678571, 0.25839286, 0.23329762])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(temp[:,:,10],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.989999999999995"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "78.1-72.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.209999999999994"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "72.11-66.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "temp1=np.nanmean(temp[:,1:,:],axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.33931548, 0.29085119, 0.33931548, 0.33931548, 0.00893155,\n",
       "       0.03090774, 0.2904881 , 0.34846726, 0.34846726, 0.34846726,\n",
       "       0.        , 0.18010417, 0.        , 0.        , 0.38867823])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(np.nanmean(temp[:,1:,:] - temp[:,1:,[10]],axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(np.nanmean(temp,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(np.nanmean(temp[:,1:,:] - temp[:,1:,[10]],axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03714286, -0.05054762, -0.03714286, -0.03714286, -0.32279762,\n",
       "        -0.31885714, -0.05210714, -0.03505952, -0.03505952, -0.03505952,\n",
       "        -0.36585714, -0.04608333, -0.36585714, -0.36585714, -0.02221117],\n",
       "       [-0.08833333, -0.08888095, -0.08833333, -0.08833333, -0.42390476,\n",
       "        -0.43736905, -0.08991667, -0.08722619, -0.08722619, -0.08722619,\n",
       "        -0.4742381 , -0.09439286, -0.4742381 , -0.4742381 , -0.05341536],\n",
       "       [-0.14778571, -0.14395238, -0.14778571, -0.14778571, -0.46521429,\n",
       "        -0.50455952, -0.14715476, -0.14222619, -0.14222619, -0.14222619,\n",
       "        -0.52263095, -0.14629762, -0.52263095, -0.52263095, -0.1059881 ],\n",
       "       [-0.22321429, -0.20952381, -0.22321429, -0.22321429, -0.48047619,\n",
       "        -0.53132143, -0.21970238, -0.2147381 , -0.2147381 , -0.2147381 ,\n",
       "        -0.54772619, -0.20130952, -0.54772619, -0.54772619, -0.17412484]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test-test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=np.nanmean(ave_noise2 - np.nanmean(ave_clean2[:,[0],:]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.23412698e-03, -6.27460317e-02,  1.59920635e-03,\n",
       "        -6.62698413e-03, -3.14948413e-01, -2.64103175e-01,\n",
       "        -6.96031746e-02,  1.50753968e-02,  8.37301587e-04,\n",
       "        -2.19436508e-01, -3.10210317e-01, -1.71067460e-01,\n",
       "        -4.34186508e-01, -1.22769841e-01,  3.12213697e-02],\n",
       "       [-6.69246032e-02, -1.34281746e-01, -5.18174603e-02,\n",
       "        -5.93293651e-02, -4.16055556e-01, -3.82615079e-01,\n",
       "        -1.34341270e-01, -3.92698413e-02, -5.21031746e-02,\n",
       "        -2.51388889e-01, -4.22757937e-01, -2.20460317e-01,\n",
       "        -5.04757937e-01, -1.72103175e-01,  1.71778011e-05],\n",
       "       [-1.22686508e-01, -2.09269841e-01, -1.17829365e-01,\n",
       "        -1.32329365e-01, -4.57365079e-01, -4.49805556e-01,\n",
       "        -2.03115079e-01, -1.03043651e-01, -1.28496032e-01,\n",
       "        -2.88365079e-01, -4.65067460e-01, -2.73043651e-01,\n",
       "        -5.30496032e-01, -2.14031746e-01, -5.25555556e-02],\n",
       "       [-2.05317460e-01, -2.83222222e-01, -2.05031746e-01,\n",
       "        -2.12496032e-01, -4.72626984e-01, -4.76567460e-01,\n",
       "        -2.78591270e-01, -1.92686508e-01, -2.09888889e-01,\n",
       "        -3.40496032e-01, -4.96246032e-01, -3.30448413e-01,\n",
       "        -5.38281746e-01, -2.65388889e-01, -1.20692302e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mask = np.ones(6,dtype=bool) \n",
    "for i in range(1):\n",
    "    mask[0] = 0\n",
    "maskmu = np.tile(mask,4)\n",
    "test_data = temp_x[:,maskmu]\n",
    "C_temp = C[maskmu,:]\n",
    "C_in = C_temp[:,maskmu]\n",
    "w_temp, c_temp = train_lda(test_data,1,mu_bool = True, mu_class = mu[:,maskmu], C = C_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_diff = acc[:,7] - acc[:,14]\n",
    "sae_diff_tr = acc_tr[:,7] - acc_tr[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr = cp.deepcopy(acc)\n",
    "std_tr = cp.deepcopy(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_summary(ave_clean,ave_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs. position\n",
    "plot_utils.plot_pos_results(ave_pos_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Mixed Linear Model Regression Results\n",
      "===============================================================================\n",
      "Model:                    MixedLM         Dependent Variable:         acc      \n",
      "No. Observations:         210             Method:                     REML     \n",
      "No. Groups:               6               Scale:                      65.1511  \n",
      "Min. group size:          35              Log-Likelihood:             -722.2117\n",
      "Max. group size:          35              Converged:                  Yes      \n",
      "Mean group size:          35.0                                                 \n",
      "-------------------------------------------------------------------------------\n",
      "                                    Coef.  Std.Err.   z    P>|z|  [0.025 0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept                           35.062    3.960  8.854 0.000  27.301 42.823\n",
      "C(mod, Treatment(10))[T.4.0]         3.174    3.610  0.879 0.379  -3.901 10.249\n",
      "C(mod, Treatment(10))[T.5.0]        -2.421    3.610 -0.671 0.502  -9.496  4.654\n",
      "C(mod, Treatment(10))[T.6.0]        -7.685    3.610 -2.129 0.033 -14.760 -0.611\n",
      "C(mod, Treatment(10))[T.7.0]       -13.379    3.610 -3.706 0.000 -20.454 -6.304\n",
      "C(mod, Treatment(10))[T.11.0]        4.089    3.610  1.133 0.257  -2.986 11.164\n",
      "C(mod, Treatment(10))[T.14.0]      -14.690    3.610 -4.070 0.000 -21.765 -7.615\n",
      "elec                                12.522    1.042 12.017 0.000  10.480 14.565\n",
      "C(mod, Treatment(10))[T.4.0]:elec   -1.489    1.474 -1.010 0.312  -4.377  1.400\n",
      "C(mod, Treatment(10))[T.5.0]:elec   -0.039    1.474 -0.026 0.979  -2.927  2.850\n",
      "C(mod, Treatment(10))[T.6.0]:elec   -7.178    1.474 -4.871 0.000 -10.066 -4.289\n",
      "C(mod, Treatment(10))[T.7.0]:elec   -7.156    1.474 -4.856 0.000 -10.044 -4.267\n",
      "C(mod, Treatment(10))[T.11.0]:elec  -7.494    1.474 -5.085 0.000 -10.382 -4.606\n",
      "C(mod, Treatment(10))[T.14.0]:elec  -8.202    1.474 -5.566 0.000 -11.090 -5.314\n",
      "Group Var                           54.995    4.513                            \n",
      "===============================================================================\n",
      "\n",
      "0.0\n",
      "                  Mixed Linear Model Regression Results\n",
      "=========================================================================\n",
      "Model:                  MixedLM       Dependent Variable:       acc      \n",
      "No. Observations:       42            Method:                   REML     \n",
      "No. Groups:             6             Scale:                    7.9422   \n",
      "Min. group size:        7             Log-Likelihood:           -104.2214\n",
      "Max. group size:        7             Converged:                Yes      \n",
      "Mean group size:        7.0                                              \n",
      "-------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------------\n",
      "Intercept                      21.898    4.933  4.439 0.000 12.229 31.566\n",
      "C(mod, Treatment(10))[T.4.0]    4.558    1.627  2.802 0.005  1.369  7.747\n",
      "C(mod, Treatment(10))[T.5.0]   -0.132    1.627 -0.081 0.935 -3.321  3.057\n",
      "C(mod, Treatment(10))[T.6.0]    5.990    1.627  3.682 0.000  2.801  9.179\n",
      "C(mod, Treatment(10))[T.7.0]    0.933    1.627  0.574 0.566 -2.256  4.122\n",
      "C(mod, Treatment(10))[T.11.0]  17.549    1.627 10.785 0.000 14.360 20.738\n",
      "C(mod, Treatment(10))[T.14.0]   0.000    1.627  0.000 1.000 -3.189  3.189\n",
      "Group Var                     138.065   33.742                           \n",
      "=========================================================================\n",
      "\n",
      "1.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       acc      \n",
      "No. Observations:         42            Method:                   REML     \n",
      "No. Groups:               6             Scale:                    45.1882  \n",
      "Min. group size:          7             Log-Likelihood:           -128.6261\n",
      "Max. group size:          7             Converged:                Yes      \n",
      "Mean group size:          7.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.   z    P>|z|  [0.025  0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                      58.483    4.281 13.661 0.000  50.093  66.874\n",
      "C(mod, Treatment(10))[T.4.0]    0.252    3.881  0.065 0.948  -7.354   7.859\n",
      "C(mod, Treatment(10))[T.5.0]   -4.832    3.881 -1.245 0.213 -12.439   2.775\n",
      "C(mod, Treatment(10))[T.6.0]  -25.385    3.881 -6.541 0.000 -32.991 -17.778\n",
      "C(mod, Treatment(10))[T.7.0]  -32.146    3.881 -8.283 0.000 -39.753 -24.540\n",
      "C(mod, Treatment(10))[T.11.0] -14.429    3.881 -3.718 0.000 -22.035  -6.822\n",
      "C(mod, Treatment(10))[T.14.0] -34.365    3.881 -8.854 0.000 -41.971 -26.758\n",
      "Group Var                      64.773    7.238                             \n",
      "===========================================================================\n",
      "\n",
      "2.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        42             Method:                    REML     \n",
      "No. Groups:              6              Scale:                     33.2034  \n",
      "Min. group size:         7              Log-Likelihood:            -123.3267\n",
      "Max. group size:         7              Converged:                 Yes      \n",
      "Mean group size:         7.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      69.321    3.715  18.661 0.000  62.040  76.602\n",
      "C(mod, Treatment(10))[T.4.0]   -0.475    3.327  -0.143 0.886  -6.995   6.045\n",
      "C(mod, Treatment(10))[T.5.0]   -3.819    3.327  -1.148 0.251 -10.340   2.701\n",
      "C(mod, Treatment(10))[T.6.0]  -32.442    3.327  -9.752 0.000 -38.962 -25.921\n",
      "C(mod, Treatment(10))[T.7.0]  -37.768    3.327 -11.353 0.000 -44.288 -31.247\n",
      "C(mod, Treatment(10))[T.11.0] -20.436    3.327  -6.143 0.000 -26.956 -13.915\n",
      "C(mod, Treatment(10))[T.14.0] -42.082    3.327 -12.649 0.000 -48.603 -35.562\n",
      "Group Var                      49.597    6.442                              \n",
      "============================================================================\n",
      "\n",
      "3.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        42             Method:                    REML     \n",
      "No. Groups:              6              Scale:                     21.1160  \n",
      "Min. group size:         7              Log-Likelihood:            -115.8110\n",
      "Max. group size:         7              Converged:                 Yes      \n",
      "Mean group size:         7.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      74.161    3.129  23.702 0.000  68.028  80.293\n",
      "C(mod, Treatment(10))[T.4.0]   -1.183    2.653  -0.446 0.656  -6.383   4.017\n",
      "C(mod, Treatment(10))[T.5.0]   -1.939    2.653  -0.731 0.465  -7.139   3.261\n",
      "C(mod, Treatment(10))[T.6.0]  -31.557    2.653 -11.895 0.000 -36.757 -26.357\n",
      "C(mod, Treatment(10))[T.7.0]  -37.107    2.653 -13.987 0.000 -42.307 -31.907\n",
      "C(mod, Treatment(10))[T.11.0] -20.085    2.653  -7.570 0.000 -25.284 -14.885\n",
      "C(mod, Treatment(10))[T.14.0] -41.664    2.653 -15.704 0.000 -46.864 -36.464\n",
      "Group Var                      37.622    6.041                              \n",
      "============================================================================\n",
      "\n",
      "4.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        42             Method:                    REML     \n",
      "No. Groups:              6              Scale:                     18.7003  \n",
      "Min. group size:         7              Log-Likelihood:            -113.1318\n",
      "Max. group size:         7              Converged:                 Yes      \n",
      "Mean group size:         7.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      76.670    2.735  28.035 0.000  71.310  82.030\n",
      "C(mod, Treatment(10))[T.4.0]   -2.167    2.497  -0.868 0.385  -7.060   2.727\n",
      "C(mod, Treatment(10))[T.5.0]   -1.773    2.497  -0.710 0.478  -6.666   3.121\n",
      "C(mod, Treatment(10))[T.6.0]  -26.812    2.497 -10.739 0.000 -31.705 -21.918\n",
      "C(mod, Treatment(10))[T.7.0]  -32.365    2.497 -12.963 0.000 -37.259 -27.472\n",
      "C(mod, Treatment(10))[T.11.0] -17.093    2.497  -6.846 0.000 -21.986 -12.199\n",
      "C(mod, Treatment(10))[T.14.0] -37.360    2.497 -14.964 0.000 -42.254 -32.467\n",
      "Group Var                      26.174    4.556                              \n",
      "============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = stat.create_dataframe(acc_clean2,acc_noise2)\n",
    "df = stat.get_mods(df)\n",
    "all_md = stat.run_fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                        4.518991e-05\n",
      "C(mod, Treatment(10))[T.4.0]     2.542982e-02\n",
      "C(mod, Treatment(10))[T.5.0]     4.676356e+00\n",
      "C(mod, Treatment(10))[T.6.0]     1.158289e-03\n",
      "C(mod, Treatment(10))[T.7.0]     2.831112e+00\n",
      "C(mod, Treatment(10))[T.11.0]    2.016412e-26\n",
      "C(mod, Treatment(10))[T.14.0]    5.000000e+00\n",
      "Group Var                        7.326145e-01\n",
      "dtype: float64\n",
      "Intercept                        8.656530e-42\n",
      "C(mod, Treatment(10))[T.4.0]     4.740756e+00\n",
      "C(mod, Treatment(10))[T.5.0]     1.065562e+00\n",
      "C(mod, Treatment(10))[T.6.0]     3.063817e-10\n",
      "C(mod, Treatment(10))[T.7.0]     6.012243e-16\n",
      "C(mod, Treatment(10))[T.11.0]    1.005328e-03\n",
      "C(mod, Treatment(10))[T.14.0]    4.206704e-18\n",
      "Group Var                        9.156474e-01\n",
      "dtype: float64\n",
      "Intercept                        5.175089e-77\n",
      "C(mod, Treatment(10))[T.4.0]     4.432325e+00\n",
      "C(mod, Treatment(10))[T.5.0]     1.254938e+00\n",
      "C(mod, Treatment(10))[T.6.0]     9.086079e-22\n",
      "C(mod, Treatment(10))[T.7.0]     3.603475e-29\n",
      "C(mod, Treatment(10))[T.11.0]    4.056593e-09\n",
      "C(mod, Treatment(10))[T.14.0]    5.639652e-36\n",
      "Group Var                        9.076266e-01\n",
      "dtype: float64\n",
      "Intercept                        1.704221e-123\n",
      "C(mod, Treatment(10))[T.4.0]      3.277886e+00\n",
      "C(mod, Treatment(10))[T.5.0]      2.324003e+00\n",
      "C(mod, Treatment(10))[T.6.0]      6.307433e-32\n",
      "C(mod, Treatment(10))[T.7.0]      9.409251e-44\n",
      "C(mod, Treatment(10))[T.11.0]     1.861012e-13\n",
      "C(mod, Treatment(10))[T.14.0]     7.065935e-55\n",
      "Group Var                         8.767628e-01\n",
      "dtype: float64\n",
      "Intercept                        3.037186e-172\n",
      "C(mod, Treatment(10))[T.4.0]      1.927470e+00\n",
      "C(mod, Treatment(10))[T.5.0]      2.388553e+00\n",
      "C(mod, Treatment(10))[T.6.0]      3.337879e-26\n",
      "C(mod, Treatment(10))[T.7.0]      9.866794e-38\n",
      "C(mod, Treatment(10))[T.11.0]     3.791207e-11\n",
      "C(mod, Treatment(10))[T.14.0]     6.319337e-50\n",
      "Group Var                         9.202339e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # print(all_md[str(i) + '.0'].pvalues)\n",
    "    print(all_md[str(i) + '.0'].pvalues*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0112058e73182145abb4cd7aaf50d75809c95241f4ac2fefe0df8a318b89874e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('latent_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
