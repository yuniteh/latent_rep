{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import latent.loop as loop\n",
    "import latent.session_functional as session\n",
    "import latent.utils.plot_utils as plot_utils \n",
    "import latent.utils.stats_utils as stat\n",
    "import latent.utils.data_utils as prd\n",
    "import latent.ml.dl_functional as dl\n",
    "from latent.ml.lda import train_lda\n",
    "import os\n",
    "import copy as cp\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "set_gpu()\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "%matplotlib qt\n",
    "mpl.rc('font', family='serif') \n",
    "mpl.rc('font', serif='Palatino Linotype') \n",
    "mpl.rc('font', size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'TR'\n",
    "with open('traindata/train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through training\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim':4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "\n",
    "for i in range(5):\n",
    "    train_out = [None] * np.max(params[:,0])\n",
    "\n",
    "    # loop through subjects\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        print('sub: ' + str(sub_i))\n",
    "        train_out[sub_i-1] = train_sess.loop_cv(raw,params,sub=sub_i,mod=['all'])\n",
    "        gc.collect()\n",
    "    \n",
    "    with open('AB_aug_' + str(i) + '.p', 'wb') as f:\n",
    "        pickle.dump([train_out],f)\n",
    "    \n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_all = [None] * 5\n",
    "aug_all = [None] * 5\n",
    "for i in range(5):\n",
    "    with open('AB_timings_' + str(i)+ '.p', 'rb') as f:\n",
    "        time_all[i] = pickle.load(f)\n",
    "    with open('AB_aug_' + str(i)+ '.p', 'rb') as f:\n",
    "        aug_all[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sae = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_cnn = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_lda = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_aug = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "\n",
    "it = 0\n",
    "for i in range(5):\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        sum_sae[it] = time_all[i][0][sub_i-1]['sae_time'] + time_all[i][0][sub_i-1]['sae_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_cnn[it] = time_all[i][0][sub_i-1]['cnn_time'] + time_all[i][0][sub_i-1]['cnn_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_lda[it] = time_all[i][0][sub_i-1]['lda_time']\n",
    "        sum_aug[it] = time_all[i][0][sub_i-1]['aug lda time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        it += 1\n",
    "\n",
    "mean_sae = np.nanmean(sum_sae)\n",
    "mean_cnn = np.nanmean(sum_cnn)\n",
    "mean_lda = np.nanmean(sum_lda)\n",
    "mean_aug = np.nanmean(sum_aug)\n",
    "\n",
    "std_sae = np.nanstd(sum_sae)\n",
    "std_cnn = np.nanstd(sum_cnn)\n",
    "std_lda = np.nanstd(sum_lda)\n",
    "std_aug = np.nanstd(sum_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_2_all_emgscalelim/TR1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse\n",
      "noisedata_all_emgscalelim/TR1_grp_2_fullallmix4_5\n",
      "loading data\n",
      "3500\n",
      "3500\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensions of inputs\n",
    "sub = 1\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim': 4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "\n",
    "\n",
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'posrealmixeven','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt': 'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict)\n",
    "ntype = 'posrealmixeven'\n",
    "addon = False\n",
    "traintest = 'trainnoise'\n",
    "\n",
    "if not addon:\n",
    "    x_clean_lda = np.array([]).reshape(0,6)\n",
    "    x_clean_noise = np.array([]).reshape(0,6)\n",
    "    x_clean_sae = np.array([]).reshape(0,test_sess.latent_dim)\n",
    "    x_clean_cnn = np.array([]).reshape(0,test_sess.latent_dim)\n",
    "    y_clean = np.array([]).reshape(0,1)\n",
    "    y_noise_clean = np.array([]).reshape(0,1)\n",
    "    max_i = 2\n",
    "\n",
    "    if traintest == 'testnoise':\n",
    "        x_noisy_lda = np.array([]).reshape(0,6)\n",
    "        x_noisy_noise = np.array([]).reshape(0,6)\n",
    "        x_noisy_sae = np.array([]).reshape(0,test_sess.latent_dim)\n",
    "        x_noisy_cnn = np.array([]).reshape(0,test_sess.latent_dim)\n",
    "        y_noisy = np.array([]).reshape(0,1)\n",
    "        max_i = 5\n",
    "\n",
    "if ntype == 'flat':\n",
    "    test_max = 2\n",
    "else:\n",
    "    test_max = 6\n",
    "\n",
    "for i in range(1,max_i):\n",
    "    if traintest == 'testnoise':\n",
    "        test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "        red_out = test_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    else:\n",
    "        red_out = train_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    for key,val in red_out.items():\n",
    "        exec(key + '=val')\n",
    "    x_clean_lda = np.vstack([x_test_lda_red[:clean_size_lda,:], x_clean_lda])\n",
    "    x_clean_noise = np.vstack([x_test_noise_red[:clean_size,:], x_clean_noise])\n",
    "    x_clean_sae = np.vstack([x_test_sae_red[:clean_size,:], x_clean_sae])\n",
    "    x_clean_cnn = np.vstack([x_test_cnn_red[:clean_size,:], x_clean_cnn])\n",
    "    y_clean = np.vstack([y_test[:clean_size_lda,:], y_clean])\n",
    "    y_noise_clean = np.vstack([y_test_noise[:clean_size,:], y_noise_clean])\n",
    "    print(clean_size)\n",
    "    print(clean_size_lda)\n",
    "\n",
    "    x_noisy_lda = np.vstack([x_test_lda_red[clean_size_lda:,:], x_noisy_lda])\n",
    "    x_noisy_noise = np.vstack([x_test_noise_red[clean_size:,:], x_noisy_noise])\n",
    "    x_noisy_sae = np.vstack([x_test_sae_red[clean_size:,:], x_noisy_sae])\n",
    "    x_noisy_cnn = np.vstack([x_test_cnn_red[clean_size:,:], x_noisy_cnn])\n",
    "    y_noisy = np.vstack([y_test[clean_size_lda:,:], y_noisy])\n",
    "\n",
    "x_all_lda = np.vstack([x_clean_lda,x_noisy_lda])\n",
    "x_all_noise = np.vstack([x_clean_noise,x_noisy_noise])\n",
    "x_all_sae = np.vstack([x_clean_sae,x_noisy_sae])\n",
    "x_all_cnn = np.vstack([x_clean_cnn,x_noisy_cnn])\n",
    "y_all = np.vstack([y_clean, y_noisy])\n",
    "\n",
    "lda_lims = tuple(np.vstack((np.min(x_all_lda[:,:3],axis=0),np.max(x_all_lda[:,:3],axis=0))).T)\n",
    "noise_lims = tuple(np.vstack((np.min(x_all_noise[:,:3],axis=0),np.max(x_all_noise[:,:3],axis=0))).T)\n",
    "sae_lims = tuple(np.vstack((np.min(x_all_sae[:,:3],axis=0),np.max(x_all_sae[:,:3],axis=0))).T)\n",
    "cnn_lims = tuple(np.vstack((np.min(x_all_cnn[:,:3],axis=0),np.max(x_all_cnn[:,:3],axis=0))).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced dimensions\n",
    "dim = 3\n",
    "train_downsamp = clean_size//clean_size_lda\n",
    "std_lim = False\n",
    "mult = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plot_utils.plot_latent_rep(x_clean_lda, y_clean,fig,loc=1,lims=lda_lims,downsamp=train_downsamp,dim=dim, lim_min=lda_min, lim_max=lda_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_noise, y_noise_clean,fig,loc=2,lims=noise_lims,downsamp=train_downsamp,dim=dim, lim_min=noise_min, lim_max=noise_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_sae, y_noise_clean,fig,loc=3,lims=sae_lims,dim=dim,downsamp=train_downsamp, lim_min=sae_min, lim_max=sae_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_cnn, y_noise_clean,fig,loc=4,lims=cnn_lims,dim=dim,downsamp=train_downsamp, lim_min=cnn_min, lim_max=cnn_max,std_lim=std_lim,mult = mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsamp = 2\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "lda_min, lda_max = plot_utils.plot_latent_rep(x_noisy_lda, y_noisy,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "noise_min, noise_max = plot_utils.plot_latent_rep(x_noisy_noise, y_noisy,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "sae_min, sae_max = plot_utils.plot_latent_rep(x_noisy_sae, y_noisy,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "cnn_min, cnn_max = plot_utils.plot_latent_rep(x_noisy_cnn, y_noisy,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_utils.plot_latent_rep(x_all_lda, y_all,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_noise, y_all,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_sae, y_all,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_cnn, y_all,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "    real_noise_temp, _ = pickle.load(f)\n",
    "    \n",
    "plot_utils.plot_all_noise(real_noise_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AB_posrealbreaknm1.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2303cabff862>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mntype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'posreal'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mall_noise\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_type\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mntype\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'1.p'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mxtestnoise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mplot_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_noisy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtestnoise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AB_posrealbreaknm1.p'"
     ]
    }
   ],
   "source": [
    "all_noise = ['breaknm','break','contact','move']\n",
    "\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(12, 4)) \n",
    "gs = gridspec.GridSpec(8, 3)\n",
    "\n",
    "for i in range(4):\n",
    "    ntype = 'posreal' + all_noise[i]\n",
    "    with open(sub_type + '_' + ntype + '1.p', 'rb') as f:\n",
    "        xtestnoise,xtest,y_out = pickle.load(f)\n",
    "    plot_utils.plot_noisy(xtestnoise,xtest,y_out,iter=i, gs=gs)\n",
    "\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.2, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import latent.loop as loop\n",
    "import latent.session_functional as session\n",
    "import latent.utils.plot_utils as plot_utils \n",
    "import latent.utils.stats_utils as stat\n",
    "import latent.utils.data_utils as prd\n",
    "import latent.ml.dl_functional as dl\n",
    "from latent.ml.lda import train_lda\n",
    "import os\n",
    "import copy as cp\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "set_gpu()\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "%matplotlib qt\n",
    "mpl.rc('font', family='serif') \n",
    "mpl.rc('font', serif='Palatino Linotype') \n",
    "mpl.rc('font', size=12)\n",
    "sub_type = 'TR'\n",
    "with open('traindata/train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_2_all_emgscalelim_noisescalelim/TR1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/TR2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/TR3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/TR4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/TR5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/TR6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/TR7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/TR1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/TR2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/TR3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/TR4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/TR5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/TR6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/TR7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/TR1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/TR2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/TR3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/TR4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/TR5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/TR6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/TR7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/TR1_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/TR2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/TR3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/TR4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/TR5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/TR6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/TR7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:69: RuntimeWarning: Mean of empty slice\n",
      "C:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:70: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "# sub_type = 'AB'\n",
    "test_dict = {'sub_type':sub_type,'dt':'manual', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partgauss4','feat_type':'tdar', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "test_all = ['noisescalelim']\n",
    "load = False\n",
    "if load:\n",
    "    posi_max = 2\n",
    "else:\n",
    "    posi_max = 5\n",
    "\n",
    "for dt in dt_all:\n",
    "    test_sess.dt = dt\n",
    "    for j in range(1):\n",
    "        test_sess.mod_dt = mod_all[j]\n",
    "        test_sess.test_dt = test_all[j]\n",
    "        for posi in range(1,posi_max):\n",
    "            ntype = 'posrealmixeven'\n",
    "            \n",
    "            if not load:\n",
    "                ntype += str(posi)\n",
    "\n",
    "            if ntype[:3] == 'pos' and not load:\n",
    "                i_start = 4\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "            elif ntype == 'flat' or 'mix' in ntype or 'real' in ntype:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "            else:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "\n",
    "            for i in range(i_start,i_end):\n",
    "                if load and 'pos' in ntype:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "                else:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i)    \n",
    "\n",
    "                if load:\n",
    "                    for sub in range(1,np.max(params[:,0])+1):\n",
    "                        foldername = test_sess.create_foldername(ftype='results')\n",
    "                    \n",
    "                        filename = test_sess.create_filename(foldername, 1, sub)\n",
    "                        print(filename + '_' + test_sess.n_test)\n",
    "                        if os.path.isfile(filename + '_' + test_sess.n_test + '_subresults.p'):\n",
    "                            with open(filename + '_' + test_sess.n_test + '_subresults.p', 'rb') as f:\n",
    "                                temp_all, temp_noise, temp_clean = pickle.load(f)\n",
    "                            acc_all[sub-1,i-i_start,:,:], acc_clean[sub-1,i-i_start,:,:], acc_noise[sub-1,i-i_start,:,:] = np.squeeze(temp_all),np.squeeze(temp_clean),np.squeeze(temp_noise)\n",
    "                else:\n",
    "                    # test_out, x_test_noise, x_test_clean, y_test_clean = test_sess.loop_test(raw, params)\n",
    "                    test_out = test_sess.loop_test(raw, params)\n",
    "                    print(test_out)\n",
    "                    for key,val in test_out.items():\n",
    "                        exec(key + '=val')\n",
    "\n",
    "            ave_pos_noise= np.nanmean(acc_noise,axis=0)\n",
    "            ave_pos_clean = np.nanmean(acc_clean,axis=0)\n",
    "            ave_noise= np.nanmean(acc_noise,axis=2)\n",
    "            ave_clean = np.nanmean(acc_clean,axis=2)\n",
    "            ave_gauss_noise = np.nanmean(ave_noise,axis=0)\n",
    "            ave_gauss_clean = np.nanmean(ave_clean,axis=0)\n",
    "\n",
    "            if load:\n",
    "                plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type)\n",
    "\n",
    "            if 'gauss' in ntype:\n",
    "                ave_gauss= cp.deepcopy(ave_noise)\n",
    "            elif 'flat' in ntype:\n",
    "                ave_flat = cp.deepcopy(ave_noise)\n",
    "            elif '60hz' in ntype:\n",
    "                ave_60hz = cp.deepcopy(ave_noise)\n",
    "            elif 'mix' in ntype:\n",
    "                ave_mix = cp.deepcopy(ave_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,0.2,200)\n",
    "temp = []\n",
    "gauss = []\n",
    "fig, ax = plt.subplots(11,1)\n",
    "for a in range(1,6):\n",
    "    temp.append(a*np.sin(2*np.pi*60*x))\n",
    "    gauss.append(np.random.normal(0,a,len(x)))\n",
    "    ax[a-1].plot(x*1000,temp[a-1],'b',label='A = ' + str(a))\n",
    "    ax[a+4].plot(x*1000,gauss[a-1],label='A = ' + str(a))\n",
    "\n",
    "ax[-1].plot(x*1000,np.zeros(x.shape))\n",
    "# ax.legend()\n",
    "for i in range(11):\n",
    "    if i > 0: \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_yticklabels([])\n",
    "    if i < 10:\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_xticklabels([])\n",
    "    ax[i].set_ylim([-5,5])\n",
    "    ax[i].set_xlim([0,200])\n",
    "ax[-1].set_xlabel('Time (ms)')\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posrealmixeven1\n",
      "Loading training data: traindata_all/TR1_traindata_2.p\n",
      "loading data\n",
      "5.54 ms ± 38.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "5.75 ms ± 38.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "6.59 µs ± 64.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "6.65 µs ± 68.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partposrealmixeven14','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "sae_time = [None] * np.max(params[:,0])\n",
    "cnn_time = [None] * np.max(params[:,0])\n",
    "lda_time = [None] * np.max(params[:,0])\n",
    "aug_time = [None] * np.max(params[:,0])\n",
    "\n",
    "# set number of models to test\n",
    "mod_tot = 15\n",
    "# set testing noise type\n",
    "noise_type = test_sess.n_test[4:-1]\n",
    "print(noise_type)\n",
    "\n",
    "# load real_noise\n",
    "if 'real' in noise_type:\n",
    "    with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "        real_noise_temp, _ = pickle.load(f)\n",
    "\n",
    "cv_tot = 1\n",
    "test_sess.max_cv = cv_tot + 1\n",
    "\n",
    "filename = 0\n",
    "\n",
    "# Set folder\n",
    "foldername = test_sess.create_foldername()\n",
    "resultsfolder = test_sess.create_foldername(ftype='results')\n",
    "\n",
    "num_feats = 4\n",
    "\n",
    "# loop through subjects\n",
    "sub = 1        \n",
    "# index based on training group and subject\n",
    "ind = (params[:,0] == sub) & (params[:,3] == test_sess.train_grp)\n",
    "\n",
    "# Check if training data exists\n",
    "if np.sum(ind):\n",
    "    # loop through cvs\n",
    "    filename = test_sess.create_filename(foldername, 1, sub)\n",
    "\n",
    "    x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,test_sess.sub_type,dt=test_sess.dt,train_grp=test_sess.train_grp)\n",
    "    \n",
    "    # Load saved data\n",
    "    with open(filename + '.p', 'rb') as f:\n",
    "        scaler, svae_w, svae_enc_w, svae_dec_w, svae_clf_w, sae_w, sae_enc_w, sae_clf_w, cnn_w, cnn_enc_w, cnn_clf_w, vcnn_w, vcnn_enc_w, vcnn_clf_w, ecnn_w, ecnn_enc_w, ecnn_clf_w, w_svae, c_svae, w_sae, c_sae, w_cnn, c_cnn, w_vcnn, c_vcnn, w_ecnn, c_ecnn, w, c, w_noise, c_noise, mu, C, qda, qda_noise,emg_scale = pickle.load(f)   \n",
    "\n",
    "    # Add noise to training data\n",
    "    y_shape = np.max(p_train[:,4])\n",
    "    # Build models and set weights\n",
    "    sae, sae_enc, sae_clf = dl.build_sae(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "    cnn, cnn_enc, cnn_clf = dl.build_cnn(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "\n",
    "    sae.set_weights(sae_w)\n",
    "    sae_enc.set_weights(sae_enc_w)\n",
    "    sae_clf.set_weights(sae_clf_w)\n",
    "\n",
    "    cnn.set_weights(cnn_w)\n",
    "    cnn_enc.set_weights(cnn_enc_w)\n",
    "    cnn_clf.set_weights(cnn_clf_w)\n",
    "\n",
    "    # set test on validation data for cv mode\n",
    "    x_test = x_test*emg_scale\n",
    "\n",
    "    # loop through test levels\n",
    "    noisefolder = test_sess.create_foldername(ftype='testnoise')\n",
    "    noisefile = test_sess.create_filename(noisefolder,1, sub, ftype='testnoise', test_scale=1)\n",
    "    \n",
    "    if os.path.isfile(noisefile + '.p'):\n",
    "        print('loading data')\n",
    "        with open(noisefile + '.p','rb') as f:\n",
    "            x_test_vae, x_test_clean_vae, x_test_lda, y_test_clean = pickle.load(f) \n",
    "        test_load = True\n",
    "    x_temp = np.transpose(x_test_lda.reshape((x_test_lda.shape[0],num_feats,-1)),(0,2,1))[...,np.newaxis]\n",
    "    x_test_vae = scaler.transform(x_temp.reshape(x_temp.shape[0]*x_temp.shape[1],-1)).reshape(x_temp.shape)\n",
    "\n",
    "    # Reshape for nonconvolutional SAE\n",
    "    x_test_dlsae = x_test_vae.reshape(x_test_vae.shape[0],-1)\n",
    "\n",
    "    ## for timing\n",
    "    %timeit predict(sae_enc(x_test_dlsae[[0],...].astype('float32')).numpy(),w_sae,c_sae)\n",
    "\n",
    "    %timeit predict(cnn_enc(x_test_vae[[0],...].astype('float32')).numpy(),w_cnn,c_cnn)\n",
    "\n",
    "    # lda_start = time.time()\n",
    "    # temp_out = predict(x_test_lda[[0],...], w, c)\n",
    "    # lda_temp = timeit.timeit(lambda: predict(x_test_lda[[0],...], w, c),number= 100)\n",
    "    %timeit predict(x_test_lda[[0],...], w, c)\n",
    "\n",
    "    %timeit predict(x_test_lda[[0],...], w_noise, c_noise)\n",
    "\n",
    "    temp_x = x_test_lda[[0],...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 µs ± 4.01 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mask = np.ones(6,dtype=bool) \n",
    "for i in range(1):\n",
    "    mask[0] = 0\n",
    "maskmu = np.tile(mask,4)\n",
    "test_data = temp_x[:,maskmu]\n",
    "C_temp = C[maskmu,:]\n",
    "C_in = C_temp[:,maskmu]\n",
    "w_temp, c_temp = train_lda(test_data,1,mu_bool = True, mu_class = mu[:,maskmu], C = C_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "px = 1/plt.rcParams['figure.dpi']  # pixel in inches\n",
    "w = 1200\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*px, h*px)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "acc, std = plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "mm = 1/25.4 \n",
    "w = 170\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*mm, h*mm)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_diff = acc[:,7] - acc[:,14]\n",
    "sae_diff_tr = acc_tr[:,7] - acc_tr[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr = cp.deepcopy(acc)\n",
    "std_tr = cp.deepcopy(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_summary(ave_clean,ave_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs. position\n",
    "plot_utils.plot_pos_results(ave_pos_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Mixed Linear Model Regression Results\n",
      "==============================================================================\n",
      "Model:                    MixedLM        Dependent Variable:        acc       \n",
      "No. Observations:         325            Method:                    REML      \n",
      "No. Groups:               13             Scale:                     27.6158   \n",
      "Min. group size:          25             Log-Likelihood:            -1018.6663\n",
      "Max. group size:          25             Converged:                 Yes       \n",
      "Mean group size:          25.0                                                \n",
      "------------------------------------------------------------------------------\n",
      "                                   Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept                          21.354    2.858   7.472 0.000 15.752 26.955\n",
      "C(mod, Treatment(10))[T.1.0]        2.156    1.597   1.350 0.177 -0.974  5.285\n",
      "C(mod, Treatment(10))[T.2.0]       -2.930    1.597  -1.835 0.067 -6.059  0.200\n",
      "C(mod, Treatment(10))[T.11.0]       1.235    1.597   0.773 0.439 -1.895  4.364\n",
      "C(mod, Treatment(10))[T.14.0]      -5.793    1.597  -3.628 0.000 -8.922 -2.663\n",
      "elec                               11.159    0.461  24.211 0.000 10.256 12.062\n",
      "C(mod, Treatment(10))[T.1.0]:elec  -6.925    0.652 -10.625 0.000 -8.203 -5.648\n",
      "C(mod, Treatment(10))[T.2.0]:elec  -7.526    0.652 -11.547 0.000 -8.804 -6.249\n",
      "C(mod, Treatment(10))[T.11.0]:elec -4.300    0.652  -6.597 0.000 -5.578 -3.022\n",
      "C(mod, Treatment(10))[T.14.0]:elec -6.384    0.652  -9.794 0.000 -7.661 -5.106\n",
      "Group Var                          89.618    7.186                            \n",
      "==============================================================================\n",
      "\n",
      "0.0\n",
      "                 Mixed Linear Model Regression Results\n",
      "========================================================================\n",
      "Model:                   MixedLM      Dependent Variable:      acc      \n",
      "No. Observations:        65           Method:                  REML     \n",
      "No. Groups:              13           Scale:                   15.5565  \n",
      "Min. group size:         5            Log-Likelihood:          -196.6136\n",
      "Max. group size:         5            Converged:               Yes      \n",
      "Mean group size:         5.0                                            \n",
      "------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.   z   P>|z| [0.025 0.975]\n",
      "------------------------------------------------------------------------\n",
      "Intercept                      17.574    3.396 5.175 0.000 10.918 24.230\n",
      "C(mod, Treatment(10))[T.1.0]    7.020    1.547 4.538 0.000  3.988 10.052\n",
      "C(mod, Treatment(10))[T.2.0]    1.730    1.547 1.118 0.264 -1.302  4.762\n",
      "C(mod, Treatment(10))[T.11.0]   5.890    1.547 3.807 0.000  2.858  8.922\n",
      "C(mod, Treatment(10))[T.14.0]   0.000    1.547 0.000 1.000 -3.032  3.032\n",
      "Group Var                     134.367   15.909                          \n",
      "========================================================================\n",
      "\n",
      "1.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       acc      \n",
      "No. Observations:         65            Method:                   REML     \n",
      "No. Groups:               13            Scale:                    17.5551  \n",
      "Min. group size:          5             Log-Likelihood:           -198.2504\n",
      "Max. group size:          5             Converged:                Yes      \n",
      "Mean group size:          5.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.   z    P>|z|  [0.025  0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                      34.734    3.106 11.183 0.000  28.647  40.822\n",
      "C(mod, Treatment(10))[T.1.0]   -7.602    1.643 -4.626 0.000 -10.823  -4.381\n",
      "C(mod, Treatment(10))[T.2.0]  -13.066    1.643 -7.951 0.000 -16.287  -9.845\n",
      "C(mod, Treatment(10))[T.11.0]  -5.686    1.643 -3.460 0.001  -8.907  -2.465\n",
      "C(mod, Treatment(10))[T.14.0] -15.176    1.643 -9.234 0.000 -18.397 -11.955\n",
      "Group Var                     107.854   12.132                             \n",
      "===========================================================================\n",
      "\n",
      "2.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        65             Method:                    REML     \n",
      "No. Groups:              13             Scale:                     25.9260  \n",
      "Min. group size:         5              Log-Likelihood:            -206.5852\n",
      "Max. group size:         5              Converged:                 Yes      \n",
      "Mean group size:         5.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      47.246    2.970  15.909 0.000  41.426  53.067\n",
      "C(mod, Treatment(10))[T.1.0]  -16.295    1.997  -8.159 0.000 -20.209 -12.380\n",
      "C(mod, Treatment(10))[T.2.0]  -22.501    1.997 -11.267 0.000 -26.415 -18.587\n",
      "C(mod, Treatment(10))[T.11.0] -11.945    1.997  -5.981 0.000 -15.859  -8.031\n",
      "C(mod, Treatment(10))[T.14.0] -24.110    1.997 -12.072 0.000 -28.024 -20.195\n",
      "Group Var                      88.725    8.418                              \n",
      "============================================================================\n",
      "\n",
      "3.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        65             Method:                    REML     \n",
      "No. Groups:              13             Scale:                     30.6327  \n",
      "Min. group size:         5              Log-Likelihood:            -209.3478\n",
      "Max. group size:         5              Converged:                 Yes      \n",
      "Mean group size:         5.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      56.138    2.786  20.154 0.000  50.679  61.598\n",
      "C(mod, Treatment(10))[T.1.0]  -20.380    2.171  -9.388 0.000 -24.635 -16.125\n",
      "C(mod, Treatment(10))[T.2.0]  -27.277    2.171 -12.565 0.000 -31.532 -23.022\n",
      "C(mod, Treatment(10))[T.11.0] -13.266    2.171  -6.111 0.000 -17.521  -9.011\n",
      "C(mod, Treatment(10))[T.14.0] -28.018    2.171 -12.906 0.000 -32.272 -23.763\n",
      "Group Var                      70.235    6.297                              \n",
      "============================================================================\n",
      "\n",
      "4.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        65             Method:                    REML     \n",
      "No. Groups:              13             Scale:                     35.8051  \n",
      "Min. group size:         5              Log-Likelihood:            -211.4395\n",
      "Max. group size:         5              Converged:                 Yes      \n",
      "Mean group size:         5.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      62.666    2.581  24.277 0.000  57.607  67.725\n",
      "C(mod, Treatment(10))[T.1.0]  -21.218    2.347  -9.040 0.000 -25.818 -16.618\n",
      "C(mod, Treatment(10))[T.2.0]  -28.796    2.347 -12.269 0.000 -33.396 -24.196\n",
      "C(mod, Treatment(10))[T.11.0] -11.820    2.347  -5.036 0.000 -16.420  -7.220\n",
      "C(mod, Treatment(10))[T.14.0] -25.499    2.347 -10.864 0.000 -30.099 -20.898\n",
      "Group Var                      50.813    4.422                              \n",
      "============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = stat.create_dataframe(acc_clean,acc_noise)\n",
    "df = stat.get_mods(df)\n",
    "all_md = stat.run_fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                        1.193632e-06\n",
      "C(mod, Treatment(10))[T.6.0]     7.780299e-02\n",
      "C(mod, Treatment(10))[T.7.0]     4.469587e+00\n",
      "C(mod, Treatment(10))[T.11.0]    3.064230e-22\n",
      "C(mod, Treatment(10))[T.14.0]    5.000000e+00\n",
      "Group Var                        2.328940e-01\n",
      "dtype: float64\n",
      "Intercept                        4.416554e-29\n",
      "C(mod, Treatment(10))[T.6.0]     2.115892e-04\n",
      "C(mod, Treatment(10))[T.7.0]     1.401737e-13\n",
      "C(mod, Treatment(10))[T.11.0]    3.133384e-05\n",
      "C(mod, Treatment(10))[T.14.0]    2.129329e-12\n",
      "Group Var                        2.311695e-01\n",
      "dtype: float64\n",
      "Intercept                        6.063096e-60\n",
      "C(mod, Treatment(10))[T.6.0]     1.412260e-11\n",
      "C(mod, Treatment(10))[T.7.0]     1.016878e-26\n",
      "C(mod, Treatment(10))[T.11.0]    1.649802e+00\n",
      "C(mod, Treatment(10))[T.14.0]    3.400562e-23\n",
      "Group Var                        2.669334e-01\n",
      "dtype: float64\n",
      "Intercept                        8.607356e-94\n",
      "C(mod, Treatment(10))[T.6.0]     1.186216e-13\n",
      "C(mod, Treatment(10))[T.7.0]     6.444625e-33\n",
      "C(mod, Treatment(10))[T.11.0]    4.022814e+00\n",
      "C(mod, Treatment(10))[T.14.0]    2.495244e-26\n",
      "Group Var                        3.059571e-01\n",
      "dtype: float64\n",
      "Intercept                        2.946821e-130\n",
      "C(mod, Treatment(10))[T.6.0]      5.211983e-12\n",
      "C(mod, Treatment(10))[T.7.0]      4.126468e-30\n",
      "C(mod, Treatment(10))[T.11.0]     4.684713e+00\n",
      "C(mod, Treatment(10))[T.14.0]     3.202539e-18\n",
      "Group Var                         3.826802e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # print(all_md[str(i) + '.0'].pvalues)\n",
    "    print(all_md[str(i) + '.0'].pvalues*5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a3b9df806ffb9c99dfd499571232d2e3ccda8a03627b2b254cd16611a407c53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf-2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
