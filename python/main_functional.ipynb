{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import latent.loop as loop\n",
    "import latent.session_functional as session\n",
    "import latent.utils.plot_utils as plot_utils \n",
    "import latent.utils.stats_utils as stat\n",
    "import latent.utils.data_utils as prd\n",
    "import latent.ml.dl_functional as dl\n",
    "from latent.ml.lda import train_lda\n",
    "import os\n",
    "import copy as cp\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "set_gpu()\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "%matplotlib qt\n",
    "mpl.rc('font', family='serif') \n",
    "mpl.rc('font', serif='Palatino Linotype') \n",
    "mpl.rc('font', size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'AB'\n",
    "with open('traindata/train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through training\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim':4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "\n",
    "for i in range(5):\n",
    "    train_out = [None] * np.max(params[:,0])\n",
    "\n",
    "    # loop through subjects\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        print('sub: ' + str(sub_i))\n",
    "        train_out[sub_i-1] = train_sess.loop_cv(raw,params,sub=sub_i,mod=['all'])\n",
    "        gc.collect()\n",
    "    \n",
    "    with open('AB_aug_' + str(i) + '.p', 'wb') as f:\n",
    "        pickle.dump([train_out],f)\n",
    "    \n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_all = [None] * 5\n",
    "aug_all = [None] * 5\n",
    "for i in range(5):\n",
    "    with open('AB_timings_' + str(i)+ '.p', 'rb') as f:\n",
    "        time_all[i] = pickle.load(f)\n",
    "    with open('AB_aug_' + str(i)+ '.p', 'rb') as f:\n",
    "        aug_all[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sae = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_cnn = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_lda = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_aug = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "\n",
    "it = 0\n",
    "for i in range(5):\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        sum_sae[it] = time_all[i][0][sub_i-1]['sae_time'] + time_all[i][0][sub_i-1]['sae_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_cnn[it] = time_all[i][0][sub_i-1]['cnn_time'] + time_all[i][0][sub_i-1]['cnn_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_lda[it] = time_all[i][0][sub_i-1]['lda_time']\n",
    "        sum_aug[it] = time_all[i][0][sub_i-1]['aug lda time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        it += 1\n",
    "\n",
    "mean_sae = np.nanmean(sum_sae)\n",
    "mean_cnn = np.nanmean(sum_cnn)\n",
    "mean_lda = np.nanmean(sum_lda)\n",
    "mean_aug = np.nanmean(sum_aug)\n",
    "\n",
    "std_sae = np.nanstd(sum_sae)\n",
    "std_cnn = np.nanstd(sum_cnn)\n",
    "std_lda = np.nanstd(sum_lda)\n",
    "std_aug = np.nanstd(sum_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensions of inputs\n",
    "sub = 5\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim': 4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "\n",
    "\n",
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'posrealmixeven','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt': 'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict)\n",
    "ntype = 'posrealmixeven'\n",
    "addon = False\n",
    "traintest = 'trainnoise'\n",
    "\n",
    "if not addon:\n",
    "    x_clean_lda = np.array([]).reshape(0,6)\n",
    "    x_clean_noise = np.array([]).reshape(0,6)\n",
    "    x_clean_sae = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "    x_clean_cnn = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "    y_clean = np.array([]).reshape(0,1)\n",
    "    y_noise_clean = np.array([]).reshape(0,1)\n",
    "    max_i = 2\n",
    "\n",
    "    if traintest == 'testnoise':\n",
    "        x_noisy_lda = np.array([]).reshape(0,6)\n",
    "        x_noisy_noise = np.array([]).reshape(0,6)\n",
    "        x_noisy_sae = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "        x_noisy_cnn = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "        y_noisy = np.array([]).reshape(0,1)\n",
    "        max_i = 5\n",
    "\n",
    "if ntype == 'flat':\n",
    "    test_max = 2\n",
    "else:\n",
    "    test_max = 6\n",
    "\n",
    "for i in range(1,max_i):\n",
    "    if traintest == 'testnoise':\n",
    "        test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "        red_out = test_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    else:\n",
    "        red_out = train_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    for key,val in red_out.items():\n",
    "        exec(key + '=val')\n",
    "    x_clean_lda = np.vstack([x_test_lda_red[:clean_size_lda,:], x_clean_lda])\n",
    "    x_clean_noise = np.vstack([x_test_noise_red[:clean_size,:], x_clean_noise])\n",
    "    x_clean_sae = np.vstack([x_test_sae_red[:clean_size,:], x_clean_sae])\n",
    "    x_clean_cnn = np.vstack([x_test_cnn_red[:clean_size,:], x_clean_cnn])\n",
    "    y_clean = np.vstack([y_test[:clean_size_lda,:], y_clean])\n",
    "    y_noise_clean = np.vstack([y_test_noise[:clean_size,:], y_noise_clean])\n",
    "    print(clean_size)\n",
    "    print(clean_size_lda)\n",
    "\n",
    "    x_noisy_lda = np.vstack([x_test_lda_red[clean_size_lda:,:], x_noisy_lda])\n",
    "    x_noisy_noise = np.vstack([x_test_noise_red[clean_size:,:], x_noisy_noise])\n",
    "    x_noisy_sae = np.vstack([x_test_sae_red[clean_size:,:], x_noisy_sae])\n",
    "    x_noisy_cnn = np.vstack([x_test_cnn_red[clean_size:,:], x_noisy_cnn])\n",
    "    y_noisy = np.vstack([y_test[clean_size_lda:,:], y_noisy])\n",
    "\n",
    "x_all_lda = np.vstack([x_clean_lda,x_noisy_lda])\n",
    "x_all_noise = np.vstack([x_clean_noise,x_noisy_noise])\n",
    "x_all_sae = np.vstack([x_clean_sae,x_noisy_sae])\n",
    "x_all_cnn = np.vstack([x_clean_cnn,x_noisy_cnn])\n",
    "y_all = np.vstack([y_clean, y_noisy])\n",
    "\n",
    "lda_lims = tuple(np.vstack((np.min(x_all_lda[:,:3],axis=0),np.max(x_all_lda[:,:3],axis=0))).T)\n",
    "noise_lims = tuple(np.vstack((np.min(x_all_noise[:,:3],axis=0),np.max(x_all_noise[:,:3],axis=0))).T)\n",
    "sae_lims = tuple(np.vstack((np.min(x_all_sae[:,:3],axis=0),np.max(x_all_sae[:,:3],axis=0))).T)\n",
    "cnn_lims = tuple(np.vstack((np.min(x_all_cnn[:,:3],axis=0),np.max(x_all_cnn[:,:3],axis=0))).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced dimensions\n",
    "dim = 3\n",
    "train_downsamp = clean_size//clean_size_lda\n",
    "std_lim = False\n",
    "mult = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plot_utils.plot_latent_rep(x_clean_lda, y_clean,fig,loc=1,lims=lda_lims,downsamp=train_downsamp,dim=dim, lim_min=lda_min, lim_max=lda_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_noise, y_noise_clean,fig,loc=2,lims=noise_lims,downsamp=train_downsamp,dim=dim, lim_min=noise_min, lim_max=noise_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_sae, y_noise_clean,fig,loc=3,lims=sae_lims,dim=dim,downsamp=train_downsamp, lim_min=sae_min, lim_max=sae_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_cnn, y_noise_clean,fig,loc=4,lims=cnn_lims,dim=dim,downsamp=train_downsamp, lim_min=cnn_min, lim_max=cnn_max,std_lim=std_lim,mult = mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsamp = 2\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "lda_min, lda_max = plot_utils.plot_latent_rep(x_noisy_lda, y_noisy,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "noise_min, noise_max = plot_utils.plot_latent_rep(x_noisy_noise, y_noisy,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "sae_min, sae_max = plot_utils.plot_latent_rep(x_noisy_sae, y_noisy,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "cnn_min, cnn_max = plot_utils.plot_latent_rep(x_noisy_cnn, y_noisy,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_utils.plot_latent_rep(x_all_lda, y_all,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_noise, y_all,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_sae, y_all,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_cnn, y_all,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "    real_noise_temp, _ = pickle.load(f)\n",
    "    \n",
    "plot_utils.plot_all_noise(real_noise_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noise = ['breaknm','break','contact','move']\n",
    "\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(12, 4)) \n",
    "gs = gridspec.GridSpec(8, 3)\n",
    "\n",
    "for i in range(4):\n",
    "    ntype = 'posreal' + all_noise[i]\n",
    "    with open(sub_type + '_' + ntype + '1.p', 'rb') as f:\n",
    "        xtestnoise,xtest,y_out = pickle.load(f)\n",
    "    plot_utils.plot_noisy(xtestnoise,xtest,y_out,iter=i, gs=gs)\n",
    "\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.2, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_2_all_emgscalelim_noisescalelim/rev21/AB2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB8_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB9_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB10_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB11_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB12_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB13_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB14_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven14\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB8_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB9_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB10_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB11_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB12_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB13_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB14_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven24\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB8_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB9_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB10_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB11_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB12_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB13_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB14_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven34\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB2_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB3_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB4_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB6_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB7_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB8_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB9_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB10_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB11_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB12_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB13_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n",
      "results_2_all_emgscalelim_noisescalelim/rev21/AB14_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse_partposrealmixeven44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:70: RuntimeWarning: Mean of empty slice\n",
      "c:\\ProgramData\\Anaconda3\\envs\\latent_env\\lib\\site-packages\\ipykernel_launcher.py:71: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "# sub_type = 'AB'\n",
    "test_dict = {'sub_type':sub_type,'dt':'manual', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partgauss4','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "test_all = ['noisescalelim']\n",
    "load = True\n",
    "if load:\n",
    "    posi_max = 2\n",
    "else:\n",
    "    posi_max = 5\n",
    "\n",
    "for dt in dt_all:\n",
    "    test_sess.dt = dt\n",
    "    for j in range(1):\n",
    "        test_sess.mod_dt = mod_all[j]\n",
    "        test_sess.test_dt = test_all[j]\n",
    "        for posi in range(1,posi_max):\n",
    "            ntype = 'posrealmixeven'\n",
    "            \n",
    "            if not load:\n",
    "                ntype += str(posi)\n",
    "\n",
    "            if ntype[:3] == 'pos' and not load:\n",
    "                i_start = 4\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "            elif ntype == 'flat' or 'mix' in ntype or 'real' in ntype:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "            else:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "\n",
    "            for i in range(i_start,i_end):\n",
    "                if load and 'pos' in ntype:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "                else:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i)    \n",
    "\n",
    "                if load:\n",
    "                    for sub in range(2,np.max(params[:,0])+1):\n",
    "                        foldername = test_sess.create_foldername(ftype='results')\n",
    "                        foldername += '/rev21'\n",
    "                        # foldername += '/temp'\n",
    "                        filename = test_sess.create_filename(foldername, 1, sub)\n",
    "                        print(filename + '_' + test_sess.n_test)\n",
    "                        if os.path.isfile(filename + '_' + test_sess.n_test + '_subresults.p'):\n",
    "                            with open(filename + '_' + test_sess.n_test + '_subresults.p', 'rb') as f:\n",
    "                                temp_all, temp_noise, temp_clean = pickle.load(f)\n",
    "                            acc_all[sub-1,i-i_start,:,:], acc_clean[sub-1,i-i_start,:,:], acc_noise[sub-1,i-i_start,:,:] = np.squeeze(temp_all),np.squeeze(temp_clean),np.squeeze(temp_noise)\n",
    "                else:\n",
    "                    # test_out, x_test_noise, x_test_clean, y_test_clean = test_sess.loop_test(raw, params)\n",
    "                    test_out = test_sess.loop_test(raw, params)\n",
    "                    # print(test_out)\n",
    "                    for key,val in test_out.items():\n",
    "                        exec(key + '=val')\n",
    "\n",
    "            ave_pos_noise= np.nanmean(acc_noise,axis=0)\n",
    "            ave_pos_clean = np.nanmean(acc_clean,axis=0)\n",
    "            ave_noise= np.nanmean(acc_noise,axis=2)\n",
    "            ave_clean = np.nanmean(acc_clean,axis=2)\n",
    "            ave_gauss_noise = np.nanmean(ave_noise,axis=0)\n",
    "            ave_gauss_clean = np.nanmean(ave_clean,axis=0)\n",
    "\n",
    "            if load:\n",
    "                plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type)\n",
    "\n",
    "            if 'gauss' in ntype:\n",
    "                ave_gauss= cp.deepcopy(ave_noise)\n",
    "            elif 'flat' in ntype:\n",
    "                ave_flat = cp.deepcopy(ave_noise)\n",
    "            elif '60hz' in ntype:\n",
    "                ave_60hz = cp.deepcopy(ave_noise)\n",
    "            elif 'mix' in ntype:\n",
    "                ave_mix = cp.deepcopy(ave_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_noise2 = cp.deepcopy(ave_noise)\n",
    "ave_clean2 = cp.deepcopy(ave_clean)\n",
    "acc_clean2 = cp.deepcopy(acc_clean)\n",
    "acc_noise2 = cp.deepcopy(acc_noise)\n",
    "# ave_mix2 = cp.deepcopy(ave_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_noise2[:,:,4] = ave_noise[:,:,6]\n",
    "ave_clean2[:,:,4] = ave_clean[:,:,6]\n",
    "ave_noise2[:,:,5] = ave_noise[:,:,7]\n",
    "ave_clean2[:,:,5] = ave_clean[:,:,7]\n",
    "acc_clean2[...,4] = acc_clean[...,6]\n",
    "acc_noise2[...,4] = acc_noise[...,6]\n",
    "acc_clean2[...,5] = acc_clean[...,7]\n",
    "acc_noise2[...,5] = acc_noise[...,7]\n",
    "# ave_mix2[:,:,4] = ave_mix[:,:,6]\n",
    "# ave_mix2[:,:,5] = ave_mix[:,:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_nn_results(ave_noise,ave_clean,ave_noise2, ave_clean2, test_sess.n_train,ntype,test_sess.sub_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yteh\\Documents\\work\\git\\projects\\latent_rep\\python\\latent\\utils\\plot_utils.py:358: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax[i].set_yticklabels([''])\n"
     ]
    }
   ],
   "source": [
    "plot_utils.plot_aug_results(ave_noise,ave_clean,ave_noise2, ave_clean2, test_sess.n_train,ntype,test_sess.sub_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = 1/25.4 \n",
    "w = 210\n",
    "h = w/2\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*mm, h*mm)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2.75])\n",
    "plot_utils.plot_electrode_results_aug(ave_noise2,ave_clean2,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "diff_mix,c ,c1 = plot_utils.plot_summary_aug(ave_clean2,ave_noise2,gs=gs[1])\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "px = 1/plt.rcParams['figure.dpi']  # pixel in inches\n",
    "w = 1200\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*px, h*px)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "acc, std = plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "mm = 1/25.4 \n",
    "w = 200\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*mm, h*mm)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,0.2,200)\n",
    "temp = []\n",
    "gauss = []\n",
    "fig, ax = plt.subplots(11,1)\n",
    "for a in range(1,6):\n",
    "    temp.append(a*np.sin(2*np.pi*60*x))\n",
    "    gauss.append(np.random.normal(0,a,len(x)))\n",
    "    ax[a-1].plot(x*1000,temp[a-1],'b',label='A = ' + str(a))\n",
    "    ax[a+4].plot(x*1000,gauss[a-1],label='A = ' + str(a))\n",
    "\n",
    "ax[-1].plot(x*1000,np.zeros(x.shape))\n",
    "# ax.legend()\n",
    "for i in range(11):\n",
    "    if i > 0: \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_yticklabels([])\n",
    "    if i < 10:\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_xticklabels([])\n",
    "    ax[i].set_ylim([-5,5])\n",
    "    ax[i].set_xlim([0,200])\n",
    "ax[-1].set_xlabel('Time (ms)')\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent.ml.lda import predict, train_lda\n",
    "from latent.ml.dl_subclass import MLP, CNN\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partposrealmixeven14','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "sae_time = [None] * np.max(params[:,0])\n",
    "cnn_time = [None] * np.max(params[:,0])\n",
    "lda_time = [None] * np.max(params[:,0])\n",
    "aug_time = [None] * np.max(params[:,0])\n",
    "\n",
    "# set number of models to test\n",
    "mod_tot = 15\n",
    "# set testing noise type\n",
    "noise_type = test_sess.n_test[4:-1]\n",
    "print(noise_type)\n",
    "\n",
    "# load real_noise\n",
    "if 'real' in noise_type:\n",
    "    with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "        real_noise_temp, _ = pickle.load(f)\n",
    "\n",
    "cv_tot = 1\n",
    "test_sess.max_cv = cv_tot + 1\n",
    "\n",
    "filename = 0\n",
    "\n",
    "# Set folder\n",
    "foldername = test_sess.create_foldername()\n",
    "resultsfolder = test_sess.create_foldername(ftype='results')\n",
    "\n",
    "num_feats = 10\n",
    "\n",
    "# loop through subjects\n",
    "sub = 1\n",
    "# index based on training group and subject\n",
    "ind = (params[:,0] == sub) & (params[:,3] == test_sess.train_grp)\n",
    "\n",
    "# Check if training data exists\n",
    "if np.sum(ind):\n",
    "    # loop through cvs\n",
    "    filename = test_sess.create_filename(foldername, 1, sub)\n",
    "\n",
    "    x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,test_sess.sub_type,dt=test_sess.dt,train_grp=test_sess.train_grp)\n",
    "    filename = 'subclass/models/TR' + str(sub) + '_tdar'\n",
    "    with open(filename + '.p', 'rb') as f:\n",
    "        mlp_w, _, cnn_w, w_sae, c_sae, _, _, w_cnn, c_cnn, w, c, w_noise, c_noise, emg_scale, scaler, mu_class, C = pickle.load(f)\n",
    "    # Load saved data\n",
    "    # with open(filename + '.p', 'rb') as f:\n",
    "    #     scaler, svae_w, svae_enc_w, svae_dec_w, svae_clf_w, sae_w, sae_enc_w, sae_clf_w, cnn_w, cnn_enc_w, cnn_clf_w, vcnn_w, vcnn_enc_w, vcnn_clf_w, ecnn_w, ecnn_enc_w, ecnn_clf_w, w_svae, c_svae, w_sae, c_sae, w_cnn, c_cnn, w_vcnn, c_vcnn, w_ecnn, c_ecnn, w, c, w_noise, c_noise, mu, C, qda, qda_noise,emg_scale = pickle.load(f)   \n",
    "\n",
    "    # Add noise to training data\n",
    "    y_shape = np.max(p_train[:,4])\n",
    "\n",
    "    sae = MLP(n_class=y_shape)\n",
    "    cnn = CNN(n_class=y_shape)\n",
    "    \n",
    "    # Build models and set weights\n",
    "    # sae, sae_enc, sae_clf = dl.build_sae(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "    # cnn, cnn_enc, cnn_clf = dl.build_cnn(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "\n",
    "    # sae.set_weights(sae_w)\n",
    "    # sae_enc.set_weights(sae_enc_w)\n",
    "    # sae_clf.set_weights(sae_clf_w)\n",
    "\n",
    "    # cnn.set_weights(cnn_w)\n",
    "    # cnn_enc.set_weights(cnn_enc_w)\n",
    "    # cnn_clf.set_weights(cnn_clf_w)\n",
    "\n",
    "    # set test on validation data for cv mode\n",
    "    x_test = x_test*emg_scale\n",
    "\n",
    "    # loop through test levels\n",
    "    noisefolder = test_sess.create_foldername(ftype='testnoise')\n",
    "    noisefolder = 'testdata/' + noisefolder\n",
    "    noisefile = test_sess.create_filename(noisefolder,1, sub, ftype='testnoise', test_scale=1)\n",
    "    if os.path.isfile(noisefile + '.p'):\n",
    "        print('loading data')\n",
    "        with open(noisefile + '.p','rb') as f:\n",
    "            x_test_vae, x_test_clean_vae, x_test_lda, y_test_clean = pickle.load(f) \n",
    "        test_load = True\n",
    "    x_temp = np.transpose(x_test_lda.reshape((x_test_lda.shape[0],num_feats,-1)),(0,2,1))[...,np.newaxis]\n",
    "    x_test_vae = scaler.transform(x_temp.reshape(x_temp.shape[0]*x_temp.shape[1],-1)).reshape(x_temp.shape)\n",
    "\n",
    "    # Reshape for nonconvolutional SAE\n",
    "    x_test_dlsae = x_test_vae.reshape(x_test_vae.shape[0],-1)\n",
    "\n",
    "    sae(x_test_dlsae[:1,...].astype('float32'))\n",
    "    cnn(x_test_vae[:1,...].astype('float32'))\n",
    "    sae.set_weights(mlp_w)\n",
    "    cnn.set_weights(cnn_w)\n",
    "    sae_enc = sae.enc\n",
    "    cnn_enc = cnn.enc\n",
    "    ## for timing\n",
    "    %timeit predict(sae_enc(x_test_dlsae[[0],...].astype('float32')).numpy(),w_sae,c_sae)\n",
    "\n",
    "    %timeit predict(cnn_enc(x_test_vae[[0],...].astype('float32')).numpy(),w_cnn,c_cnn)\n",
    "\n",
    "    # lda_start = time.time()\n",
    "    # temp_out = predict(x_test_lda[[0],...], w, c)\n",
    "    # lda_temp = timeit.timeit(lambda: predict(x_test_lda[[0],...], w, c),number= 100)\n",
    "    %timeit predict(x_test_lda[[0],...], w, c)\n",
    "\n",
    "    %timeit predict(x_test_lda[[0],...], w_noise, c_noise)\n",
    "\n",
    "    temp_x = x_test_lda[[0],...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mask = np.ones(6,dtype=bool) \n",
    "for i in range(1):\n",
    "    mask[0] = 0\n",
    "maskmu = np.tile(mask,4)\n",
    "test_data = temp_x[:,maskmu]\n",
    "C_temp = C[maskmu,:]\n",
    "C_in = C_temp[:,maskmu]\n",
    "w_temp, c_temp = train_lda(test_data,1,mu_bool = True, mu_class = mu[:,maskmu], C = C_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_diff = acc[:,7] - acc[:,14]\n",
    "sae_diff_tr = acc_tr[:,7] - acc_tr[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr = cp.deepcopy(acc)\n",
    "std_tr = cp.deepcopy(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_summary(ave_clean,ave_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs. position\n",
    "plot_utils.plot_pos_results(ave_pos_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = stat.create_dataframe(acc_clean2,acc_noise2)\n",
    "df = stat.get_mods(df)\n",
    "all_md = stat.run_fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    # print(all_md[str(i) + '.0'].pvalues)\n",
    "    print(all_md[str(i) + '.0'].pvalues*5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0112058e73182145abb4cd7aaf50d75809c95241f4ac2fefe0df8a318b89874e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('latent_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
