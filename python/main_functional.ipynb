{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import latent.loop as loop\n",
    "import latent.session_functional as session\n",
    "import latent.utils.plot_utils as plot_utils \n",
    "import latent.utils.stats_utils as stat\n",
    "import latent.utils.data_utils as prd\n",
    "import latent.ml.dl_functional as dl\n",
    "from latent.ml.lda import train_lda\n",
    "import os\n",
    "import copy as cp\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "set_gpu()\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "%matplotlib qt\n",
    "mpl.rc('font', family='serif') \n",
    "mpl.rc('font', serif='Palatino Linotype') \n",
    "mpl.rc('font', size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_type = 'TR'\n",
    "with open('traindata/train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through training\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim':4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "\n",
    "for i in range(5):\n",
    "    train_out = [None] * np.max(params[:,0])\n",
    "\n",
    "    # loop through subjects\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        print('sub: ' + str(sub_i))\n",
    "        train_out[sub_i-1] = train_sess.loop_cv(raw,params,sub=sub_i,mod=['all'])\n",
    "        gc.collect()\n",
    "    \n",
    "    with open('AB_aug_' + str(i) + '.p', 'wb') as f:\n",
    "        pickle.dump([train_out],f)\n",
    "    \n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_all = [None] * 5\n",
    "aug_all = [None] * 5\n",
    "for i in range(5):\n",
    "    with open('AB_timings_' + str(i)+ '.p', 'rb') as f:\n",
    "        time_all[i] = pickle.load(f)\n",
    "    with open('AB_aug_' + str(i)+ '.p', 'rb') as f:\n",
    "        aug_all[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sae = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_cnn = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_lda = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "sum_aug = np.full((5*np.max(params[:,0]),),np.nan)\n",
    "\n",
    "it = 0\n",
    "for i in range(5):\n",
    "    for sub_i in range(1,np.max(params[:,0])+1):\n",
    "        sum_sae[it] = time_all[i][0][sub_i-1]['sae_time'] + time_all[i][0][sub_i-1]['sae_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_cnn[it] = time_all[i][0][sub_i-1]['cnn_time'] + time_all[i][0][sub_i-1]['cnn_a_time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        sum_lda[it] = time_all[i][0][sub_i-1]['lda_time']\n",
    "        sum_aug[it] = time_all[i][0][sub_i-1]['aug lda time'] + aug_all[i][0][sub_i-1]['noise_time']\n",
    "        it += 1\n",
    "\n",
    "mean_sae = np.nanmean(sum_sae)\n",
    "mean_cnn = np.nanmean(sum_cnn)\n",
    "mean_lda = np.nanmean(sum_lda)\n",
    "mean_aug = np.nanmean(sum_aug)\n",
    "\n",
    "std_sae = np.nanstd(sum_sae)\n",
    "std_cnn = np.nanstd(sum_cnn)\n",
    "std_lda = np.nanstd(sum_lda)\n",
    "std_aug = np.nanstd(sum_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_2_all_emgscalelim/TR5_feat_dim_4_ep_30_bat_128_fullallmix4_5_lr_10_sparse\n",
      "noisedata/noisedata_all_emgscalelim/TR5_grp_2_fullallmix4_5\n",
      "loading data\n",
      "(22500, 60)\n",
      "WARNING:tensorflow:Layer mlp is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer cnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "(22500, 6)\n",
      "2500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensions of inputs\n",
    "sub = 5\n",
    "train_dict = {'sub_type':sub_type,'n_train':'fullallmix4', 'load':False, 'train_scale':5, 'epochs': 30, 'batch_size' : 128, 'sparsity':True,'dt':'all','feat_type':'feat','noise':True,'gens':50, 'mod_dt':'emgscalelim','train_grp':2,'latent_dim': 4}\n",
    "train_sess = session.Session(**train_dict)\n",
    "\n",
    "\n",
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'posrealmixeven','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt': 'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict)\n",
    "ntype = 'posrealmixeven'\n",
    "addon = False\n",
    "traintest = 'trainnoise'\n",
    "\n",
    "if not addon:\n",
    "    x_clean_lda = np.array([]).reshape(0,6)\n",
    "    x_clean_noise = np.array([]).reshape(0,6)\n",
    "    x_clean_sae = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "    x_clean_cnn = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "    y_clean = np.array([]).reshape(0,1)\n",
    "    y_noise_clean = np.array([]).reshape(0,1)\n",
    "    max_i = 2\n",
    "\n",
    "    if traintest == 'testnoise':\n",
    "        x_noisy_lda = np.array([]).reshape(0,6)\n",
    "        x_noisy_noise = np.array([]).reshape(0,6)\n",
    "        x_noisy_sae = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "        x_noisy_cnn = np.array([]).reshape(0,6)#test_sess.latent_dim)\n",
    "        y_noisy = np.array([]).reshape(0,1)\n",
    "        max_i = 5\n",
    "\n",
    "if ntype == 'flat':\n",
    "    test_max = 2\n",
    "else:\n",
    "    test_max = 6\n",
    "\n",
    "for i in range(1,max_i):\n",
    "    if traintest == 'testnoise':\n",
    "        test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "        red_out = test_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    else:\n",
    "        red_out = train_sess.reduce_latent(raw, params, sub,traintest=traintest)\n",
    "    for key,val in red_out.items():\n",
    "        exec(key + '=val')\n",
    "    x_clean_lda = np.vstack([x_test_lda_red[:clean_size_lda,:], x_clean_lda])\n",
    "    x_clean_noise = np.vstack([x_test_noise_red[:clean_size,:], x_clean_noise])\n",
    "    x_clean_sae = np.vstack([x_test_sae_red[:clean_size,:], x_clean_sae])\n",
    "    x_clean_cnn = np.vstack([x_test_cnn_red[:clean_size,:], x_clean_cnn])\n",
    "    y_clean = np.vstack([y_test[:clean_size_lda,:], y_clean])\n",
    "    y_noise_clean = np.vstack([y_test_noise[:clean_size,:], y_noise_clean])\n",
    "    print(clean_size)\n",
    "    print(clean_size_lda)\n",
    "\n",
    "    x_noisy_lda = np.vstack([x_test_lda_red[clean_size_lda:,:], x_noisy_lda])\n",
    "    x_noisy_noise = np.vstack([x_test_noise_red[clean_size:,:], x_noisy_noise])\n",
    "    x_noisy_sae = np.vstack([x_test_sae_red[clean_size:,:], x_noisy_sae])\n",
    "    x_noisy_cnn = np.vstack([x_test_cnn_red[clean_size:,:], x_noisy_cnn])\n",
    "    y_noisy = np.vstack([y_test[clean_size_lda:,:], y_noisy])\n",
    "\n",
    "x_all_lda = np.vstack([x_clean_lda,x_noisy_lda])\n",
    "x_all_noise = np.vstack([x_clean_noise,x_noisy_noise])\n",
    "x_all_sae = np.vstack([x_clean_sae,x_noisy_sae])\n",
    "x_all_cnn = np.vstack([x_clean_cnn,x_noisy_cnn])\n",
    "y_all = np.vstack([y_clean, y_noisy])\n",
    "\n",
    "lda_lims = tuple(np.vstack((np.min(x_all_lda[:,:3],axis=0),np.max(x_all_lda[:,:3],axis=0))).T)\n",
    "noise_lims = tuple(np.vstack((np.min(x_all_noise[:,:3],axis=0),np.max(x_all_noise[:,:3],axis=0))).T)\n",
    "sae_lims = tuple(np.vstack((np.min(x_all_sae[:,:3],axis=0),np.max(x_all_sae[:,:3],axis=0))).T)\n",
    "cnn_lims = tuple(np.vstack((np.min(x_all_cnn[:,:3],axis=0),np.max(x_all_cnn[:,:3],axis=0))).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced dimensions\n",
    "dim = 3\n",
    "train_downsamp = clean_size//clean_size_lda\n",
    "std_lim = False\n",
    "mult = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plot_utils.plot_latent_rep(x_clean_lda, y_clean,fig,loc=1,lims=lda_lims,downsamp=train_downsamp,dim=dim, lim_min=lda_min, lim_max=lda_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_noise, y_noise_clean,fig,loc=2,lims=noise_lims,downsamp=train_downsamp,dim=dim, lim_min=noise_min, lim_max=noise_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_sae, y_noise_clean,fig,loc=3,lims=sae_lims,dim=dim,downsamp=train_downsamp, lim_min=sae_min, lim_max=sae_max,std_lim=std_lim,mult = mult)\n",
    "plot_utils.plot_latent_rep(x_clean_cnn, y_noise_clean,fig,loc=4,lims=cnn_lims,dim=dim,downsamp=train_downsamp, lim_min=cnn_min, lim_max=cnn_max,std_lim=std_lim,mult = mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsamp = 2\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "lda_min, lda_max = plot_utils.plot_latent_rep(x_noisy_lda, y_noisy,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "noise_min, noise_max = plot_utils.plot_latent_rep(x_noisy_noise, y_noisy,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "sae_min, sae_max = plot_utils.plot_latent_rep(x_noisy_sae, y_noisy,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "cnn_min, cnn_max = plot_utils.plot_latent_rep(x_noisy_cnn, y_noisy,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim,std_lim=std_lim,mult=mult)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.1, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_utils.plot_latent_rep(x_all_lda, y_all,fig,loc=1,lims=lda_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_noise, y_all,fig,loc=2,lims=noise_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_sae, y_all,fig,loc=3,lims=sae_lims,downsamp=downsamp,dim=dim)\n",
    "plot_utils.plot_latent_rep(x_all_cnn, y_all,fig,loc=4,lims=cnn_lims,downsamp=downsamp,dim=dim)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "    real_noise_temp, _ = pickle.load(f)\n",
    "    \n",
    "plot_utils.plot_all_noise(real_noise_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AB_posrealbreaknm1.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2303cabff862>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mntype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'posreal'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mall_noise\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_type\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mntype\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'1.p'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mxtestnoise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mplot_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_noisy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtestnoise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AB_posrealbreaknm1.p'"
     ]
    }
   ],
   "source": [
    "all_noise = ['breaknm','break','contact','move']\n",
    "\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(12, 4)) \n",
    "gs = gridspec.GridSpec(8, 3)\n",
    "\n",
    "for i in range(4):\n",
    "    ntype = 'posreal' + all_noise[i]\n",
    "    with open(sub_type + '_' + ntype + '1.p', 'rb') as f:\n",
    "        xtestnoise,xtest,y_out = pickle.load(f)\n",
    "    plot_utils.plot_noisy(xtestnoise,xtest,y_out,iter=i, gs=gs)\n",
    "\n",
    "fig.subplots_adjust(left=0.1, right=.9, bottom=0.2, top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from gpu import set_gpu\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import latent.loop as loop\n",
    "import latent.session_functional as session\n",
    "import latent.utils.plot_utils as plot_utils \n",
    "import latent.utils.stats_utils as stat\n",
    "import latent.utils.data_utils as prd\n",
    "import latent.ml.dl_functional as dl\n",
    "from latent.ml.lda import train_lda\n",
    "import os\n",
    "import copy as cp\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "set_gpu()\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "%matplotlib qt\n",
    "mpl.rc('font', family='serif') \n",
    "mpl.rc('font', serif='Palatino Linotype') \n",
    "mpl.rc('font', size=12)\n",
    "sub_type = 'AB'\n",
    "with open('traindata/train_data_raw_'  + sub_type + '.p', 'rb') as f:\n",
    "    raw, params,feat,feat_sq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub_type = 'AB'\n",
    "test_dict = {'sub_type':sub_type,'dt':'manual', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partgauss4','feat_type':'tdar', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "dt_all = ['all']\n",
    "mod_all = ['emgscalelim']\n",
    "test_all = ['noisescalelim']\n",
    "load = True\n",
    "if load:\n",
    "    posi_max = 2\n",
    "else:\n",
    "    posi_max = 5\n",
    "\n",
    "for dt in dt_all:\n",
    "    test_sess.dt = dt\n",
    "    for j in range(1):\n",
    "        test_sess.mod_dt = mod_all[j]\n",
    "        test_sess.test_dt = test_all[j]\n",
    "        for posi in range(1,posi_max):\n",
    "            ntype = 'posrealmixeven'\n",
    "            \n",
    "            if not load:\n",
    "                ntype += str(posi)\n",
    "\n",
    "            if ntype[:3] == 'pos' and not load:\n",
    "                i_start = 4\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 3, 4, 15],np.nan)\n",
    "            elif ntype == 'flat' or 'mix' in ntype or 'real' in ntype:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 1, 15],np.nan)\n",
    "            else:\n",
    "                i_start = 1\n",
    "                i_end = 5\n",
    "                acc_all = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_clean = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "                acc_noise = np.full([np.max(params[:,0]), 4, 5, 15],np.nan)\n",
    "\n",
    "            for i in range(i_start,i_end):\n",
    "                if load and 'pos' in ntype:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i) + '4'\n",
    "                else:\n",
    "                    test_sess.n_test = 'part' + ntype + str(i)    \n",
    "\n",
    "                if load:\n",
    "                    for sub in range(1,np.max(params[:,0])+1):\n",
    "                        foldername = test_sess.create_foldername(ftype='results')\n",
    "                        # foldername += '/tdar_lat_8'\n",
    "                        filename = test_sess.create_filename(foldername, 1, sub)\n",
    "                        print(filename + '_' + test_sess.n_test)\n",
    "                        if os.path.isfile(filename + '_' + test_sess.n_test + '_subresults.p'):\n",
    "                            with open(filename + '_' + test_sess.n_test + '_subresults.p', 'rb') as f:\n",
    "                                temp_all, temp_noise, temp_clean = pickle.load(f)\n",
    "                            acc_all[sub-1,i-i_start,:,:], acc_clean[sub-1,i-i_start,:,:], acc_noise[sub-1,i-i_start,:,:] = np.squeeze(temp_all),np.squeeze(temp_clean),np.squeeze(temp_noise)\n",
    "                else:\n",
    "                    # test_out, x_test_noise, x_test_clean, y_test_clean = test_sess.loop_test(raw, params)\n",
    "                    test_out = test_sess.loop_test(raw, params)\n",
    "                    print(test_out)\n",
    "                    for key,val in test_out.items():\n",
    "                        exec(key + '=val')\n",
    "\n",
    "            ave_pos_noise= np.nanmean(acc_noise,axis=0)\n",
    "            ave_pos_clean = np.nanmean(acc_clean,axis=0)\n",
    "            ave_noise= np.nanmean(acc_noise,axis=2)\n",
    "            ave_clean = np.nanmean(acc_clean,axis=2)\n",
    "            ave_gauss_noise = np.nanmean(ave_noise,axis=0)\n",
    "            ave_gauss_clean = np.nanmean(ave_clean,axis=0)\n",
    "\n",
    "            if load:\n",
    "                plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type)\n",
    "\n",
    "            if 'gauss' in ntype:\n",
    "                ave_gauss= cp.deepcopy(ave_noise)\n",
    "            elif 'flat' in ntype:\n",
    "                ave_flat = cp.deepcopy(ave_noise)\n",
    "            elif '60hz' in ntype:\n",
    "                ave_60hz = cp.deepcopy(ave_noise)\n",
    "            elif 'mix' in ntype:\n",
    "                ave_mix = cp.deepcopy(ave_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,0.2,200)\n",
    "temp = []\n",
    "gauss = []\n",
    "fig, ax = plt.subplots(11,1)\n",
    "for a in range(1,6):\n",
    "    temp.append(a*np.sin(2*np.pi*60*x))\n",
    "    gauss.append(np.random.normal(0,a,len(x)))\n",
    "    ax[a-1].plot(x*1000,temp[a-1],'b',label='A = ' + str(a))\n",
    "    ax[a+4].plot(x*1000,gauss[a-1],label='A = ' + str(a))\n",
    "\n",
    "ax[-1].plot(x*1000,np.zeros(x.shape))\n",
    "# ax.legend()\n",
    "for i in range(11):\n",
    "    if i > 0: \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_yticklabels([])\n",
    "    if i < 10:\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_xticklabels([])\n",
    "    ax[i].set_ylim([-5,5])\n",
    "    ax[i].set_xlim([0,200])\n",
    "ax[-1].set_xlabel('Time (ms)')\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posrealmixeven1\n",
      "Loading training data: traindata_all/TR1_traindata_2.p\n",
      "loading data\n",
      "5.54 ms ± 38.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "5.75 ms ± 38.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "6.59 µs ± 64.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "6.65 µs ± 68.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "test_dict = {'sub_type':sub_type,'dt':'all', 'mod_dt':'emgscalelim','sparsity':True, 'load':True, 'batch_size':128, 'latent_dim':4, 'epochs':30,'train_scale':5, 'n_train':'fullallmix4', 'n_test':'partposrealmixeven14','feat_type':'feat', 'noise':True,'train_grp':2,'test_dt':'noisescalelim'}\n",
    "test_sess = session.Session(**test_dict) \n",
    "\n",
    "sae_time = [None] * np.max(params[:,0])\n",
    "cnn_time = [None] * np.max(params[:,0])\n",
    "lda_time = [None] * np.max(params[:,0])\n",
    "aug_time = [None] * np.max(params[:,0])\n",
    "\n",
    "# set number of models to test\n",
    "mod_tot = 15\n",
    "# set testing noise type\n",
    "noise_type = test_sess.n_test[4:-1]\n",
    "print(noise_type)\n",
    "\n",
    "# load real_noise\n",
    "if 'real' in noise_type:\n",
    "    with open('real_noise/all_real_noise.p', 'rb') as f:\n",
    "        real_noise_temp, _ = pickle.load(f)\n",
    "\n",
    "cv_tot = 1\n",
    "test_sess.max_cv = cv_tot + 1\n",
    "\n",
    "filename = 0\n",
    "\n",
    "# Set folder\n",
    "foldername = test_sess.create_foldername()\n",
    "resultsfolder = test_sess.create_foldername(ftype='results')\n",
    "\n",
    "num_feats = 4\n",
    "\n",
    "# loop through subjects\n",
    "sub = 1        \n",
    "# index based on training group and subject\n",
    "ind = (params[:,0] == sub) & (params[:,3] == test_sess.train_grp)\n",
    "\n",
    "# Check if training data exists\n",
    "if np.sum(ind):\n",
    "    # loop through cvs\n",
    "    filename = test_sess.create_filename(foldername, 1, sub)\n",
    "\n",
    "    x_train, x_test, x_valid, p_train, p_test, p_valid = prd.train_data_split(raw,params,sub,test_sess.sub_type,dt=test_sess.dt,train_grp=test_sess.train_grp)\n",
    "    \n",
    "    # Load saved data\n",
    "    with open(filename + '.p', 'rb') as f:\n",
    "        scaler, svae_w, svae_enc_w, svae_dec_w, svae_clf_w, sae_w, sae_enc_w, sae_clf_w, cnn_w, cnn_enc_w, cnn_clf_w, vcnn_w, vcnn_enc_w, vcnn_clf_w, ecnn_w, ecnn_enc_w, ecnn_clf_w, w_svae, c_svae, w_sae, c_sae, w_cnn, c_cnn, w_vcnn, c_vcnn, w_ecnn, c_ecnn, w, c, w_noise, c_noise, mu, C, qda, qda_noise,emg_scale = pickle.load(f)   \n",
    "\n",
    "    # Add noise to training data\n",
    "    y_shape = np.max(p_train[:,4])\n",
    "    # Build models and set weights\n",
    "    sae, sae_enc, sae_clf = dl.build_sae(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "    cnn, cnn_enc, cnn_clf = dl.build_cnn(test_sess.latent_dim, y_shape, input_type=test_sess.feat_type, sparse=test_sess.sparsity,lr=test_sess.lr)\n",
    "\n",
    "    sae.set_weights(sae_w)\n",
    "    sae_enc.set_weights(sae_enc_w)\n",
    "    sae_clf.set_weights(sae_clf_w)\n",
    "\n",
    "    cnn.set_weights(cnn_w)\n",
    "    cnn_enc.set_weights(cnn_enc_w)\n",
    "    cnn_clf.set_weights(cnn_clf_w)\n",
    "\n",
    "    # set test on validation data for cv mode\n",
    "    x_test = x_test*emg_scale\n",
    "\n",
    "    # loop through test levels\n",
    "    noisefolder = test_sess.create_foldername(ftype='testnoise')\n",
    "    noisefile = test_sess.create_filename(noisefolder,1, sub, ftype='testnoise', test_scale=1)\n",
    "    \n",
    "    if os.path.isfile(noisefile + '.p'):\n",
    "        print('loading data')\n",
    "        with open(noisefile + '.p','rb') as f:\n",
    "            x_test_vae, x_test_clean_vae, x_test_lda, y_test_clean = pickle.load(f) \n",
    "        test_load = True\n",
    "    x_temp = np.transpose(x_test_lda.reshape((x_test_lda.shape[0],num_feats,-1)),(0,2,1))[...,np.newaxis]\n",
    "    x_test_vae = scaler.transform(x_temp.reshape(x_temp.shape[0]*x_temp.shape[1],-1)).reshape(x_temp.shape)\n",
    "\n",
    "    # Reshape for nonconvolutional SAE\n",
    "    x_test_dlsae = x_test_vae.reshape(x_test_vae.shape[0],-1)\n",
    "\n",
    "    ## for timing\n",
    "    %timeit predict(sae_enc(x_test_dlsae[[0],...].astype('float32')).numpy(),w_sae,c_sae)\n",
    "\n",
    "    %timeit predict(cnn_enc(x_test_vae[[0],...].astype('float32')).numpy(),w_cnn,c_cnn)\n",
    "\n",
    "    # lda_start = time.time()\n",
    "    # temp_out = predict(x_test_lda[[0],...], w, c)\n",
    "    # lda_temp = timeit.timeit(lambda: predict(x_test_lda[[0],...], w, c),number= 100)\n",
    "    %timeit predict(x_test_lda[[0],...], w, c)\n",
    "\n",
    "    %timeit predict(x_test_lda[[0],...], w_noise, c_noise)\n",
    "\n",
    "    temp_x = x_test_lda[[0],...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 µs ± 4.01 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mask = np.ones(6,dtype=bool) \n",
    "for i in range(1):\n",
    "    mask[0] = 0\n",
    "maskmu = np.tile(mask,4)\n",
    "test_data = temp_x[:,maskmu]\n",
    "C_temp = C[maskmu,:]\n",
    "C_in = C_temp[:,maskmu]\n",
    "w_temp, c_temp = train_lda(test_data,1,mu_bool = True, mu_class = mu[:,maskmu], C = C_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "px = 1/plt.rcParams['figure.dpi']  # pixel in inches\n",
    "w = 1200\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*px, h*px)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "acc, std = plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "mm = 1/25.4 \n",
    "w = 170\n",
    "h = w/2.125\n",
    "# plot accuracy vs # noisy electrodes\n",
    "fig = plt.figure(figsize=(w*mm, h*mm)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2])\n",
    "plot_utils.plot_electrode_results(ave_noise,ave_clean,test_sess.n_train,ntype,test_sess.sub_type,gs=gs[0])\n",
    "plot_utils.plot_summary(ave_clean,ave_mix,gs=gs[1])\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_diff = acc[:,7] - acc[:,14]\n",
    "sae_diff_tr = acc_tr[:,7] - acc_tr[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr = cp.deepcopy(acc)\n",
    "std_tr = cp.deepcopy(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_summary(ave_clean,ave_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs. position\n",
    "plot_utils.plot_pos_results(ave_pos_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Mixed Linear Model Regression Results\n",
      "==============================================================================\n",
      "Model:                    MixedLM        Dependent Variable:        acc       \n",
      "No. Observations:         325            Method:                    REML      \n",
      "No. Groups:               13             Scale:                     25.3706   \n",
      "Min. group size:          25             Log-Likelihood:            -1005.7780\n",
      "Max. group size:          25             Converged:                 Yes       \n",
      "Mean group size:          25.0                                                \n",
      "------------------------------------------------------------------------------\n",
      "                                   Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept                          21.354    2.833   7.539 0.000 15.802 26.906\n",
      "C(mod, Treatment(10))[T.1.0]        1.369    1.530   0.894 0.371 -1.631  4.368\n",
      "C(mod, Treatment(10))[T.2.0]       -3.453    1.530  -2.257 0.024 -6.453 -0.454\n",
      "C(mod, Treatment(10))[T.11.0]       1.235    1.530   0.807 0.420 -1.765  4.234\n",
      "C(mod, Treatment(10))[T.14.0]      -5.793    1.530  -3.785 0.000 -8.792 -2.793\n",
      "elec                               11.159    0.442  25.260 0.000 10.293 12.025\n",
      "C(mod, Treatment(10))[T.1.0]:elec  -7.152    0.625 -11.447 0.000 -8.376 -5.927\n",
      "C(mod, Treatment(10))[T.2.0]:elec  -7.497    0.625 -12.000 0.000 -8.721 -6.272\n",
      "C(mod, Treatment(10))[T.11.0]:elec -4.300    0.625  -6.883 0.000 -5.524 -3.076\n",
      "C(mod, Treatment(10))[T.14.0]:elec -6.384    0.625 -10.218 0.000 -7.608 -5.159\n",
      "Group Var                          89.083    7.445                            \n",
      "==============================================================================\n",
      "\n",
      "0.0\n",
      "                  Mixed Linear Model Regression Results\n",
      "=========================================================================\n",
      "Model:                  MixedLM       Dependent Variable:       acc      \n",
      "No. Observations:       65            Method:                   REML     \n",
      "No. Groups:             13            Scale:                    14.9098  \n",
      "Min. group size:        5             Log-Likelihood:           -195.6049\n",
      "Max. group size:        5             Converged:                Yes      \n",
      "Mean group size:        5.0                                              \n",
      "-------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------------\n",
      "Intercept                      17.574    3.393  5.180 0.000 10.924 24.223\n",
      "C(mod, Treatment(10))[T.1.0]    5.974    1.515  3.944 0.000  3.005  8.942\n",
      "C(mod, Treatment(10))[T.2.0]    1.180    1.515  0.779 0.436 -1.788  4.149\n",
      "C(mod, Treatment(10))[T.11.0]   5.890    1.515  3.889 0.000  2.922  8.859\n",
      "C(mod, Treatment(10))[T.14.0]  -0.000    1.515 -0.000 1.000 -2.968  2.968\n",
      "Group Var                     134.732   16.278                           \n",
      "=========================================================================\n",
      "\n",
      "1.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        65             Method:                    REML     \n",
      "No. Groups:              13             Scale:                     13.8713  \n",
      "Min. group size:         5              Log-Likelihood:            -192.6836\n",
      "Max. group size:         5              Converged:                 Yes      \n",
      "Mean group size:         5.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      34.734    3.089  11.244 0.000  28.679  40.789\n",
      "C(mod, Treatment(10))[T.1.0]   -8.358    1.461  -5.722 0.000 -11.221  -5.495\n",
      "C(mod, Treatment(10))[T.2.0]  -13.659    1.461  -9.350 0.000 -16.523 -10.796\n",
      "C(mod, Treatment(10))[T.11.0]  -5.686    1.461  -3.892 0.000  -8.549  -2.823\n",
      "C(mod, Treatment(10))[T.14.0] -15.176    1.461 -10.388 0.000 -18.039 -12.312\n",
      "Group Var                     110.193   13.844                              \n",
      "============================================================================\n",
      "\n",
      "2.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        65             Method:                    REML     \n",
      "No. Groups:              13             Scale:                     21.9164  \n",
      "Min. group size:         5              Log-Likelihood:            -202.5350\n",
      "Max. group size:         5              Converged:                 Yes      \n",
      "Mean group size:         5.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      47.246    2.924  16.157 0.000  41.515  52.977\n",
      "C(mod, Treatment(10))[T.1.0]  -17.396    1.836  -9.474 0.000 -20.995 -13.797\n",
      "C(mod, Treatment(10))[T.2.0]  -22.809    1.836 -12.422 0.000 -26.408 -19.210\n",
      "C(mod, Treatment(10))[T.11.0] -11.945    1.836  -6.505 0.000 -15.544  -8.346\n",
      "C(mod, Treatment(10))[T.14.0] -24.110    1.836 -13.130 0.000 -27.709 -20.511\n",
      "Group Var                      89.246    9.128                              \n",
      "============================================================================\n",
      "\n",
      "3.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        65             Method:                    REML     \n",
      "No. Groups:              13             Scale:                     28.7211  \n",
      "Min. group size:         5              Log-Likelihood:            -207.6707\n",
      "Max. group size:         5              Converged:                 Yes      \n",
      "Mean group size:         5.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      56.138    2.741  20.479 0.000  50.766  61.511\n",
      "C(mod, Treatment(10))[T.1.0]  -21.857    2.102 -10.398 0.000 -25.977 -17.737\n",
      "C(mod, Treatment(10))[T.2.0]  -27.626    2.102 -13.143 0.000 -31.746 -23.506\n",
      "C(mod, Treatment(10))[T.11.0] -13.266    2.102  -6.311 0.000 -17.386  -9.146\n",
      "C(mod, Treatment(10))[T.14.0] -28.018    2.102 -13.329 0.000 -32.138 -23.898\n",
      "Group Var                      68.973    6.363                              \n",
      "============================================================================\n",
      "\n",
      "4.0\n",
      "                   Mixed Linear Model Regression Results\n",
      "============================================================================\n",
      "Model:                   MixedLM        Dependent Variable:        acc      \n",
      "No. Observations:        65             Method:                    REML     \n",
      "No. Groups:              13             Scale:                     32.7231  \n",
      "Min. group size:         5              Log-Likelihood:            -208.9256\n",
      "Max. group size:         5              Converged:                 Yes      \n",
      "Mean group size:         5.0                                                \n",
      "----------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "----------------------------------------------------------------------------\n",
      "Intercept                      62.666    2.494  25.131 0.000  57.779  67.553\n",
      "C(mod, Treatment(10))[T.1.0]  -23.035    2.244 -10.266 0.000 -27.433 -18.638\n",
      "C(mod, Treatment(10))[T.2.0]  -29.321    2.244 -13.068 0.000 -33.719 -24.923\n",
      "C(mod, Treatment(10))[T.11.0] -11.820    2.244  -5.268 0.000 -16.217  -7.422\n",
      "C(mod, Treatment(10))[T.14.0] -25.499    2.244 -11.364 0.000 -29.896 -21.101\n",
      "Group Var                      48.112    4.361                              \n",
      "============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = stat.create_dataframe(acc_clean,acc_noise)\n",
    "df = stat.get_mods(df)\n",
    "all_md = stat.run_fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                        1.193632e-06\n",
      "C(mod, Treatment(10))[T.6.0]     7.780299e-02\n",
      "C(mod, Treatment(10))[T.7.0]     4.469587e+00\n",
      "C(mod, Treatment(10))[T.11.0]    3.064230e-22\n",
      "C(mod, Treatment(10))[T.14.0]    5.000000e+00\n",
      "Group Var                        2.328940e-01\n",
      "dtype: float64\n",
      "Intercept                        4.416554e-29\n",
      "C(mod, Treatment(10))[T.6.0]     2.115892e-04\n",
      "C(mod, Treatment(10))[T.7.0]     1.401737e-13\n",
      "C(mod, Treatment(10))[T.11.0]    3.133384e-05\n",
      "C(mod, Treatment(10))[T.14.0]    2.129329e-12\n",
      "Group Var                        2.311695e-01\n",
      "dtype: float64\n",
      "Intercept                        6.063096e-60\n",
      "C(mod, Treatment(10))[T.6.0]     1.412260e-11\n",
      "C(mod, Treatment(10))[T.7.0]     1.016878e-26\n",
      "C(mod, Treatment(10))[T.11.0]    1.649802e+00\n",
      "C(mod, Treatment(10))[T.14.0]    3.400562e-23\n",
      "Group Var                        2.669334e-01\n",
      "dtype: float64\n",
      "Intercept                        8.607356e-94\n",
      "C(mod, Treatment(10))[T.6.0]     1.186216e-13\n",
      "C(mod, Treatment(10))[T.7.0]     6.444625e-33\n",
      "C(mod, Treatment(10))[T.11.0]    4.022814e+00\n",
      "C(mod, Treatment(10))[T.14.0]    2.495244e-26\n",
      "Group Var                        3.059571e-01\n",
      "dtype: float64\n",
      "Intercept                        2.946821e-130\n",
      "C(mod, Treatment(10))[T.6.0]      5.211983e-12\n",
      "C(mod, Treatment(10))[T.7.0]      4.126468e-30\n",
      "C(mod, Treatment(10))[T.11.0]     4.684713e+00\n",
      "C(mod, Treatment(10))[T.14.0]     3.202539e-18\n",
      "Group Var                         3.826802e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # print(all_md[str(i) + '.0'].pvalues)\n",
    "    print(all_md[str(i) + '.0'].pvalues*5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a3b9df806ffb9c99dfd499571232d2e3ccda8a03627b2b254cd16611a407c53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf-2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
